{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of NCBI+SciModel-Bio.ipynb","provenance":[{"file_id":"1apRBKJ_i2t4gsKy0TfRAM0Gih4gDkI15","timestamp":1634538734401}],"collapsed_sections":["LyMVIljFrioE","52t8l945rf1Y","-DBrafz0KqEq","oGYV8ipcJ5fU","7LthVVOhx_Sz","kv6pGzbGpv2D","BBA4owXH8oS1","dcdDIwq0kXy2","k0w9Lc0d3iOT","hC35X0v72kXB","ymiejDO5srYE"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2908749eeb9541cab5e9ce0a8e3aa2ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ec6de0704a14579966efb2bc602fdf5","IPY_MODEL_02b4bfa1af2245e0815a2e1a00c1e718","IPY_MODEL_1421cbe3022f49c2bc62dca7a5e2b0d0"],"layout":"IPY_MODEL_2cd7f8839ec44ebfaefe8aa0519b8005"}},"0ec6de0704a14579966efb2bc602fdf5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c614aafbbbc24a37beb63e4f3414b16a","placeholder":"​","style":"IPY_MODEL_cf2b767db5944f6298c0ca917a5c3127","value":"Downloading: 100%"}},"02b4bfa1af2245e0815a2e1a00c1e718":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5592cc2822804ed6a2f0985a5e03df57","max":385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d0706183667840678f5df7dbef64226d","value":385}},"1421cbe3022f49c2bc62dca7a5e2b0d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da16a46911dc48a7846f1a95d8829fab","placeholder":"​","style":"IPY_MODEL_f1c95ef525ea472eb89baa37fb700ac4","value":" 385/385 [00:00&lt;00:00, 2.58kB/s]"}},"2cd7f8839ec44ebfaefe8aa0519b8005":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c614aafbbbc24a37beb63e4f3414b16a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf2b767db5944f6298c0ca917a5c3127":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5592cc2822804ed6a2f0985a5e03df57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0706183667840678f5df7dbef64226d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"da16a46911dc48a7846f1a95d8829fab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1c95ef525ea472eb89baa37fb700ac4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"edea1b24b98b40c18d26b73b1086682a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2b7522c89549432ab2d861fe45d9b662","IPY_MODEL_1c6c420a82b9405389bdcb214d3c4503","IPY_MODEL_ccb12d7ff89540faa7ce5cf9000c4b46"],"layout":"IPY_MODEL_ae5494940874402ca542ac7213f97fe9"}},"2b7522c89549432ab2d861fe45d9b662":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8994e2ba58fd4f79a13f8aa0dbc013f9","placeholder":"​","style":"IPY_MODEL_d8c89200554b4e79bb144fe53e86ca3c","value":"Downloading: 100%"}},"1c6c420a82b9405389bdcb214d3c4503":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8a559057a0a45fc9a3973a1fd837b64","max":227845,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a0220417aa4a4bf98b0c6db7bee5f4a1","value":227845}},"ccb12d7ff89540faa7ce5cf9000c4b46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7442a5c53f74e1bb57921e8bb3116e9","placeholder":"​","style":"IPY_MODEL_4c419aa1c2e149d5a619ac787f943fa6","value":" 223k/223k [00:00&lt;00:00, 477kB/s]"}},"ae5494940874402ca542ac7213f97fe9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8994e2ba58fd4f79a13f8aa0dbc013f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8c89200554b4e79bb144fe53e86ca3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8a559057a0a45fc9a3973a1fd837b64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0220417aa4a4bf98b0c6db7bee5f4a1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7442a5c53f74e1bb57921e8bb3116e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c419aa1c2e149d5a619ac787f943fa6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d0350b59d1e4fadb07e111ecbc0425e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_91b6e70663fe45adbdb846526169106b","IPY_MODEL_9691485dec3b497ab4f7f94fd472ce54","IPY_MODEL_65a03863a5f34ef3a374ee94cacfbfde"],"layout":"IPY_MODEL_e645f74f69d1470192b34af58524b8d0"}},"91b6e70663fe45adbdb846526169106b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c472f8785084f62a835b7067f65296d","placeholder":"​","style":"IPY_MODEL_dd6119bedc5a4cf0aa46fe7e8d034a98","value":"Downloading: 100%"}},"9691485dec3b497ab4f7f94fd472ce54":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6befb835f9d64d42ac1b822cfd409207","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1a0e33b8dcc34aaaa51ff62f32a5756d","value":442221694}},"65a03863a5f34ef3a374ee94cacfbfde":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28687c678b3e4bf3b8eef0db76abef90","placeholder":"​","style":"IPY_MODEL_20424c56fe024d89ae8bdfa391c0fb6a","value":" 422M/422M [00:12&lt;00:00, 36.1MB/s]"}},"e645f74f69d1470192b34af58524b8d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c472f8785084f62a835b7067f65296d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd6119bedc5a4cf0aa46fe7e8d034a98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6befb835f9d64d42ac1b822cfd409207":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a0e33b8dcc34aaaa51ff62f32a5756d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"28687c678b3e4bf3b8eef0db76abef90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20424c56fe024d89ae8bdfa391c0fb6a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4a684e6ba6648ecac5d892c2a57465c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2d403e2117a44692836452fe29746f72","IPY_MODEL_9741798c0ddb4b7793a1013c1c635b5c","IPY_MODEL_a50f30893ced4f8db73246e45b51505e"],"layout":"IPY_MODEL_5f01e30a492b48f892de34c0b047d67a"}},"2d403e2117a44692836452fe29746f72":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a57d711b71974c348992799da99a5dd7","placeholder":"​","style":"IPY_MODEL_819fd0d7f5374f729190caef0c29d889","value":"Downloading: "}},"9741798c0ddb4b7793a1013c1c635b5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f0863d2d864414687d2141651f7bb63","max":2279,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b018dc3d84f4f79a107d39d9802f43a","value":2279}},"a50f30893ced4f8db73246e45b51505e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f960d4cd1ec34be785fbbee7d60394ea","placeholder":"​","style":"IPY_MODEL_aa5968b1be144ee191e166aab3a63348","value":" 5.83k/? [00:00&lt;00:00, 124kB/s]"}},"5f01e30a492b48f892de34c0b047d67a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a57d711b71974c348992799da99a5dd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"819fd0d7f5374f729190caef0c29d889":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f0863d2d864414687d2141651f7bb63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b018dc3d84f4f79a107d39d9802f43a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f960d4cd1ec34be785fbbee7d60394ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa5968b1be144ee191e166aab3a63348":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"483e5020da1f4be4abc92aa3b50c2fc8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a16d02491884dc5b1714449d650e8b0","IPY_MODEL_17cb6dcae0c840ceaea0776d46b3bbf3","IPY_MODEL_aa2f8b48dad5493bb071289cf3b8a5de"],"layout":"IPY_MODEL_ab0f1a3f8c0a424f825db7ce2fa7d960"}},"9a16d02491884dc5b1714449d650e8b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25ca668e17964471b95540fdbeb7a203","placeholder":"​","style":"IPY_MODEL_25f9138e40c445548122b2ef5b403945","value":"Downloading: "}},"17cb6dcae0c840ceaea0776d46b3bbf3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3a11595166a49c48fdb099852bf2e63","max":1549,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0b21011565f044f686e042c83ea44d23","value":1549}},"aa2f8b48dad5493bb071289cf3b8a5de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa439b6ff05348c5a313a7f78b032c87","placeholder":"​","style":"IPY_MODEL_e79c31b8352e44879bd5eab85bd56af8","value":" 3.45k/? [00:00&lt;00:00, 46.3kB/s]"}},"ab0f1a3f8c0a424f825db7ce2fa7d960":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25ca668e17964471b95540fdbeb7a203":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25f9138e40c445548122b2ef5b403945":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3a11595166a49c48fdb099852bf2e63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b21011565f044f686e042c83ea44d23":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa439b6ff05348c5a313a7f78b032c87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e79c31b8352e44879bd5eab85bd56af8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f8a628530e74ab7b087f02be6ef5df0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4acb59b5557c4264899cbcdc52f01f15","IPY_MODEL_0835d97423214e159f402d5c54b80ce1","IPY_MODEL_bf716e0897524c10a8654ace8c184f98"],"layout":"IPY_MODEL_22dc28422cb543ec84e47790db20ab8e"}},"4acb59b5557c4264899cbcdc52f01f15":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a2392d75c414f2bba11be06c0b9faa6","placeholder":"​","style":"IPY_MODEL_5983c3d642164bda871ba951bbec2706","value":"100%"}},"0835d97423214e159f402d5c54b80ce1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc627b7165844858ba0e2fd9e7445bc3","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d9505a1988794f04acfe8757cdece3dd","value":3}},"bf716e0897524c10a8654ace8c184f98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a0907c447224a18a3b416e34523d1ca","placeholder":"​","style":"IPY_MODEL_d7946753d7d449d2b82bf99fc25ec240","value":" 3/3 [00:02&lt;00:00,  1.61it/s]"}},"22dc28422cb543ec84e47790db20ab8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a2392d75c414f2bba11be06c0b9faa6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5983c3d642164bda871ba951bbec2706":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc627b7165844858ba0e2fd9e7445bc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9505a1988794f04acfe8757cdece3dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a0907c447224a18a3b416e34523d1ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7946753d7d449d2b82bf99fc25ec240":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ede52f275c4545a798012183dc544e5e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21a71ec14ec24001a8c90c9dc20fcfb1","IPY_MODEL_61f9961c17984054a69b0e5b0ade09bb","IPY_MODEL_87bccc17914345149dee7ed7eb018139"],"layout":"IPY_MODEL_6f688b60ed3c498183374005f9cabef4"}},"21a71ec14ec24001a8c90c9dc20fcfb1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27340d5ffff24799957fe59e7973c1c8","placeholder":"​","style":"IPY_MODEL_d09e7686226142e8bde6d16738b727df","value":"Downloading: "}},"61f9961c17984054a69b0e5b0ade09bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_003e540fadc3435fb9ea1aef9c582795","max":283883,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66691b19e19b4598841e4b83a2d1377e","value":283883}},"87bccc17914345149dee7ed7eb018139":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a248be62b184450bb7997b9db605e075","placeholder":"​","style":"IPY_MODEL_e6538ab1d7874a11884f6d7e0cc46fcc","value":" 1.14M/? [00:00&lt;00:00, 13.7MB/s]"}},"6f688b60ed3c498183374005f9cabef4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27340d5ffff24799957fe59e7973c1c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d09e7686226142e8bde6d16738b727df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"003e540fadc3435fb9ea1aef9c582795":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66691b19e19b4598841e4b83a2d1377e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a248be62b184450bb7997b9db605e075":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6538ab1d7874a11884f6d7e0cc46fcc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"adf6a0c8662a453cbc97ba3e812520ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b98ce72d99a84cb9b6204f1ce3b061b5","IPY_MODEL_3d83745cf7f04ef39ba08d36ca4e3ad4","IPY_MODEL_9eb0799851ad418688f5cbcd26caee7b"],"layout":"IPY_MODEL_fe31698e0ddb47c7af0ec97679821a7a"}},"b98ce72d99a84cb9b6204f1ce3b061b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3057437b054d4b779cf2dc984529308a","placeholder":"​","style":"IPY_MODEL_788ca13fed6c42b894b4d25feb75ffd7","value":"Downloading: "}},"3d83745cf7f04ef39ba08d36ca4e3ad4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_57d7a9ae6bfb4d6ea1a36cf9fa995dc1","max":51200,"min":0,"orientation":"horizontal","style":"IPY_MODEL_01d0b3bd6a544db4b449093f6b1697ae","value":51200}},"9eb0799851ad418688f5cbcd26caee7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e715c858f2a84940b6f6cd23c9fcc30e","placeholder":"​","style":"IPY_MODEL_b317e421c256410a9cd81aa8cd549c79","value":" 200k/? [00:00&lt;00:00, 3.86MB/s]"}},"fe31698e0ddb47c7af0ec97679821a7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3057437b054d4b779cf2dc984529308a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"788ca13fed6c42b894b4d25feb75ffd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57d7a9ae6bfb4d6ea1a36cf9fa995dc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01d0b3bd6a544db4b449093f6b1697ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e715c858f2a84940b6f6cd23c9fcc30e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b317e421c256410a9cd81aa8cd549c79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63bfefb8bad94e7eb9db4ac687dcb6b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d5f10844502440f9ff496c6334872b3","IPY_MODEL_1fa8067559854650ba726bf502939dea","IPY_MODEL_eb894632c40b4a16a9e94c5d0895761d"],"layout":"IPY_MODEL_d6e77d8854fc4fe3a6abbb99291f4425"}},"4d5f10844502440f9ff496c6334872b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab4908d2b1764b09852124a7173e3f2c","placeholder":"​","style":"IPY_MODEL_55012f29b0274f148ea5c0d25027c216","value":"Downloading: "}},"1fa8067559854650ba726bf502939dea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_80b4d709448449d2bf17a47f0b335973","max":52411,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52a494b693a7435b9aad2bf3429d96a4","value":52411}},"eb894632c40b4a16a9e94c5d0895761d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31ff893c6d6543a3bcfdc6d3abe2cac7","placeholder":"​","style":"IPY_MODEL_c599109fc7864dad88ca1b8f6e06cc15","value":" 206k/? [00:00&lt;00:00, 2.96MB/s]"}},"d6e77d8854fc4fe3a6abbb99291f4425":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab4908d2b1764b09852124a7173e3f2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55012f29b0274f148ea5c0d25027c216":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80b4d709448449d2bf17a47f0b335973":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52a494b693a7435b9aad2bf3429d96a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"31ff893c6d6543a3bcfdc6d3abe2cac7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c599109fc7864dad88ca1b8f6e06cc15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b72d2c668a8f4d6984baef0c6f8901d1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_02951eafc1544b1ba39119681744c692","IPY_MODEL_af2c78dd2338485aaaa165a06042cc3b","IPY_MODEL_324e4a822ed14150a6c7666015f0cd8b"],"layout":"IPY_MODEL_84de313911a4453ab3a163c12dd95692"}},"02951eafc1544b1ba39119681744c692":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70e19c3bbd86406e9af16832d9f106cf","placeholder":"​","style":"IPY_MODEL_91ef2e773a7c4a858fecec0e8bdc027c","value":"100%"}},"af2c78dd2338485aaaa165a06042cc3b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_63ec199feca04b2785ddd9fafe8d1c8f","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7595590b5fba4eb5bb0300b8c230d745","value":3}},"324e4a822ed14150a6c7666015f0cd8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d27fbcb8d7b249fabe15433aeac595e9","placeholder":"​","style":"IPY_MODEL_6778e0889a324aae895431042e2f7079","value":" 3/3 [00:00&lt;00:00, 37.69it/s]"}},"84de313911a4453ab3a163c12dd95692":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70e19c3bbd86406e9af16832d9f106cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91ef2e773a7c4a858fecec0e8bdc027c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63ec199feca04b2785ddd9fafe8d1c8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7595590b5fba4eb5bb0300b8c230d745":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d27fbcb8d7b249fabe15433aeac595e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6778e0889a324aae895431042e2f7079":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5fbf5b8b8092419cb1c9386181b3884f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_96c6ec6fefb44460a869a978e726ba36","IPY_MODEL_9ddb3737371e470d81832638a6c2325e","IPY_MODEL_cf167b3260a0406782446dac46524248"],"layout":"IPY_MODEL_ae3be152eddc43eeb1a515ce51529662"}},"96c6ec6fefb44460a869a978e726ba36":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa9ad868ed9c4a2ca1bbe0fba8780c02","placeholder":"​","style":"IPY_MODEL_cad47f631a8f4244beb21d316ae57f81","value":""}},"9ddb3737371e470d81832638a6c2325e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_7078eca031a848088dfbc5febbbedc4f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cd0284d273f1486db1c5c39ab06c0765","value":1}},"cf167b3260a0406782446dac46524248":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5862275f95df433b9e89cfa2fb4c8faf","placeholder":"​","style":"IPY_MODEL_59549132164a4b0a8bdb0a0b6dec18e8","value":" 5183/0 [00:01&lt;00:00, 2493.67 examples/s]"}},"ae3be152eddc43eeb1a515ce51529662":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa9ad868ed9c4a2ca1bbe0fba8780c02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cad47f631a8f4244beb21d316ae57f81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7078eca031a848088dfbc5febbbedc4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"cd0284d273f1486db1c5c39ab06c0765":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5862275f95df433b9e89cfa2fb4c8faf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59549132164a4b0a8bdb0a0b6dec18e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a395abe100a54ab98e3a367368b04966":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_42ece18376334992b7d398e51263f195","IPY_MODEL_7589ec5d35174fa39b919e6b129a6253","IPY_MODEL_5f0297f7e34e40ba9cb0b58f61d11693"],"layout":"IPY_MODEL_29e9064263cd41ac8ee8adc2cd04b1c4"}},"42ece18376334992b7d398e51263f195":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c639c58a11be45e18bef8eb6dd29b325","placeholder":"​","style":"IPY_MODEL_8b62d250845f4ec190168144ea9c7e1a","value":""}},"7589ec5d35174fa39b919e6b129a6253":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bea9229c4b1419289d82957a52ae9d6","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8d0300c5cb84cd6a2260d0444ef8fad","value":1}},"5f0297f7e34e40ba9cb0b58f61d11693":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c42ac460d1254cbaac67aaed1db856a1","placeholder":"​","style":"IPY_MODEL_53e13ffd45774adb88688e795bc50e8d","value":" 785/0 [00:00&lt;00:00, 1724.60 examples/s]"}},"29e9064263cd41ac8ee8adc2cd04b1c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c639c58a11be45e18bef8eb6dd29b325":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b62d250845f4ec190168144ea9c7e1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5bea9229c4b1419289d82957a52ae9d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b8d0300c5cb84cd6a2260d0444ef8fad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c42ac460d1254cbaac67aaed1db856a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53e13ffd45774adb88688e795bc50e8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae1a04ad00384ab9b51ab77f00a87d10":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6157b19cfd9b450081a239ce14d30b9f","IPY_MODEL_2e7f959fcbf247f1ac011fdfd4d1e92b","IPY_MODEL_938286fc091c4384bffd6ea33c1344ad"],"layout":"IPY_MODEL_5dc3f685359d4faa835a94998cfe912a"}},"6157b19cfd9b450081a239ce14d30b9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90ecaae0ef3c4e0a8609c09b3c993eab","placeholder":"​","style":"IPY_MODEL_5fe35823d14a4807be2dc8d5a3bcf950","value":""}},"2e7f959fcbf247f1ac011fdfd4d1e92b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_7820bf754e8a4dd9b1bf54ae8c86df21","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4999c60af904c7aa60c5bd33a7aad7b","value":1}},"938286fc091c4384bffd6ea33c1344ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18b75a47e6864b30ac47b17bd0e3aa23","placeholder":"​","style":"IPY_MODEL_130a7e6663c84fc7b3d16f3a9e8687fd","value":" 769/0 [00:00&lt;00:00, 1548.70 examples/s]"}},"5dc3f685359d4faa835a94998cfe912a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90ecaae0ef3c4e0a8609c09b3c993eab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fe35823d14a4807be2dc8d5a3bcf950":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7820bf754e8a4dd9b1bf54ae8c86df21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c4999c60af904c7aa60c5bd33a7aad7b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"18b75a47e6864b30ac47b17bd0e3aa23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"130a7e6663c84fc7b3d16f3a9e8687fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CQ6H5sYFfFCM","executionInfo":{"status":"ok","timestamp":1638577821479,"user_tz":360,"elapsed":242,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"1c6f9353-196c-43fa-a996-765dca75925e"},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sample_data\n"]}]},{"cell_type":"markdown","metadata":{"id":"LyMVIljFrioE"},"source":["#External Databases"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IeeP8a6fKXOX","executionInfo":{"status":"ok","timestamp":1647068675001,"user_tz":360,"elapsed":41016,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"b319e6dd-725d-4056-9de8-f2d04edabefc"},"source":["! pip install git+https://github.com/huggingface/transformers.git"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/transformers.git\n","  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-cpdb1j33\n","  Running command git clone -q https://github.com/huggingface/transformers.git /tmp/pip-req-build-cpdb1j33\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (4.63.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (1.21.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (3.6.0)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 12.3 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 4.9 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 44.0 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (4.11.2)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 50.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0.dev0) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.18.0.dev0) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.18.0.dev0) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0.dev0) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0.dev0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0.dev0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0.dev0) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0.dev0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0.dev0) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0.dev0) (1.15.0)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.18.0.dev0-py3-none-any.whl size=3836842 sha256=e44be4d294ca48515d13918d2b5c72f795c9f74d72e927de24b87d39e198fb16\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-majyksk1/wheels/90/a5/44/6bcd83827c8a60628c5ad602f429cd5076bcce5f2a90054947\n","Successfully built transformers\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.6 transformers-4.18.0.dev0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_L4bHxBGsZk_","executionInfo":{"status":"ok","timestamp":1647068700570,"user_tz":360,"elapsed":25573,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"cbea4ee0-7b15-487d-e851-f1f5a0b5fa60"},"source":["! pip install ray[tune]"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ray[tune]\n","  Downloading ray-1.11.0-cp37-cp37m-manylinux2014_x86_64.whl (52.7 MB)\n","\u001b[K     |████████████████████████████████| 52.7 MB 132 kB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.6.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.0.3)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.3.3)\n","Collecting redis>=3.5.0\n","  Downloading redis-4.1.4-py3-none-any.whl (175 kB)\n","\u001b[K     |████████████████████████████████| 175 kB 48.6 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (6.0)\n","Collecting grpcio<=1.43.0,>=1.28.1\n","  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n","\u001b[K     |████████████████████████████████| 4.1 MB 7.3 MB/s \n","\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (7.1.2)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.21.5)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (21.4.0)\n","Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.17.3)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.8.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.3.5)\n","Collecting tensorboardX>=1.9\n","  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 39.7 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray[tune]) (1.15.0)\n","Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (21.3)\n","Collecting deprecated>=1.2.3\n","  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (4.11.2)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]) (1.13.3)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]) (3.7.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.4->redis>=3.5.0->ray[tune]) (3.0.7)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (0.18.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (5.4.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2.8.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2021.10.8)\n","Installing collected packages: deprecated, redis, grpcio, tensorboardX, ray\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.44.0\n","    Uninstalling grpcio-1.44.0:\n","      Successfully uninstalled grpcio-1.44.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n","Successfully installed deprecated-1.2.13 grpcio-1.43.0 ray-1.11.0 redis-4.1.4 tensorboardX-2.5\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UI0tseYdav7D","executionInfo":{"status":"ok","timestamp":1647068717031,"user_tz":360,"elapsed":16478,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"39fd0227-43cc-40c4-d993-31379c9632cc"},"source":["!pip install datasets"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-1.18.4-py3-none-any.whl (312 kB)\n","\u001b[K     |████████████████████████████████| 312 kB 10.9 MB/s \n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 52.9 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.63.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n","Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 48.3 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n","\u001b[K     |████████████████████████████████| 134 kB 53.5 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 54.0 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 1.8 MB/s \n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 36.5 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 37.6 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-1.18.4 frozenlist-1.3.0 fsspec-2022.2.0 multidict-6.0.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"]}]},{"cell_type":"code","source":["!pip install seqeval"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ApLO4wm1cmwo","executionInfo":{"status":"ok","timestamp":1647068728097,"user_tz":360,"elapsed":11071,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"14223759-c23c-4045-ed95-0538965f6352"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[?25l\r\u001b[K     |███████▌                        | 10 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20 kB 26.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30 kB 22.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=0b9b5070f96bf1a40ebcb8838bd656120c73cbeeda0d11dbbfe3432554602221\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n"]}]},{"cell_type":"markdown","metadata":{"id":"52t8l945rf1Y"},"source":["#Libraries"]},{"cell_type":"code","metadata":{"id":"qSbdGMYCgquq","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["2908749eeb9541cab5e9ce0a8e3aa2ab","0ec6de0704a14579966efb2bc602fdf5","02b4bfa1af2245e0815a2e1a00c1e718","1421cbe3022f49c2bc62dca7a5e2b0d0","2cd7f8839ec44ebfaefe8aa0519b8005","c614aafbbbc24a37beb63e4f3414b16a","cf2b767db5944f6298c0ca917a5c3127","5592cc2822804ed6a2f0985a5e03df57","d0706183667840678f5df7dbef64226d","da16a46911dc48a7846f1a95d8829fab","f1c95ef525ea472eb89baa37fb700ac4","edea1b24b98b40c18d26b73b1086682a","2b7522c89549432ab2d861fe45d9b662","1c6c420a82b9405389bdcb214d3c4503","ccb12d7ff89540faa7ce5cf9000c4b46","ae5494940874402ca542ac7213f97fe9","8994e2ba58fd4f79a13f8aa0dbc013f9","d8c89200554b4e79bb144fe53e86ca3c","a8a559057a0a45fc9a3973a1fd837b64","a0220417aa4a4bf98b0c6db7bee5f4a1","a7442a5c53f74e1bb57921e8bb3116e9","4c419aa1c2e149d5a619ac787f943fa6","8d0350b59d1e4fadb07e111ecbc0425e","91b6e70663fe45adbdb846526169106b","9691485dec3b497ab4f7f94fd472ce54","65a03863a5f34ef3a374ee94cacfbfde","e645f74f69d1470192b34af58524b8d0","4c472f8785084f62a835b7067f65296d","dd6119bedc5a4cf0aa46fe7e8d034a98","6befb835f9d64d42ac1b822cfd409207","1a0e33b8dcc34aaaa51ff62f32a5756d","28687c678b3e4bf3b8eef0db76abef90","20424c56fe024d89ae8bdfa391c0fb6a"],"height":0},"executionInfo":{"status":"ok","timestamp":1647068763342,"user_tz":360,"elapsed":35248,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"ee05d8f2-5eb1-46ff-dd52-ee0b699dac92"},"source":["from google.colab import files\n","\n","import os\n","import re\n","import json\n","import string\n","\n","import torch\n","import torch.nn as nn\n","\n","import numpy as np\n","#import tensorflow as tf\n","from tensorflow import keras\n","#from tensorflow.keras import layers\n","\n","from datasets import load_metric\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","from seqeval.metrics import classification_report\n","from sklearn.metrics import precision_recall_fscore_support as prfs\n","\n","import tensorflow_hub as hub\n","from keras import backend as K\n","\n","import transformers\n","print(transformers.__version__)\n","from transformers import TrainingArguments\n","from transformers import Trainer\n","from transformers.trainer_utils import EvalLoopOutput\n","\n","from transformers import AutoTokenizer, AutoModel\n","BertTokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n","BertEmbModel = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["4.18.0.dev0\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2908749eeb9541cab5e9ce0a8e3aa2ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/223k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edea1b24b98b40c18d26b73b1086682a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/422M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d0350b59d1e4fadb07e111ecbc0425e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"markdown","metadata":{"id":"-DBrafz0KqEq"},"source":["#Loading Dataset"]},{"cell_type":"code","source":["class NCBIDataset(torch.utils.data.Dataset):\n","  def __init__(self, raw_dataset, max_length=180):\n","    self.raw_x = [x['tokens'] for x in raw_dataset]\n","    self.raw_y = [x['ner_tags'] for x in raw_dataset]\n","    \n","    self.max_length = max_length\n","\n","  def tokenize_and_preserve_labels(self, sentence, text_labels):\n","    \"\"\"\n","    The tokenizer can split single words into multiple tokens - this breaks\n","    the labels, so we need to keep track of this!\n","    \"\"\"\n","    tokenized_sentence = []\n","    labels = []\n","\n","    for word, label in zip(sentence, text_labels):\n","\n","        # Tokenize the word and count # of subwords the word is broken into\n","        tokenized_word = BertTokenizer.tokenize(word)\n","        n_subwords = len(tokenized_word)\n","\n","        # Add the tokenized word to the final tokenized word list\n","        tokenized_sentence.extend(tokenized_word)\n","\n","        # Add the same label to the new list of labels `n_subwords` times\n","        labels.extend([label] * n_subwords)\n","\n","    return tokenized_sentence, labels\n","\n","  def __getitem__(self, idx):\n","    tokens = self.raw_x[idx]\n","    labels = np.zeros((len(tokens)))\n","    for i, label in enumerate(self.raw_y[idx]):\n","      labels[i] = label\n","\n","    # This could be moved to __init__ to save time?\n","    tokens, labels = self.tokenize_and_preserve_labels(tokens, labels)\n","\n","    # Convert each token to an id number \n","    input_ids = BertTokenizer.convert_tokens_to_ids(tokens)\n","    \n","    # add and adjust for special tokens\n","    input_ids = [BertTokenizer.cls_token_id] + input_ids + [BertTokenizer.sep_token_id]  \n","    labels = [0] + labels + [0]\n","\n","    # Pad inputs\n","    input_ids = torch.tensor(np.pad(input_ids, [0, self.max_length-len(input_ids)]))\n","    labels = torch.tensor(np.pad(labels, [0, self.max_length-len(labels)], constant_values=-100))\n","\n","    attention_mask = torch.tensor([int(i != 0) for i in input_ids])\n","\n","    #return {input_ids, labels}\n","    #return {'input_ids': [input_ids], 'labels': labels}\n","    return {'input_ids': [input_ids], 'attention_mask': [attention_mask], 'labels': labels}\n","\n","  def __len__(self):\n","    return len(self.raw_y)"],"metadata":{"id":"_vZ1ILIWq9do","executionInfo":{"status":"ok","timestamp":1647068763343,"user_tz":360,"elapsed":6,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Entity mapping, uses BIO tags\n","def Entity2ID(Sc_Entity):\n","  return {\n","        'B': 1,\n","        'I': 2,\n","        'O': 0,\n","    }[Sc_Entity]\n","\n","def ID2Entity(Sc_Entity):\n","  return {\n","        1: 'B',\n","        2: 'I',\n","        0: 'None',\n","    }[Sc_Entity]\n"],"metadata":{"id":"gJBtnL2Jq_eQ","executionInfo":{"status":"ok","timestamp":1647068763957,"user_tz":360,"elapsed":619,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Download dataset using datasets, might need to install it!\n","from datasets import load_dataset\n","\n","raw_train = load_dataset('ncbi_disease', split='train')\n","raw_test = load_dataset('ncbi_disease', split='test')\n","raw_val = load_dataset('ncbi_disease', split='validation')\n","\n","# Convert to torch datasets\n","train = NCBIDataset(raw_train)\n","test = NCBIDataset(raw_test)\n","val = NCBIDataset(raw_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["f4a684e6ba6648ecac5d892c2a57465c","2d403e2117a44692836452fe29746f72","9741798c0ddb4b7793a1013c1c635b5c","a50f30893ced4f8db73246e45b51505e","5f01e30a492b48f892de34c0b047d67a","a57d711b71974c348992799da99a5dd7","819fd0d7f5374f729190caef0c29d889","0f0863d2d864414687d2141651f7bb63","7b018dc3d84f4f79a107d39d9802f43a","f960d4cd1ec34be785fbbee7d60394ea","aa5968b1be144ee191e166aab3a63348","483e5020da1f4be4abc92aa3b50c2fc8","9a16d02491884dc5b1714449d650e8b0","17cb6dcae0c840ceaea0776d46b3bbf3","aa2f8b48dad5493bb071289cf3b8a5de","ab0f1a3f8c0a424f825db7ce2fa7d960","25ca668e17964471b95540fdbeb7a203","25f9138e40c445548122b2ef5b403945","e3a11595166a49c48fdb099852bf2e63","0b21011565f044f686e042c83ea44d23","fa439b6ff05348c5a313a7f78b032c87","e79c31b8352e44879bd5eab85bd56af8","9f8a628530e74ab7b087f02be6ef5df0","4acb59b5557c4264899cbcdc52f01f15","0835d97423214e159f402d5c54b80ce1","bf716e0897524c10a8654ace8c184f98","22dc28422cb543ec84e47790db20ab8e","1a2392d75c414f2bba11be06c0b9faa6","5983c3d642164bda871ba951bbec2706","cc627b7165844858ba0e2fd9e7445bc3","d9505a1988794f04acfe8757cdece3dd","9a0907c447224a18a3b416e34523d1ca","d7946753d7d449d2b82bf99fc25ec240","ede52f275c4545a798012183dc544e5e","21a71ec14ec24001a8c90c9dc20fcfb1","61f9961c17984054a69b0e5b0ade09bb","87bccc17914345149dee7ed7eb018139","6f688b60ed3c498183374005f9cabef4","27340d5ffff24799957fe59e7973c1c8","d09e7686226142e8bde6d16738b727df","003e540fadc3435fb9ea1aef9c582795","66691b19e19b4598841e4b83a2d1377e","a248be62b184450bb7997b9db605e075","e6538ab1d7874a11884f6d7e0cc46fcc","adf6a0c8662a453cbc97ba3e812520ab","b98ce72d99a84cb9b6204f1ce3b061b5","3d83745cf7f04ef39ba08d36ca4e3ad4","9eb0799851ad418688f5cbcd26caee7b","fe31698e0ddb47c7af0ec97679821a7a","3057437b054d4b779cf2dc984529308a","788ca13fed6c42b894b4d25feb75ffd7","57d7a9ae6bfb4d6ea1a36cf9fa995dc1","01d0b3bd6a544db4b449093f6b1697ae","e715c858f2a84940b6f6cd23c9fcc30e","b317e421c256410a9cd81aa8cd549c79","63bfefb8bad94e7eb9db4ac687dcb6b8","4d5f10844502440f9ff496c6334872b3","1fa8067559854650ba726bf502939dea","eb894632c40b4a16a9e94c5d0895761d","d6e77d8854fc4fe3a6abbb99291f4425","ab4908d2b1764b09852124a7173e3f2c","55012f29b0274f148ea5c0d25027c216","80b4d709448449d2bf17a47f0b335973","52a494b693a7435b9aad2bf3429d96a4","31ff893c6d6543a3bcfdc6d3abe2cac7","c599109fc7864dad88ca1b8f6e06cc15","b72d2c668a8f4d6984baef0c6f8901d1","02951eafc1544b1ba39119681744c692","af2c78dd2338485aaaa165a06042cc3b","324e4a822ed14150a6c7666015f0cd8b","84de313911a4453ab3a163c12dd95692","70e19c3bbd86406e9af16832d9f106cf","91ef2e773a7c4a858fecec0e8bdc027c","63ec199feca04b2785ddd9fafe8d1c8f","7595590b5fba4eb5bb0300b8c230d745","d27fbcb8d7b249fabe15433aeac595e9","6778e0889a324aae895431042e2f7079","5fbf5b8b8092419cb1c9386181b3884f","96c6ec6fefb44460a869a978e726ba36","9ddb3737371e470d81832638a6c2325e","cf167b3260a0406782446dac46524248","ae3be152eddc43eeb1a515ce51529662","fa9ad868ed9c4a2ca1bbe0fba8780c02","cad47f631a8f4244beb21d316ae57f81","7078eca031a848088dfbc5febbbedc4f","cd0284d273f1486db1c5c39ab06c0765","5862275f95df433b9e89cfa2fb4c8faf","59549132164a4b0a8bdb0a0b6dec18e8","a395abe100a54ab98e3a367368b04966","42ece18376334992b7d398e51263f195","7589ec5d35174fa39b919e6b129a6253","5f0297f7e34e40ba9cb0b58f61d11693","29e9064263cd41ac8ee8adc2cd04b1c4","c639c58a11be45e18bef8eb6dd29b325","8b62d250845f4ec190168144ea9c7e1a","5bea9229c4b1419289d82957a52ae9d6","b8d0300c5cb84cd6a2260d0444ef8fad","c42ac460d1254cbaac67aaed1db856a1","53e13ffd45774adb88688e795bc50e8d","ae1a04ad00384ab9b51ab77f00a87d10","6157b19cfd9b450081a239ce14d30b9f","2e7f959fcbf247f1ac011fdfd4d1e92b","938286fc091c4384bffd6ea33c1344ad","5dc3f685359d4faa835a94998cfe912a","90ecaae0ef3c4e0a8609c09b3c993eab","5fe35823d14a4807be2dc8d5a3bcf950","7820bf754e8a4dd9b1bf54ae8c86df21","c4999c60af904c7aa60c5bd33a7aad7b","18b75a47e6864b30ac47b17bd0e3aa23","130a7e6663c84fc7b3d16f3a9e8687fd"],"height":0},"id":"k2c1cCUnq_aP","executionInfo":{"status":"ok","timestamp":1647068775995,"user_tz":360,"elapsed":12040,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"cba6d8ca-db36-46e5-fc88-49a376be7628"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/2.28k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4a684e6ba6648ecac5d892c2a57465c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"483e5020da1f4be4abc92aa3b50c2fc8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset ncbi_disease/ncbi_disease (download: 1.47 MiB, generated: 3.04 MiB, post-processed: Unknown size, total: 4.52 MiB) to /root/.cache/huggingface/datasets/ncbi_disease/ncbi_disease/1.0.0/92314c7992b0b8a5ea2ad101be33f365b684a2cc011e0ffa29c691e6d32b2d03...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f8a628530e74ab7b087f02be6ef5df0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/284k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ede52f275c4545a798012183dc544e5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/51.2k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adf6a0c8662a453cbc97ba3e812520ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/52.4k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63bfefb8bad94e7eb9db4ac687dcb6b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b72d2c668a8f4d6984baef0c6f8901d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fbf5b8b8092419cb1c9386181b3884f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a395abe100a54ab98e3a367368b04966"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae1a04ad00384ab9b51ab77f00a87d10"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset ncbi_disease downloaded and prepared to /root/.cache/huggingface/datasets/ncbi_disease/ncbi_disease/1.0.0/92314c7992b0b8a5ea2ad101be33f365b684a2cc011e0ffa29c691e6d32b2d03. Subsequent calls will reuse this data.\n"]},{"output_type":"stream","name":"stderr","text":["Reusing dataset ncbi_disease (/root/.cache/huggingface/datasets/ncbi_disease/ncbi_disease/1.0.0/92314c7992b0b8a5ea2ad101be33f365b684a2cc011e0ffa29c691e6d32b2d03)\n","Reusing dataset ncbi_disease (/root/.cache/huggingface/datasets/ncbi_disease/ncbi_disease/1.0.0/92314c7992b0b8a5ea2ad101be33f365b684a2cc011e0ffa29c691e6d32b2d03)\n"]}]},{"cell_type":"code","source":["train[2739]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nFPiiZ7vq_Vq","executionInfo":{"status":"ok","timestamp":1647068775996,"user_tz":360,"elapsed":7,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"0f2d64ce-e789-4cbf-bd12-ee64f9e1fbbb"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n"," 'input_ids': [tensor([  102,   407,   453,  3768,   198,   158,   546,  1211,   259,  1168,\n","           4662,   115, 30132,  7411,   165,  3111,   214,   106,  2317,   579,\n","           2971,  2147,  6110,  7459,   198,  4080, 24241,  5354,   131, 10906,\n","            370,   781,  2980, 13718,   422,  2429,   121,  3014,   131,   106,\n","          12462, 11458, 13348,   422,   170,   546,   111,  2317,   579,  2971,\n","           2147,  7459,   121,   111,  1211,   259,   115, 30132, 30147, 30131,\n","            983,   165,  3974,  1111,   190,   111,  9995, 16147,  1352,  5255,\n","           2665,   106,  1678,   422,   132,  1828,   422,   115, 30132, 30147,\n","          30131,   422, 11412, 30113,   422,   115, 30140, 30110, 30140,   422,\n","            115, 30140, 30125, 30132,   422,   741, 30128, 30132,   422,  3849,\n","            198,   355,   115, 30132,   579, 13869,  2374,   190,   238, 16147,\n","           1352,  5255,  2665,   650, 14480,   111,  2317,   579,  2971,  2147,\n","            115, 30132,   983,  7459,   422,   137,   239,   546,  1211,  1264,\n","            115, 30132,  7411,   165,  3111,   214,   106,   643,   422,   188,\n","           3481,  9508,  4522,  1669, 17000,  1581,   422,  2271,  2576,  7465,\n","            205,   205,   103,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0])],\n"," 'labels': tensor([   0.,    0.,    0.,    0.,    0.,    0.,    0.,    1.,    2.,    2.,\n","            2.,    2.,    2.,    2.,    0.,    0.,    0.,    0.,    0.,    0.,\n","            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","            0.,    0.,    1.,    1.,    2.,    2.,    0.,    0.,    0.,    0.,\n","            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    1.,    2.,\n","            2.,    2.,    2.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    1.,    2.,\n","            0.,    0.,    0., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.],\n","        dtype=torch.float64)}"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["local_hp_train = []\n","local_hp_val = []\n","for x in range(500):\n","  local_hp_train.append(train[x])\n","\n","for x in range(180):\n","  local_hp_val.append(val[x])\n","\n","print(len(local_hp_train))\n","print(local_hp_train[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"puC_JdGDeRkD","executionInfo":{"status":"ok","timestamp":1647068788319,"user_tz":360,"elapsed":12327,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"ad8d2828-afc7-4c80-86e7-8ed6ed619f09"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["500\n","{'input_ids': [tensor([  102,   111, 24243,   861,   153,  7503,  1070,  5703,   145, 16036,\n","          546,  7421,   579, 14957,   787,  3151,   111, 12157, 10636,  3430,\n","          214,  8437,   106,  1127,   190, 18260, 12242,  4655,   239, 12186,\n","          145, 20362,   579,   239, 12186,   546,   422, 10361, 30111,  1352,\n","         6030,   107,   137,  6130, 14025,   205,   103,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])], 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])], 'labels': tensor([   0.,    0.,    1.,    1.,    1.,    2.,    2.,    2.,    2.,    2.,\n","           2.,    2.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","           0.,    0.,    0.,    0.,    0.,    0.,    0., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.],\n","       dtype=torch.float64)}\n"]}]},{"cell_type":"markdown","metadata":{"id":"oGYV8ipcJ5fU"},"source":["# Pytorch Model Definition"]},{"cell_type":"code","metadata":{"id":"eFp2ZFd25KwK","executionInfo":{"status":"ok","timestamp":1647068788319,"user_tz":360,"elapsed":5,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"source":["class NerModel(nn.Module):\n","  def __init__(self, b_embeddings, emb_dims=768, ff_dims=14, out_dims=3):\n","    super(NerModel, self).__init__()\n","    self.sci_embeddings = b_embeddings\n","    self.embd_dropout = nn.Dropout(0.1)\n","    self.ff_dropout = nn.Dropout(0.1)\n","    self.ff = nn.Linear(emb_dims, ff_dims)\n","    self.tanh = nn.Tanh()\n","    self.lstm = nn.LSTM(768, 100, 1, bidirectional=True)\n","    self.lstm_drop = nn.Dropout(0.4)\n","    self.ff = nn.Linear(200, 14)\n","    self.ff_act = nn.ReLU()\n","    self.classifier = nn.Linear(ff_dims, out_dims)\n","  def forward(self, **inputs):\n","    embds = self.sci_embeddings(**inputs)['last_hidden_state']\n","    out = self.embd_dropout(embds)\n","    out, _ = self.lstm(out)\n","    out = self.tanh(out)\n","    out = self.lstm_drop(out)\n","    out = self.ff(out)\n","    out = self.ff_act(out)\n","    out = self.ff_dropout(out)\n","    out = self.classifier(out)\n","    return out\n"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7LthVVOhx_Sz"},"source":["# Metrics and Configs"]},{"cell_type":"code","metadata":{"id":"VZJjqYf2AKA8","executionInfo":{"status":"ok","timestamp":1647068788320,"user_tz":360,"elapsed":5,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"source":["def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    #print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","\n","import math\n","\n","def load_param():\n","  for n, v in best_run.hyperparameters.items():\n","    if n == 'seed':\n","      setattr(trainer.args, n, math.ceil(v))\n","      print(n, math.ceil(v))\n","    else:\n","      setattr(trainer.args, n, v)\n","      print(n, v)   "],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"qjMXqFluyLCW","executionInfo":{"status":"ok","timestamp":1647068788598,"user_tz":360,"elapsed":282,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"source":["batch_size = 4\n","training_args = TrainingArguments(\n","    \"trained_scibert_ner_model\", # output dir\n","    learning_rate=1e-5, \n","    num_train_epochs=10, \n","    dataloader_drop_last=True,\n","    per_device_eval_batch_size=batch_size, \n","    per_device_train_batch_size=batch_size,\n","    save_steps=len(train) // batch_size,\n","    lr_scheduler_type='cosine',\n","    evaluation_strategy='steps',\n","    eval_steps=len(train) // batch_size\n","    )\n","#print(training_args)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"fabdHzMRybBR","executionInfo":{"status":"ok","timestamp":1647068788599,"user_tz":360,"elapsed":7,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"source":["def collator(batch):\n","  out =  {\n","      'input_ids': torch.stack([(x['input_ids'][0]) for x in batch]),\n","      'attention_mask': torch.stack([x['attention_mask'][0] for x in batch]),\n","      'labels': torch.stack([x['labels'].clone().detach() for x in batch])\n","  }\n","  return out"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"dZluJPsy2eb5","executionInfo":{"status":"ok","timestamp":1647068788600,"user_tz":360,"elapsed":7,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"source":["import torch.nn.functional as F\n","\n","class FocalLoss(nn.modules.loss._WeightedLoss):\n","    def __init__(self, weight, gamma, reduction='mean'):\n","        super(FocalLoss, self).__init__(weight,reduction=reduction)\n","        self.gamma = gamma\n","        self.weight = weight #weight parameter will act as the alpha parameter to balance class weights\n","\n","    def forward(self, input, target):\n","        ce_loss = F.cross_entropy(input, target, ignore_index=-100, reduction=self.reduction, weight=self.weight)\n","        pt = torch.exp(-ce_loss)\n","        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n","        return focal_loss"],"execution_count":15,"outputs":[]},{"cell_type":"code","execution_count":16,"metadata":{"id":"QLbpwNckLvV6","executionInfo":{"status":"ok","timestamp":1647068788816,"user_tz":360,"elapsed":221,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"outputs":[],"source":["class MultilabelTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False, num_labels=3):\n","        labels = inputs.pop(\"labels\")\n","        outputs = model(**inputs)\n","        logits = outputs\n","\n","        weights = torch.tensor([0.38, 1.65, 1.5]).cuda()  # The no-class label has too many examples, we need to weight the loss - this probably needs further tuning\n","        gamma=5\n","        loss_fct = FocalLoss(weight=weights, gamma=gamma)\n","        loss = loss_fct(logits.view(-1, num_labels), labels.long().view(-1))\n","        return (loss, outputs) if return_outputs else loss\n","\n","    def evaluation_loop(self, dataloader, description, prediction_loss_only=None, ignore_keys=None, metric_key_prefix=\"eval\", num_labels=4):\n","      args = self.args\n","      prediction_loss_only = prediction_loss_only if prediction_loss_only is not None else args.prediction_loss_only\n","\n","      self.model.eval()\n","\n","      all_losses = []\n","      all_preds = []\n","      all_labels = []\n","      for step, sample in enumerate(dataloader):\n","        for i in range(0, len(sample['labels'])):\n","          inputs = {}\n","          inputs['input_ids'] = torch.stack([sample['input_ids'][i].cuda()])\n","          inputs['attention_mask'] = torch.stack([sample['attention_mask'][i].cuda()])\n","          inputs['labels'] = torch.stack([sample['labels'][i].cuda()])\n","          labels = inputs['labels'][0].cpu().numpy()\n","          \n","          (loss, logits) = self.compute_loss(self.model, inputs, return_outputs=True)\n","          logits = logits[0].cpu().detach().numpy()\n","          preds = np.argmax(nn.Softmax(dim=-1)(torch.tensor(logits)).numpy(), axis=-1)\n","\n","          all_losses = np.concatenate((all_losses, [loss.detach().cpu().numpy()]), axis=0)\n","\n","          preds = preds[labels != -100]\n","          labels = labels[labels != -100]\n","          all_preds = np.concatenate((all_preds, preds))\n","          all_labels = np.concatenate((all_labels, labels))\n","\n","      metrics = {}\n","      metrics['macro_f1'] = f1_score(all_labels, all_preds, average='macro')\n","      metrics['macro_precision'] = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n","      metrics['macro_recall'] = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n","      metrics['micro_f1'] = f1_score(all_labels, all_preds, average='micro')\n","      metrics['micro_precision'] = precision_score(all_labels, all_preds, average='micro', zero_division=0)\n","      metrics['micro_recall'] = recall_score(all_labels, all_preds, average='micro', zero_division=0)\n","\n","      metrics['macro_f1_no_o'] = f1_score(all_labels, all_preds, average='macro', labels=[1, 2])\n","      metrics['macro_precision_no_o'] = precision_score(all_labels, all_preds, average='macro', labels=[1, 2], zero_division=0)\n","      metrics['macro_recall_no_o'] = recall_score(all_labels, all_preds, average='macro', labels=[1, 2], zero_division=0)\n","      metrics['micro_f1_no_o'] = f1_score(all_labels, all_preds, average='micro', labels=[1, 2])\n","      metrics['micro_precision_no_o'] = precision_score(all_labels, all_preds, average='micro', labels=[1, 2], zero_division=0)\n","      metrics['micro_recall_no_o'] = recall_score(all_labels, all_preds, average='micro', labels=[1, 2], zero_division=0)\n","\n","      for key in list(metrics.keys()):\n","        if not key.startswith(metric_key_prefix):\n","          metrics[metric_key_prefix + '_' + key] = metrics.pop(key)\n","      \n","      metrics[metric_key_prefix + '_loss'] = all_losses.mean().item()\n","\n","      return EvalLoopOutput(predictions=all_preds, label_ids=all_labels, metrics=metrics, num_samples=len(dataloader))"]},{"cell_type":"code","metadata":{"id":"infNapI_OmFr","executionInfo":{"status":"ok","timestamp":1647068788816,"user_tz":360,"elapsed":4,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"source":["def my_hp_space_ray(trial):\n","    from ray import tune\n","\n","    return {\n","        \"learning_rate\": tune.loguniform(1e-6, 1e-4),\n","        \"num_train_epochs\": tune.choice(range(8, 20)),\n","        \"weight_decay\": tune.uniform(0.0, 0.5),\n","        \"per_device_train_batch_size\": tune.choice([4, 8, 16]),  #<16 definetly not working\n","    }"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Nh8Lcpvb_F4"},"source":["# Hyperparameter Tuning"]},{"cell_type":"code","metadata":{"id":"w6AqbEPyPK7O"},"source":["def model_init():\n","    x = NerModel(BertEmbModel)\n","    x.sci_embeddings.requires_grad = False\n","    return x\n","\n","trainer = MultilabelTrainer(model_init=model_init,\n","                            args=training_args,\n","                            train_dataset=train,\n","                            eval_dataset=val,\n","                            data_collator=collator  # defines how to merge data into batches, using the collator function above\n","                            )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IGyHLY640NRz","colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1jQoaimRV1z4LN9U20PugP-ajijfTt-G2"},"executionInfo":{"status":"ok","timestamp":1645161901506,"user_tz":360,"elapsed":5459737,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"b6a9b604-6db3-4fcd-9f32-823c4b1d3fd0"},"source":["from ray.tune.suggest.hyperopt import HyperOptSearch\n","from ray.tune.schedulers import ASHAScheduler\n","\n","best_run = trainer.hyperparameter_search(backend=\"ray\", \n","                                         resources_per_trial={\"gpu\": 1, \"cpu\": 0},\n","                                         n_trials=16, \n","                                         direction=\"maximize\", \n","                                         hp_space=my_hp_space_ray,\n","                                         search_alg=HyperOptSearch(metric='eval_micro_recall_no_o', mode=\"max\"),  #'eval_*f1_micro'\n","                                         scheduler=ASHAScheduler(metric='eval_micro_recall_no_o', mode=\"max\")\n","                                         )"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zH0H8agAbzZi","executionInfo":{"status":"ok","timestamp":1645161902962,"user_tz":360,"elapsed":1,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"58d0318a-e848-4bde-969b-2c2262143fe9"},"source":["best_run"],"execution_count":null,"outputs":[{"data":{"text/plain":["BestRun(run_id='220b1c42', objective=11.083303124175789, hyperparameters={'learning_rate': 1.5441110254159498e-05, 'num_train_epochs': 12, 'weight_decay': 0.21467682833420043, 'per_device_train_batch_size': 16})"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"kv6pGzbGpv2D"},"source":["# Cossvalidation"]},{"cell_type":"code","metadata":{"id":"LhipElJSzRUF"},"source":["#import tensorflow as tf\n","from torch.utils.data import DataLoader, ConcatDataset\n","from sklearn.model_selection import KFold\n","from torch import nn\n","from transformers import Trainer\n","\n","#print('GPU detected:', tf.config.list_physical_devices('GPU'))\n","k_folds = 5\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","results = np.zeros(5)\n","resultss = np.zeros(5)\n","dataset = ConcatDataset([train, test])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"zQyLOxyMjZq2","executionInfo":{"status":"ok","timestamp":1646877687899,"user_tz":360,"elapsed":6568348,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"c01c3a9c-0d1b-43df-9b63-6feb02d9e661"},"source":["for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    #train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    #test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    local_train = []\n","    i = 0\n","    for idx in train_ids:\n","      #if i <= 1920:\n","      local_train.append(dataset[idx])\n","      #i += 1\n","    \n","    local_test = []\n","    i = 0\n","    for idx in test_ids:\n","      #if i <= 480:\n","      local_test.append(dataset[idx])\n","      #i += 1\n","\n","    training_args = TrainingArguments(\"trained_scibert_ner_model\", # output dir\n","                                      learning_rate=1.5441110254159498e-05, \n","                                      weight_decay=0.21467682833420043,\n","                                      num_train_epochs=12, \n","                                      dataloader_drop_last=True,\n","                                      per_device_eval_batch_size=16, \n","                                      per_device_train_batch_size=16,\n","                                      logging_steps=50,\n","                                      save_steps=len(local_train) // batch_size,\n","                                      lr_scheduler_type='cosine',\n","                                      evaluation_strategy='steps',\n","                                      eval_steps=len(local_train) // batch_size\n","                                      )\n","\n","    #learning_rate 1.5441110254159498e-05\n","    #num_train_epochs 12\n","    #weight_decay 0.21467682833420043\n","    #per_device_train_batch_size 16\n","\n","\n","    # Init the neural network\n","    ner_model = NerModel(BertEmbModel).to('cuda')  # make sure we move the model to the GPU for training\n","    \n","    trainer = MultilabelTrainer(model=ner_model,\n","                                args=training_args,\n","                                train_dataset=local_train,\n","                                eval_dataset=local_test,\n","                                data_collator=collator  # defines how to merge data into batches, using the collator function above\n","                                )\n","\n","    #Loading Best parameters\n","    #load_param()\n","\n","    #Training\n","    trainer.train()\n","          \n","    # Process is complete.\n","    print('Training process has finished. Saving trained model.')\n","\n","    # Print about testing\n","    print('Starting testing')\n","    \n","    # Saving the model\n","    save_path = f'./model-fold-{fold}.pth'\n","    torch.save(ner_model.state_dict(), save_path)\n","\n","    # Evaluationfor this fold\n","    #correct, total = 0, 0\n","    with torch.no_grad():\n","      result = trainer.evaluate(local_test)\n","      print(result)\n","\n","      # Print accuracy\n","      print('Accuracy for fold ', fold, ': ', result['eval_micro_f1_no_o'], ' -- ', result['eval_micro_f1'])\n","      print('--------------------------------')\n","      results[fold] = result['eval_micro_f1_no_o']\n","      resultss[fold] = result['eval_micro_f1']\n","      del result\n","    \n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FOLD 0\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 5099\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3816\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3816' max='3816' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3816/3816 20:27, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1274</td>\n","      <td>0.000300</td>\n","      <td>0.003145</td>\n","      <td>0.926424</td>\n","      <td>0.903547</td>\n","      <td>0.951544</td>\n","      <td>0.980652</td>\n","      <td>0.980652</td>\n","      <td>0.980652</td>\n","      <td>0.894280</td>\n","      <td>0.857466</td>\n","      <td>0.934433</td>\n","      <td>0.894385</td>\n","      <td>0.857482</td>\n","      <td>0.934608</td>\n","    </tr>\n","    <tr>\n","      <td>2548</td>\n","      <td>0.000200</td>\n","      <td>0.002869</td>\n","      <td>0.928672</td>\n","      <td>0.902786</td>\n","      <td>0.957426</td>\n","      <td>0.981066</td>\n","      <td>0.981066</td>\n","      <td>0.981066</td>\n","      <td>0.897583</td>\n","      <td>0.855906</td>\n","      <td>0.943529</td>\n","      <td>0.897713</td>\n","      <td>0.856038</td>\n","      <td>0.943655</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-1274\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2548\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.9325631445862216, 'eval_macro_precision': 0.9107833604368422, 'eval_macro_recall': 0.9563230269998023, 'eval_micro_f1': 0.9824090098933175, 'eval_micro_precision': 0.9824090098933175, 'eval_micro_recall': 0.9824090098933175, 'eval_macro_f1_no_o': 0.903032828696872, 'eval_macro_precision_no_o': 0.8680290920472502, 'eval_macro_recall_no_o': 0.9409849422905425, 'eval_micro_f1_no_o': 0.903137789904502, 'eval_micro_precision_no_o': 0.8681449690033382, 'eval_micro_recall_no_o': 0.9410700439390023, 'eval_loss': 0.0029756858960302487, 'eval_runtime': 12.3913, 'eval_samples_per_second': 6.375, 'eval_steps_per_second': 0.404, 'epoch': 12.0}\n","Accuracy for fold  0 :  0.903137789904502  --  0.9824090098933175\n","--------------------------------\n","FOLD 1\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 5099\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3816\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3816' max='3816' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3816/3816 20:28, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1274</td>\n","      <td>0.000200</td>\n","      <td>0.001708</td>\n","      <td>0.965877</td>\n","      <td>0.948189</td>\n","      <td>0.984772</td>\n","      <td>0.990646</td>\n","      <td>0.990646</td>\n","      <td>0.990646</td>\n","      <td>0.951157</td>\n","      <td>0.922817</td>\n","      <td>0.981293</td>\n","      <td>0.950940</td>\n","      <td>0.922567</td>\n","      <td>0.981113</td>\n","    </tr>\n","    <tr>\n","      <td>2548</td>\n","      <td>0.000100</td>\n","      <td>0.001742</td>\n","      <td>0.968235</td>\n","      <td>0.952631</td>\n","      <td>0.984773</td>\n","      <td>0.991365</td>\n","      <td>0.991365</td>\n","      <td>0.991365</td>\n","      <td>0.954484</td>\n","      <td>0.929494</td>\n","      <td>0.980865</td>\n","      <td>0.954061</td>\n","      <td>0.928912</td>\n","      <td>0.980609</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-1274\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2548\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.968760860907493, 'eval_macro_precision': 0.9534841509813252, 'eval_macro_recall': 0.9849404233362032, 'eval_micro_f1': 0.9914938452445198, 'eval_micro_precision': 0.9914938452445198, 'eval_micro_recall': 0.9914938452445198, 'eval_macro_f1_no_o': 0.955244152113102, 'eval_macro_precision_no_o': 0.9307733826994896, 'eval_macro_recall_no_o': 0.9810595389021928, 'eval_micro_f1_no_o': 0.9547738693467337, 'eval_micro_precision_no_o': 0.9300382043935053, 'eval_micro_recall_no_o': 0.9808612440191388, 'eval_loss': 0.0017366195318348368, 'eval_runtime': 12.3603, 'eval_samples_per_second': 6.391, 'eval_steps_per_second': 0.405, 'epoch': 12.0}\n","Accuracy for fold  1 :  0.9547738693467337  --  0.9914938452445198\n","--------------------------------\n","FOLD 2\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 5099\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3816\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3816' max='3816' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3816/3816 20:28, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1274</td>\n","      <td>0.000000</td>\n","      <td>0.000344</td>\n","      <td>0.969988</td>\n","      <td>0.951171</td>\n","      <td>0.990203</td>\n","      <td>0.992011</td>\n","      <td>0.992011</td>\n","      <td>0.992011</td>\n","      <td>0.957002</td>\n","      <td>0.926960</td>\n","      <td>0.989126</td>\n","      <td>0.957114</td>\n","      <td>0.927345</td>\n","      <td>0.988856</td>\n","    </tr>\n","    <tr>\n","      <td>2548</td>\n","      <td>0.000000</td>\n","      <td>0.000339</td>\n","      <td>0.976673</td>\n","      <td>0.963901</td>\n","      <td>0.990046</td>\n","      <td>0.993891</td>\n","      <td>0.993891</td>\n","      <td>0.993891</td>\n","      <td>0.966518</td>\n","      <td>0.946157</td>\n","      <td>0.987776</td>\n","      <td>0.966251</td>\n","      <td>0.945870</td>\n","      <td>0.987530</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-1274\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2548\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.9766921525807302, 'eval_macro_precision': 0.9644121104978769, 'eval_macro_recall': 0.9895298083112799, 'eval_micro_f1': 0.9938908179515965, 'eval_micro_precision': 0.9938908179515965, 'eval_micro_recall': 0.9938908179515965, 'eval_macro_f1_no_o': 0.9665474875928691, 'eval_macro_precision_no_o': 0.9469672668115736, 'eval_macro_recall_no_o': 0.9869587537016453, 'eval_micro_f1_no_o': 0.9662249935048064, 'eval_micro_precision_no_o': 0.9465512853143293, 'eval_micro_recall_no_o': 0.9867338816662244, 'eval_loss': 0.000351153266536215, 'eval_runtime': 12.3665, 'eval_samples_per_second': 6.388, 'eval_steps_per_second': 0.404, 'epoch': 12.0}\n","Accuracy for fold  2 :  0.9662249935048064  --  0.9938908179515965\n","--------------------------------\n","FOLD 3\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 5099\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3816\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3816' max='3816' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3816/3816 20:28, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1274</td>\n","      <td>0.000000</td>\n","      <td>0.000485</td>\n","      <td>0.983772</td>\n","      <td>0.973200</td>\n","      <td>0.994758</td>\n","      <td>0.995578</td>\n","      <td>0.995578</td>\n","      <td>0.995578</td>\n","      <td>0.976774</td>\n","      <td>0.959890</td>\n","      <td>0.994276</td>\n","      <td>0.977014</td>\n","      <td>0.960278</td>\n","      <td>0.994344</td>\n","    </tr>\n","    <tr>\n","      <td>2548</td>\n","      <td>0.000000</td>\n","      <td>0.000513</td>\n","      <td>0.985454</td>\n","      <td>0.975958</td>\n","      <td>0.995276</td>\n","      <td>0.996031</td>\n","      <td>0.996031</td>\n","      <td>0.996031</td>\n","      <td>0.979179</td>\n","      <td>0.964012</td>\n","      <td>0.994831</td>\n","      <td>0.979251</td>\n","      <td>0.964126</td>\n","      <td>0.994859</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-1274\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2548\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.9862113084012171, 'eval_macro_precision': 0.9771879490731076, 'eval_macro_recall': 0.995530326639846, 'eval_micro_f1': 0.9962438062763067, 'eval_micro_precision': 0.9962438062763067, 'eval_micro_recall': 0.9962438062763067, 'eval_macro_f1_no_o': 0.980262198464223, 'eval_macro_precision_no_o': 0.9658564814814814, 'eval_macro_recall_no_o': 0.9951083763125983, 'eval_micro_f1_no_o': 0.9803722932759275, 'eval_micro_precision_no_o': 0.9660593960569004, 'eval_micro_recall_no_o': 0.9951156812339331, 'eval_loss': 0.0005189194556308687, 'eval_runtime': 12.3351, 'eval_samples_per_second': 6.404, 'eval_steps_per_second': 0.405, 'epoch': 12.0}\n","Accuracy for fold  3 :  0.9803722932759275  --  0.9962438062763067\n","--------------------------------\n","FOLD 4\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 5100\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3816\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3816' max='3816' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3816/3816 20:28, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1275</td>\n","      <td>0.000000</td>\n","      <td>0.000276</td>\n","      <td>0.978854</td>\n","      <td>0.964086</td>\n","      <td>0.994455</td>\n","      <td>0.993818</td>\n","      <td>0.993818</td>\n","      <td>0.993818</td>\n","      <td>0.969919</td>\n","      <td>0.946245</td>\n","      <td>0.994832</td>\n","      <td>0.969792</td>\n","      <td>0.945997</td>\n","      <td>0.994815</td>\n","    </tr>\n","    <tr>\n","      <td>2550</td>\n","      <td>0.000000</td>\n","      <td>0.000160</td>\n","      <td>0.983894</td>\n","      <td>0.973190</td>\n","      <td>0.995026</td>\n","      <td>0.995351</td>\n","      <td>0.995351</td>\n","      <td>0.995351</td>\n","      <td>0.977063</td>\n","      <td>0.959931</td>\n","      <td>0.994832</td>\n","      <td>0.976964</td>\n","      <td>0.959743</td>\n","      <td>0.994815</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-1275\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2550\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.9849622877508016, 'eval_macro_precision': 0.9749987272480424, 'eval_macro_recall': 0.9952920048021866, 'eval_micro_f1': 0.995636476974624, 'eval_micro_precision': 0.995636476974624, 'eval_micro_recall': 0.995636476974624, 'eval_macro_f1_no_o': 0.9785995430200802, 'eval_macro_precision_no_o': 0.9626583753040737, 'eval_macro_recall_no_o': 0.995085985491283, 'eval_micro_f1_no_o': 0.9785115940269516, 'eval_micro_precision_no_o': 0.9625029854310962, 'eval_micro_recall_no_o': 0.9950617283950617, 'eval_loss': 0.0001586702746783862, 'eval_runtime': 12.3555, 'eval_samples_per_second': 6.394, 'eval_steps_per_second': 0.405, 'epoch': 12.0}\n","Accuracy for fold  4 :  0.9785115940269516  --  0.995636476974624\n","--------------------------------\n"]}]},{"cell_type":"markdown","metadata":{"id":"BBA4owXH8oS1"},"source":["# Results"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dhusoblW-oCA","executionInfo":{"status":"ok","timestamp":1646877687900,"user_tz":360,"elapsed":7,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"33f145ae-e20c-459a-bec8-b03a60b66ecd"},"source":["results"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.90313779, 0.95477387, 0.96622499, 0.98037229, 0.97851159])"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["resultss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ryi6TlOOQaTE","executionInfo":{"status":"ok","timestamp":1646877687900,"user_tz":360,"elapsed":5,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"5c75edfc-3dfd-4487-b5eb-3c1d64944899"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.98240901, 0.99149385, 0.99389082, 0.99624381, 0.99563648])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yPIH-gt_-foF","executionInfo":{"status":"ok","timestamp":1646877687900,"user_tz":360,"elapsed":5,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"e1d80bde-a2cf-470b-a8d2-dd52d030538a"},"source":["# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","key = 0\n","for value in results:\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","  key += 1\n","print(f'Average: {sum/len(results)} %')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n","--------------------------------\n","Fold 0: 0.903137789904502 %\n","Fold 1: 0.9547738693467337 %\n","Fold 2: 0.9662249935048064 %\n","Fold 3: 0.9803722932759275 %\n","Fold 4: 0.9785115940269516 %\n","Average: 0.9566041080117843 %\n"]}]},{"cell_type":"markdown","metadata":{"id":"1DkDHptAhniL"},"source":["# Pytorch Training - Loop UPDT"]},{"cell_type":"code","metadata":{"id":"rirS-e83GVn0","executionInfo":{"status":"ok","timestamp":1647068788817,"user_tz":360,"elapsed":4,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"source":["device = 'cuda'"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"KSDdzo_so0vk","executionInfo":{"status":"ok","timestamp":1647068788817,"user_tz":360,"elapsed":4,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"source":["training_args = TrainingArguments(\"trained_scibert_ner_model\", # output dir\n","                                      learning_rate=1.5441110254159498e-05, \n","                                      num_train_epochs=12, \n","                                      dataloader_drop_last=True,\n","                                      per_device_eval_batch_size=16, \n","                                      per_device_train_batch_size=16,\n","                                      logging_steps=50,\n","                                      save_steps=len(train) // batch_size,\n","                                      lr_scheduler_type='cosine',\n","                                      evaluation_strategy='steps',\n","                                      weight_decay=0.21467682833420043,\n","                                      eval_steps=len(train) // batch_size,\n","                                      report_to='all'\n","                                      )\n","                                      \n","#learning_rate 1.5441110254159498e-05\n","#num_train_epochs 12\n","#weight_decay 0.21467682833420043\n","#per_device_train_batch_size 16\n","\n","#load_param()"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"fdde459a-edf4-45c8-9cdc-56285c6dcdf6","id":"nZR3aDuKyUqy","executionInfo":{"status":"ok","timestamp":1647090131288,"user_tz":360,"elapsed":21342474,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"source":["loop_val = 10\n","loop_results = np.zeros(loop_val)\n","loop_resultss = np.zeros(loop_val)\n","for r in range(loop_val):\n","\n","  ner_model = NerModel(BertEmbModel).to('cuda')  # make sure we move the model to the GPU for training\n","\n","  trainer = MultilabelTrainer(\n","      model=ner_model, \n","      args=training_args, \n","      train_dataset=train, \n","      eval_dataset=test,\n","      data_collator=collator  # defines how to merge data into batches, using the collator function above\n","  )\n","\n","  # Print\n","  print(f'Train run #{r}')\n","  print('--------------------------------')\n","\n","  trainer.train()\n","\n","  # Process is complete.\n","  print('Training process has finished.')\n","\n","  # Print about testing\n","  print('Starting testing')\n","\n","  with torch.no_grad():\n","    result = trainer.evaluate(test)\n","    print(result)\n","\n","    # Print accuracy\n","    print('Accuracy for fold ', r, ': ', result['eval_micro_f1_no_o'], ' -- ', result['eval_micro_f1'])\n","    print('--------------------------------')\n","    loop_results[r] = result['eval_micro_f1_no_o']\n","    loop_resultss[r] = result['eval_micro_f1']\n","    del result\n","\n","  if r > 0:\n","    if loop_results[r] < loop_results[r-1]:\n","      save_path = f'./model-fold-{r}.pth'\n","      torch.save(ner_model.state_dict(), save_path)\n","\n","  print('Testing process has finished.')"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 5433\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4068\n"]},{"output_type":"stream","name":"stdout","text":["Train run #0\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4068' max='4068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4068/4068 30:41, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1358</td>\n","      <td>0.000300</td>\n","      <td>0.001902</td>\n","      <td>0.911166</td>\n","      <td>0.877109</td>\n","      <td>0.951014</td>\n","      <td>0.976231</td>\n","      <td>0.976231</td>\n","      <td>0.976231</td>\n","      <td>0.872390</td>\n","      <td>0.817200</td>\n","      <td>0.936201</td>\n","      <td>0.872001</td>\n","      <td>0.815908</td>\n","      <td>0.936376</td>\n","    </tr>\n","    <tr>\n","      <td>2716</td>\n","      <td>0.000100</td>\n","      <td>0.001757</td>\n","      <td>0.918757</td>\n","      <td>0.893048</td>\n","      <td>0.947419</td>\n","      <td>0.978814</td>\n","      <td>0.978814</td>\n","      <td>0.978814</td>\n","      <td>0.883128</td>\n","      <td>0.841701</td>\n","      <td>0.928953</td>\n","      <td>0.883117</td>\n","      <td>0.841742</td>\n","      <td>0.928769</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-1358\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2716\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 5433\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4068\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_macro_f1': 0.9207029810944589, 'eval_macro_precision': 0.892911291366021, 'eval_macro_recall': 0.9519239295296623, 'eval_micro_f1': 0.979296565503462, 'eval_micro_precision': 0.979296565503462, 'eval_micro_recall': 0.979296565503462, 'eval_macro_f1_no_o': 0.8859150079369011, 'eval_macro_precision_no_o': 0.841110312223369, 'eval_macro_recall_no_o': 0.9358248314334153, 'eval_micro_f1_no_o': 0.8859060402684564, 'eval_micro_precision_no_o': 0.841156356854212, 'eval_micro_recall_no_o': 0.9356846473029046, 'eval_loss': 0.001608610278724192, 'eval_runtime': 19.4965, 'eval_samples_per_second': 2.975, 'eval_steps_per_second': 0.205, 'epoch': 12.0}\n","Accuracy for fold  0 :  0.8859060402684564  --  0.979296565503462\n","--------------------------------\n","Testing process has finished.\n","Train run #1\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4068' max='4068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4068/4068 27:23, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1358</td>\n","      <td>0.000100</td>\n","      <td>0.001528</td>\n","      <td>0.920913</td>\n","      <td>0.888043</td>\n","      <td>0.958676</td>\n","      <td>0.978987</td>\n","      <td>0.978987</td>\n","      <td>0.978987</td>\n","      <td>0.886352</td>\n","      <td>0.833249</td>\n","      <td>0.946738</td>\n","      <td>0.886228</td>\n","      <td>0.832978</td>\n","      <td>0.946750</td>\n","    </tr>\n","    <tr>\n","      <td>2716</td>\n","      <td>0.000000</td>\n","      <td>0.001559</td>\n","      <td>0.925165</td>\n","      <td>0.899996</td>\n","      <td>0.953189</td>\n","      <td>0.980985</td>\n","      <td>0.980985</td>\n","      <td>0.980985</td>\n","      <td>0.892057</td>\n","      <td>0.851504</td>\n","      <td>0.936861</td>\n","      <td>0.892034</td>\n","      <td>0.851131</td>\n","      <td>0.937068</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-1358\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2716\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 5433\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4068\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_macro_f1': 0.9250528728926132, 'eval_macro_precision': 0.8993292437616277, 'eval_macro_recall': 0.9536494736472071, 'eval_micro_f1': 0.9808811877777395, 'eval_micro_precision': 0.9808811877777395, 'eval_micro_recall': 0.9808811877777395, 'eval_macro_f1_no_o': 0.8919370060124484, 'eval_macro_precision_no_o': 0.8505031535681383, 'eval_macro_recall_no_o': 0.9376479488493545, 'eval_micro_f1_no_o': 0.8919585594474594, 'eval_micro_precision_no_o': 0.8504233301975541, 'eval_micro_recall_no_o': 0.9377593360995851, 'eval_loss': 0.0014115568777344442, 'eval_runtime': 17.3917, 'eval_samples_per_second': 3.335, 'eval_steps_per_second': 0.23, 'epoch': 12.0}\n","Accuracy for fold  1 :  0.8919585594474594  --  0.9808811877777395\n","--------------------------------\n","Testing process has finished.\n","Train run #2\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4068' max='4068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4068/4068 27:58, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1358</td>\n","      <td>0.000000</td>\n","      <td>0.001932</td>\n","      <td>0.925218</td>\n","      <td>0.901425</td>\n","      <td>0.951437</td>\n","      <td>0.980847</td>\n","      <td>0.980847</td>\n","      <td>0.980847</td>\n","      <td>0.892250</td>\n","      <td>0.853954</td>\n","      <td>0.934157</td>\n","      <td>0.892338</td>\n","      <td>0.853982</td>\n","      <td>0.934302</td>\n","    </tr>\n","    <tr>\n","      <td>2716</td>\n","      <td>0.000000</td>\n","      <td>0.001551</td>\n","      <td>0.923904</td>\n","      <td>0.901454</td>\n","      <td>0.948519</td>\n","      <td>0.980778</td>\n","      <td>0.980778</td>\n","      <td>0.980778</td>\n","      <td>0.890210</td>\n","      <td>0.854094</td>\n","      <td>0.929550</td>\n","      <td>0.890214</td>\n","      <td>0.854147</td>\n","      <td>0.929461</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-1358\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2716\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 5433\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4068\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_macro_f1': 0.9268551997654898, 'eval_macro_precision': 0.9074602212886669, 'eval_macro_recall': 0.9478247362042721, 'eval_micro_f1': 0.9815701539839471, 'eval_micro_precision': 0.9815701539839471, 'eval_micro_recall': 0.9815701539839471, 'eval_macro_f1_no_o': 0.894480121814322, 'eval_macro_precision_no_o': 0.8633122455132474, 'eval_macro_recall_no_o': 0.9279926041724984, 'eval_micro_f1_no_o': 0.8945175804032661, 'eval_micro_precision_no_o': 0.8633000964940495, 'eval_micro_recall_no_o': 0.9280774550484094, 'eval_loss': 0.0021744045129298783, 'eval_runtime': 17.5621, 'eval_samples_per_second': 3.303, 'eval_steps_per_second': 0.228, 'epoch': 12.0}\n","Accuracy for fold  2 :  0.8945175804032661  --  0.9815701539839471\n","--------------------------------\n","Testing process has finished.\n","Train run #3\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4068' max='4068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4068/4068 27:44, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1358</td>\n","      <td>0.000000</td>\n","      <td>0.002376</td>\n","      <td>0.931120</td>\n","      <td>0.913572</td>\n","      <td>0.949930</td>\n","      <td>0.982810</td>\n","      <td>0.982810</td>\n","      <td>0.982810</td>\n","      <td>0.900549</td>\n","      <td>0.872382</td>\n","      <td>0.930596</td>\n","      <td>0.900452</td>\n","      <td>0.872285</td>\n","      <td>0.930498</td>\n","    </tr>\n","    <tr>\n","      <td>2716</td>\n","      <td>0.000000</td>\n","      <td>0.001867</td>\n","      <td>0.933716</td>\n","      <td>0.909277</td>\n","      <td>0.960672</td>\n","      <td>0.983086</td>\n","      <td>0.983086</td>\n","      <td>0.983086</td>\n","      <td>0.904450</td>\n","      <td>0.865152</td>\n","      <td>0.947493</td>\n","      <td>0.904440</td>\n","      <td>0.865172</td>\n","      <td>0.947441</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-1358\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2716\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 5433\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4068\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_macro_f1': 0.9348134141920065, 'eval_macro_precision': 0.9116962923915842, 'eval_macro_recall': 0.9601697772052736, 'eval_micro_f1': 0.9833959144303972, 'eval_micro_precision': 0.9833959144303972, 'eval_micro_recall': 0.9833959144303972, 'eval_macro_f1_no_o': 0.9060266423584495, 'eval_macro_precision_no_o': 0.8688775658334059, 'eval_macro_recall_no_o': 0.9465101656740007, 'eval_micro_f1_no_o': 0.9059913935782853, 'eval_micro_precision_no_o': 0.8688888888888889, 'eval_micro_recall_no_o': 0.9464038727524204, 'eval_loss': 0.001965138311566187, 'eval_runtime': 17.716, 'eval_samples_per_second': 3.274, 'eval_steps_per_second': 0.226, 'epoch': 12.0}\n","Accuracy for fold  3 :  0.9059913935782853  --  0.9833959144303972\n","--------------------------------\n","Testing process has finished.\n","Train run #4\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4068' max='4068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4068/4068 27:22, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1358</td>\n","      <td>0.000000</td>\n","      <td>0.001844</td>\n","      <td>0.923069</td>\n","      <td>0.891199</td>\n","      <td>0.959539</td>\n","      <td>0.979365</td>\n","      <td>0.979365</td>\n","      <td>0.979365</td>\n","      <td>0.889594</td>\n","      <td>0.838157</td>\n","      <td>0.947878</td>\n","      <td>0.889646</td>\n","      <td>0.838226</td>\n","      <td>0.947787</td>\n","    </tr>\n","    <tr>\n","      <td>2716</td>\n","      <td>0.000000</td>\n","      <td>0.002304</td>\n","      <td>0.926437</td>\n","      <td>0.903487</td>\n","      <td>0.951701</td>\n","      <td>0.981019</td>\n","      <td>0.981019</td>\n","      <td>0.981019</td>\n","      <td>0.894097</td>\n","      <td>0.857182</td>\n","      <td>0.934457</td>\n","      <td>0.894110</td>\n","      <td>0.857234</td>\n","      <td>0.934302</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-1358\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2716\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.9295708612323375, 'eval_macro_precision': 0.9046552971132179, 'eval_macro_recall': 0.9571389868093609, 'eval_micro_f1': 0.9818112921561197, 'eval_micro_precision': 0.9818112921561197, 'eval_micro_recall': 0.9818112921561197, 'eval_macro_f1_no_o': 0.898597410503658, 'eval_macro_precision_no_o': 0.8585107556798832, 'eval_macro_recall_no_o': 0.9426335289954624, 'eval_micro_f1_no_o': 0.8986319432998185, 'eval_micro_precision_no_o': 0.8585826771653543, 'eval_micro_recall_no_o': 0.9426002766251729, 'eval_loss': 0.0020227156734308996, 'eval_runtime': 19.5757, 'eval_samples_per_second': 2.963, 'eval_steps_per_second': 0.204, 'epoch': 12.0}\n","Accuracy for fold  4 :  0.8986319432998185  --  0.9818112921561197\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 5433\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4068\n"]},{"output_type":"stream","name":"stdout","text":["Testing process has finished.\n","Train run #5\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4068' max='4068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4068/4068 46:23, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1358</td>\n","      <td>0.000000</td>\n","      <td>0.002154</td>\n","      <td>0.931447</td>\n","      <td>0.911418</td>\n","      <td>0.953199</td>\n","      <td>0.982741</td>\n","      <td>0.982741</td>\n","      <td>0.982741</td>\n","      <td>0.901090</td>\n","      <td>0.868922</td>\n","      <td>0.935825</td>\n","      <td>0.901099</td>\n","      <td>0.868979</td>\n","      <td>0.935685</td>\n","    </tr>\n","    <tr>\n","      <td>2716</td>\n","      <td>0.000000</td>\n","      <td>0.001551</td>\n","      <td>0.928960</td>\n","      <td>0.904335</td>\n","      <td>0.956161</td>\n","      <td>0.981467</td>\n","      <td>0.981467</td>\n","      <td>0.981467</td>\n","      <td>0.897825</td>\n","      <td>0.858204</td>\n","      <td>0.941281</td>\n","      <td>0.897757</td>\n","      <td>0.858134</td>\n","      <td>0.941217</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-1358\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2716\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.9262710969844558, 'eval_macro_precision': 0.8979855318083466, 'eval_macro_recall': 0.9580991445308502, 'eval_micro_f1': 0.9806744979158772, 'eval_micro_precision': 0.9806744979158772, 'eval_micro_recall': 0.9806744979158772, 'eval_macro_f1_no_o': 0.893969075692677, 'eval_macro_precision_no_o': 0.8483925330567799, 'eval_macro_recall_no_o': 0.944819834369065, 'eval_micro_f1_no_o': 0.8939790575916231, 'eval_micro_precision_no_o': 0.8484472049689441, 'eval_micro_recall_no_o': 0.9446749654218534, 'eval_loss': 0.0014960947667334828, 'eval_runtime': 25.0349, 'eval_samples_per_second': 2.317, 'eval_steps_per_second': 0.16, 'epoch': 12.0}\n","Accuracy for fold  5 :  0.8939790575916231  --  0.9806744979158772\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 5433\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4068\n"]},{"output_type":"stream","name":"stdout","text":["Testing process has finished.\n","Train run #6\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4068' max='4068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4068/4068 28:37, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1358</td>\n","      <td>0.000000</td>\n","      <td>0.002259</td>\n","      <td>0.925338</td>\n","      <td>0.901907</td>\n","      <td>0.951460</td>\n","      <td>0.981363</td>\n","      <td>0.981363</td>\n","      <td>0.981363</td>\n","      <td>0.892132</td>\n","      <td>0.854368</td>\n","      <td>0.933904</td>\n","      <td>0.892191</td>\n","      <td>0.853712</td>\n","      <td>0.934302</td>\n","    </tr>\n","    <tr>\n","      <td>2716</td>\n","      <td>0.000000</td>\n","      <td>0.002590</td>\n","      <td>0.929586</td>\n","      <td>0.910318</td>\n","      <td>0.950474</td>\n","      <td>0.982466</td>\n","      <td>0.982466</td>\n","      <td>0.982466</td>\n","      <td>0.898298</td>\n","      <td>0.867329</td>\n","      <td>0.931680</td>\n","      <td>0.898333</td>\n","      <td>0.867117</td>\n","      <td>0.931881</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-1358\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2716\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 5433\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4068\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_macro_f1': 0.9309237994291065, 'eval_macro_precision': 0.9115191828126464, 'eval_macro_recall': 0.9519106166419596, 'eval_micro_f1': 0.9826724999138792, 'eval_micro_precision': 0.9826724999138792, 'eval_micro_recall': 0.9826724999138792, 'eval_macro_f1_no_o': 0.9003044052022867, 'eval_macro_precision_no_o': 0.8691305546286758, 'eval_macro_recall_no_o': 0.933834475293888, 'eval_micro_f1_no_o': 0.9003333333333333, 'eval_micro_precision_no_o': 0.8690476190476191, 'eval_micro_recall_no_o': 0.9339557399723375, 'eval_loss': 0.002548331533633246, 'eval_runtime': 19.2489, 'eval_samples_per_second': 3.013, 'eval_steps_per_second': 0.208, 'epoch': 12.0}\n","Accuracy for fold  6 :  0.9003333333333333  --  0.9826724999138792\n","--------------------------------\n","Testing process has finished.\n","Train run #7\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4068' max='4068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4068/4068 38:35, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1358</td>\n","      <td>0.000000</td>\n","      <td>0.002444</td>\n","      <td>0.923214</td>\n","      <td>0.899336</td>\n","      <td>0.949543</td>\n","      <td>0.980468</td>\n","      <td>0.980468</td>\n","      <td>0.980468</td>\n","      <td>0.889283</td>\n","      <td>0.850840</td>\n","      <td>0.931373</td>\n","      <td>0.889402</td>\n","      <td>0.850916</td>\n","      <td>0.931535</td>\n","    </tr>\n","    <tr>\n","      <td>2716</td>\n","      <td>0.000000</td>\n","      <td>0.002142</td>\n","      <td>0.928485</td>\n","      <td>0.910773</td>\n","      <td>0.947665</td>\n","      <td>0.981777</td>\n","      <td>0.981777</td>\n","      <td>0.981777</td>\n","      <td>0.896971</td>\n","      <td>0.868531</td>\n","      <td>0.927601</td>\n","      <td>0.896990</td>\n","      <td>0.868523</td>\n","      <td>0.927386</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-1358\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2716\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.927342230077503, 'eval_macro_precision': 0.9081237218229132, 'eval_macro_recall': 0.9481636866450679, 'eval_micro_f1': 0.9815701539839471, 'eval_micro_precision': 0.9815701539839471, 'eval_micro_recall': 0.9815701539839471, 'eval_macro_f1_no_o': 0.8952584469218634, 'eval_macro_precision_no_o': 0.8643844023154368, 'eval_macro_recall_no_o': 0.9285201598027013, 'eval_micro_f1_no_o': 0.895298432810937, 'eval_micro_precision_no_o': 0.8644558918222794, 'eval_micro_recall_no_o': 0.9284232365145229, 'eval_loss': 0.002640057669344448, 'eval_runtime': 34.9971, 'eval_samples_per_second': 1.657, 'eval_steps_per_second': 0.114, 'epoch': 12.0}\n","Accuracy for fold  7 :  0.895298432810937  --  0.9815701539839471\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 5433\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4068\n"]},{"output_type":"stream","name":"stdout","text":["Testing process has finished.\n","Train run #8\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4068' max='4068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4068/4068 48:19, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1358</td>\n","      <td>0.000000</td>\n","      <td>0.001117</td>\n","      <td>0.898823</td>\n","      <td>0.852643</td>\n","      <td>0.956628</td>\n","      <td>0.971270</td>\n","      <td>0.971270</td>\n","      <td>0.971270</td>\n","      <td>0.855342</td>\n","      <td>0.779944</td>\n","      <td>0.948027</td>\n","      <td>0.854472</td>\n","      <td>0.777652</td>\n","      <td>0.948133</td>\n","    </tr>\n","    <tr>\n","      <td>2716</td>\n","      <td>0.000000</td>\n","      <td>0.002449</td>\n","      <td>0.930205</td>\n","      <td>0.913066</td>\n","      <td>0.948563</td>\n","      <td>0.982535</td>\n","      <td>0.982535</td>\n","      <td>0.982535</td>\n","      <td>0.899262</td>\n","      <td>0.871758</td>\n","      <td>0.928583</td>\n","      <td>0.899196</td>\n","      <td>0.871753</td>\n","      <td>0.928423</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-1358\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2716\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 5433\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4068\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_macro_f1': 0.9307097782386432, 'eval_macro_precision': 0.9115573039718368, 'eval_macro_recall': 0.951380242055285, 'eval_micro_f1': 0.9827069482241896, 'eval_micro_precision': 0.9827069482241896, 'eval_micro_recall': 0.9827069482241896, 'eval_macro_f1_no_o': 0.8999446566015591, 'eval_macro_precision_no_o': 0.8691874506539943, 'eval_macro_recall_no_o': 0.9329623935378383, 'eval_micro_f1_no_o': 0.8999332888592395, 'eval_micro_precision_no_o': 0.8692010309278351, 'eval_micro_recall_no_o': 0.9329183955739973, 'eval_loss': 0.0026453475390081018, 'eval_runtime': 41.1074, 'eval_samples_per_second': 1.411, 'eval_steps_per_second': 0.097, 'epoch': 12.0}\n","Accuracy for fold  8 :  0.8999332888592395  --  0.9827069482241896\n","--------------------------------\n","Testing process has finished.\n","Train run #9\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4068' max='4068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4068/4068 47:57, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1358</td>\n","      <td>0.000000</td>\n","      <td>0.002287</td>\n","      <td>0.926423</td>\n","      <td>0.906293</td>\n","      <td>0.948448</td>\n","      <td>0.981673</td>\n","      <td>0.981673</td>\n","      <td>0.981673</td>\n","      <td>0.893707</td>\n","      <td>0.861311</td>\n","      <td>0.928928</td>\n","      <td>0.893582</td>\n","      <td>0.860666</td>\n","      <td>0.929115</td>\n","    </tr>\n","    <tr>\n","      <td>2716</td>\n","      <td>0.000000</td>\n","      <td>0.003622</td>\n","      <td>0.926067</td>\n","      <td>0.910767</td>\n","      <td>0.942387</td>\n","      <td>0.981639</td>\n","      <td>0.981639</td>\n","      <td>0.981639</td>\n","      <td>0.893226</td>\n","      <td>0.868653</td>\n","      <td>0.919320</td>\n","      <td>0.893181</td>\n","      <td>0.868387</td>\n","      <td>0.919433</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-1358\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2716\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.9254589188268799, 'eval_macro_precision': 0.9086898033874192, 'eval_macro_recall': 0.9434264943759364, 'eval_micro_f1': 0.9814323607427056, 'eval_micro_precision': 0.9814323607427056, 'eval_micro_recall': 0.9814323607427056, 'eval_macro_f1_no_o': 0.8923640842706153, 'eval_macro_precision_no_o': 0.8654239151003966, 'eval_macro_recall_no_o': 0.9210891619258437, 'eval_micro_f1_no_o': 0.8923128454195276, 'eval_micro_precision_no_o': 0.8652159792140305, 'eval_micro_recall_no_o': 0.921161825726141, 'eval_loss': 0.00352710609116552, 'eval_runtime': 41.0006, 'eval_samples_per_second': 1.415, 'eval_steps_per_second': 0.098, 'epoch': 12.0}\n","Accuracy for fold  9 :  0.8923128454195276  --  0.9814323607427056\n","--------------------------------\n","Testing process has finished.\n"]}]},{"cell_type":"code","source":["loop_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wpkvea8G6EuP","executionInfo":{"status":"ok","timestamp":1647090131288,"user_tz":360,"elapsed":6,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"b9aa91be-b4d6-492e-90ed-5d8fb40165b8"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.88590604, 0.89195856, 0.89451758, 0.90599139, 0.89863194,\n","       0.89397906, 0.90033333, 0.89529843, 0.89993329, 0.89231285])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["loop_resultss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GUMuY7uY6Epd","executionInfo":{"status":"ok","timestamp":1647090131529,"user_tz":360,"elapsed":244,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"aee1e40c-6032-4c96-b3c3-1a814ae55514"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.97929657, 0.98088119, 0.98157015, 0.98339591, 0.98181129,\n","       0.9806745 , 0.9826725 , 0.98157015, 0.98270695, 0.98143236])"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["sum = 0.0\n","for value in loop_results:\n","  sum += value\n","print(f'Average micro_f1_no_o: {sum/len(loop_results)} %')\n","\n","sum = 0.0\n","for value in loop_resultss:\n","  sum += value\n","print(f'Average micro_f1: {sum/len(loop_results)} %')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hrSHvYq06Ej1","executionInfo":{"status":"ok","timestamp":1647090131530,"user_tz":360,"elapsed":3,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"e00a4730-a0cc-463e-e668-c71de6de1b48"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Average micro_f1_no_o: 0.8958862475011944 %\n","Average micro_f1: 0.9816011574632263 %\n"]}]},{"cell_type":"code","source":["ner_model = NerModel(BertEmbModel).to('cuda')  # make sure we move the model to the GPU for training\n","ner_model.load_state_dict(torch.load(save_path))\n","ner_model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASHUrO0o6EcH","executionInfo":{"status":"ok","timestamp":1647090132042,"user_tz":360,"elapsed":514,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"827c69ec-7afb-4195-c549-0c9cb4a400bf"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NerModel(\n","  (sci_embeddings): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (embd_dropout): Dropout(p=0.1, inplace=False)\n","  (ff_dropout): Dropout(p=0.1, inplace=False)\n","  (ff): Linear(in_features=200, out_features=14, bias=True)\n","  (tanh): Tanh()\n","  (lstm): LSTM(768, 100, bidirectional=True)\n","  (lstm_drop): Dropout(p=0.4, inplace=False)\n","  (ff_act): ReLU()\n","  (classifier): Linear(in_features=14, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"dcdDIwq0kXy2"},"source":["# Get Values of Thruth"]},{"cell_type":"code","metadata":{"id":"uCnsc2rplFzW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647090132043,"user_tz":360,"elapsed":4,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"ad1a93b0-b516-49f6-eeea-466ce32b4c86"},"source":["# Pytorch thing (if we aren't training, do this)\n","ner_model.eval()\n","ner_model.to('cuda')"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NerModel(\n","  (sci_embeddings): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (embd_dropout): Dropout(p=0.1, inplace=False)\n","  (ff_dropout): Dropout(p=0.1, inplace=False)\n","  (ff): Linear(in_features=200, out_features=14, bias=True)\n","  (tanh): Tanh()\n","  (lstm): LSTM(768, 100, bidirectional=True)\n","  (lstm_drop): Dropout(p=0.4, inplace=False)\n","  (ff_act): ReLU()\n","  (classifier): Linear(in_features=14, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"FVfjoHmcI0pL","executionInfo":{"status":"ok","timestamp":1647090158958,"user_tz":360,"elapsed":26918,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"source":["output_preds = []\n","output_real = []\n","for x in range(len(test)):\n","  inputs1 = test[x]['input_ids'][0].clone().detach().to(torch.long).unsqueeze(0).to('cuda')\n","  inputs2 = test[x]['attention_mask'][0].clone().detach().to(torch.long).unsqueeze(0).to('cuda')\n","  inputs = {'input_ids': inputs1,  'attention_mask': inputs2}\n","  #print(inputs)\n","\n","  temp_test = test[x]\n","  temp_out = temp_test.pop(\"labels\")\n","  output_real.append(np.array(temp_out[temp_out != -100])) \n","\n","  gen_preds = ner_model(**inputs)\n","  label_preds = np.argmax(gen_preds.cpu().detach().numpy(), axis=-1)[0]\n","  output_preds.append(label_preds[temp_out != -100])\n"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"mXBvXjpP-VGh","executionInfo":{"status":"ok","timestamp":1647090159155,"user_tz":360,"elapsed":207,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"source":["for x in range(len(output_real)):\n","  output_real[x] = [ID2Entity(y) for y in output_real[x]]\n","  output_preds[x] = [ID2Entity(z) for z in output_preds[x]]"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pd1Xl1giQ7z7","executionInfo":{"status":"ok","timestamp":1647090159155,"user_tz":360,"elapsed":6,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"source":["#output_real[28]"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"5rslGT68vvC8","colab":{"base_uri":"https://localhost:8080/","height":724},"executionInfo":{"status":"ok","timestamp":1647090160328,"user_tz":360,"elapsed":1179,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"bd22cb6e-9d95-4e87-f835-7cbd4b2679d1"},"source":["from sklearn.metrics import mean_squared_error, multilabel_confusion_matrix, confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support\n","import matplotlib.pyplot as plt\n","\n","plt.rcParams['figure.figsize'] = [12, 9]\n","plt.rcParams[\"figure.autolayout\"] = True\n","plt.rcParams.update({'font.size': 13})\n","\n","labels = [\"None\", 'B', 'I']\n","cm = confusion_matrix(output_real[0], output_preds[0], labels=labels)\n","for x in range(len(output_real)-1):\n","  cm += confusion_matrix(output_real[x+1], output_preds[x+1], labels=labels)\n","print(cm)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n","disp.plot(cmap=plt.cm.Blues)"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["[[26187   177   140]\n"," [   58  1382    56]\n"," [   66    50  1330]]\n"]},{"output_type":"execute_result","data":{"text/plain":["<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fc6928dab10>"]},"metadata":{},"execution_count":29},{"output_type":"display_data","data":{"text/plain":["<Figure size 864x648 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"m10aBi5x5Hdb","executionInfo":{"status":"ok","timestamp":1647090160328,"user_tz":360,"elapsed":9,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"source":["del cm"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"fgGd1XfheERK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647090160328,"user_tz":360,"elapsed":8,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"4905d003-3ddf-4ada-c228-babe7d8a7ad4"},"source":["len(output_real)"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["941"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"fHlg1QV3eZCa","executionInfo":{"status":"ok","timestamp":1647090160329,"user_tz":360,"elapsed":8,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"source":[""],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k0w9Lc0d3iOT"},"source":["# Test over Text"]},{"cell_type":"code","metadata":{"id":"mgNM3p1q3hrf"},"source":["def prepare_input(txt):\n","  inputs = BertTokenizer(txt, return_tensors='pt', padding='max_length', truncation=True, max_length=150).to('cuda')\n","  return inputs\n","\n","input_text = [\"English is shown to be trans-context-free on the basis of coordinations of the respectively type that involve strictly syntactic cross-serial agreement.\"]\n","##input_text = [\"The transient analysis of gyro-elastic structured media, composed of periodically placed masses interconnected by elastic rods and attached to gyroscopic spinners, is presented.\"] \n","##input_text = [\"The results indicated that thermal curing promoted the early strength of mortars, while decreased the late strength of mortars.\"] \n","##input_text = [\"A wide variety of processes are attested in the literature, and we find different forms of clippings in our data, including mixtures of different clippings, homophone respellings, phonetic respellings in-cluding informal oral forms, initialisms (but no acronyms), and mixtures of clipping together with homo-phone and phonetic respellings.\"] \n","\n","#input_text = [\"The goal is to accurately predict the running time of applications for task scheduling and job migration.\"] \n","#input_text = [\"This paper reports on the development of a cross-domain framework for describing complex design practices.\"] \n","#input_text = [\"Studies of inequality in China typically ignore cost of liv-ing differences between areas.\"] \n","#input_text = [\"The present study was designed to explore the long-term differences be-tween three mouse models for depression.\"]\n","#\n","input_text = [\"Finally, regarding professional competencies, teachers appeared to be largely unprepared to conduct language assessments consistent with the LAR demands.\"] \n","\n","##input_text = [\"propose a fast and reliable restoration method of virtual resources on OpenStack when physical servers or virtual machines are down.\"] \n","##input_text = [\"The results from our simulations reveal that the network assisted adaptation clearly outperforms the purely client-based DASH heuristics in some of the metrics, not all of them, particularly, in situations when the achievable throughput is moderately high or the link quality of the mobile clients does not differ from each other substantially.\"] \n","##input_text = [\"For hard rock drilling in coal mine, the drilling efficiency and service life of polycrystalline diamond compact bit are very low.\"] \n","##input_text = [\"Capturing changes in foreign reserves and exchange rates through the exchange market pressure, this article investigates whether economic policy uncertainty plays any role in exchange market pressure movements while controlling for the effects of domestic and external factors.\"] \n","##input_text = [\"This paper presents design of an self contained actuators unit in wide area damping control of power system in stabilizing system response for both nominal system condition and during actuator faults.\"] \n","\n","##input_text = [\"Ultrasound-based brain stimulation techniques may become a powerful new technique to modulate the human brain in a focal and targeted manner.\"] \n","#input_text = [\"Recent work pre-training Transformers with self-supervised objectives on large text corpora has shown great success when fine-tuned on downstream NLP tasks including text summarization.\"]\n","\n","# Tokenize + pad\n","inputs = prepare_input(input_text)\n","\n","#inputs\n","#print(inputs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jaG1vUq58BFI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645211610139,"user_tz":360,"elapsed":2,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"ce95fec4-a4cd-4608-fc55-75b5b485c9e3"},"source":["# Pytorch thing (if we aren't training, do this)\n","ner_model.eval()\n","\n","# Get predictions\n","preds = ner_model(**inputs).cpu().detach().numpy()\n","preds = np.argmax(preds, axis=-1)[0]\n","pred_labels = [ID2Entity(x) for x in preds]\n","\n","# Convert token ids to text\n","tokens = BertTokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n","\n","# Display result\n","for token, label in zip(tokens, pred_labels):\n","  if token == '[SEP]':\n","    break\n","  if token == '[CLS]':\n","    continue\n","  print('{} -> {}'.format(token, label))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["finally -> None\n",", -> None\n","regarding -> None\n","professional -> None\n","competencies -> None\n",", -> None\n","teachers -> None\n","appeared -> None\n","to -> None\n","be -> None\n","largely -> None\n","un -> None\n","##prep -> None\n","##ared -> None\n","to -> None\n","conduct -> None\n","language -> None\n","assessments -> None\n","consistent -> None\n","with -> None\n","the -> None\n","lar -> B\n","demands -> None\n",". -> None\n"]}]},{"cell_type":"markdown","metadata":{"id":"hC35X0v72kXB"},"source":["# Model Save and Load"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AnK4H5vP2kJU","executionInfo":{"status":"ok","timestamp":1639143321741,"user_tz":360,"elapsed":347,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"537a928e-691b-4471-f65b-b7650341f273"},"source":["print(\"Our model: \\n\\n\", ner_model, '\\n')\n","print(\"The state dict keys: \\n\\n\", ner_model.state_dict().keys())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Our model: \n","\n"," NerModel(\n","  (sci_embeddings): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (embd_dropout): Dropout(p=0.1, inplace=False)\n","  (ff_dropout): Dropout(p=0.1, inplace=False)\n","  (ff): Linear(in_features=200, out_features=14, bias=True)\n","  (tanh): Tanh()\n","  (lstm): LSTM(768, 100, bidirectional=True)\n","  (lstm_drop): Dropout(p=0.4, inplace=False)\n","  (ff_act): ReLU()\n","  (classifier): Linear(in_features=14, out_features=3, bias=True)\n",") \n","\n","The state dict keys: \n","\n"," odict_keys(['sci_embeddings.embeddings.position_ids', 'sci_embeddings.embeddings.word_embeddings.weight', 'sci_embeddings.embeddings.position_embeddings.weight', 'sci_embeddings.embeddings.token_type_embeddings.weight', 'sci_embeddings.embeddings.LayerNorm.weight', 'sci_embeddings.embeddings.LayerNorm.bias', 'sci_embeddings.encoder.layer.0.attention.self.query.weight', 'sci_embeddings.encoder.layer.0.attention.self.query.bias', 'sci_embeddings.encoder.layer.0.attention.self.key.weight', 'sci_embeddings.encoder.layer.0.attention.self.key.bias', 'sci_embeddings.encoder.layer.0.attention.self.value.weight', 'sci_embeddings.encoder.layer.0.attention.self.value.bias', 'sci_embeddings.encoder.layer.0.attention.output.dense.weight', 'sci_embeddings.encoder.layer.0.attention.output.dense.bias', 'sci_embeddings.encoder.layer.0.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.0.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.0.intermediate.dense.weight', 'sci_embeddings.encoder.layer.0.intermediate.dense.bias', 'sci_embeddings.encoder.layer.0.output.dense.weight', 'sci_embeddings.encoder.layer.0.output.dense.bias', 'sci_embeddings.encoder.layer.0.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.0.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.1.attention.self.query.weight', 'sci_embeddings.encoder.layer.1.attention.self.query.bias', 'sci_embeddings.encoder.layer.1.attention.self.key.weight', 'sci_embeddings.encoder.layer.1.attention.self.key.bias', 'sci_embeddings.encoder.layer.1.attention.self.value.weight', 'sci_embeddings.encoder.layer.1.attention.self.value.bias', 'sci_embeddings.encoder.layer.1.attention.output.dense.weight', 'sci_embeddings.encoder.layer.1.attention.output.dense.bias', 'sci_embeddings.encoder.layer.1.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.1.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.1.intermediate.dense.weight', 'sci_embeddings.encoder.layer.1.intermediate.dense.bias', 'sci_embeddings.encoder.layer.1.output.dense.weight', 'sci_embeddings.encoder.layer.1.output.dense.bias', 'sci_embeddings.encoder.layer.1.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.1.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.2.attention.self.query.weight', 'sci_embeddings.encoder.layer.2.attention.self.query.bias', 'sci_embeddings.encoder.layer.2.attention.self.key.weight', 'sci_embeddings.encoder.layer.2.attention.self.key.bias', 'sci_embeddings.encoder.layer.2.attention.self.value.weight', 'sci_embeddings.encoder.layer.2.attention.self.value.bias', 'sci_embeddings.encoder.layer.2.attention.output.dense.weight', 'sci_embeddings.encoder.layer.2.attention.output.dense.bias', 'sci_embeddings.encoder.layer.2.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.2.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.2.intermediate.dense.weight', 'sci_embeddings.encoder.layer.2.intermediate.dense.bias', 'sci_embeddings.encoder.layer.2.output.dense.weight', 'sci_embeddings.encoder.layer.2.output.dense.bias', 'sci_embeddings.encoder.layer.2.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.2.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.3.attention.self.query.weight', 'sci_embeddings.encoder.layer.3.attention.self.query.bias', 'sci_embeddings.encoder.layer.3.attention.self.key.weight', 'sci_embeddings.encoder.layer.3.attention.self.key.bias', 'sci_embeddings.encoder.layer.3.attention.self.value.weight', 'sci_embeddings.encoder.layer.3.attention.self.value.bias', 'sci_embeddings.encoder.layer.3.attention.output.dense.weight', 'sci_embeddings.encoder.layer.3.attention.output.dense.bias', 'sci_embeddings.encoder.layer.3.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.3.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.3.intermediate.dense.weight', 'sci_embeddings.encoder.layer.3.intermediate.dense.bias', 'sci_embeddings.encoder.layer.3.output.dense.weight', 'sci_embeddings.encoder.layer.3.output.dense.bias', 'sci_embeddings.encoder.layer.3.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.3.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.4.attention.self.query.weight', 'sci_embeddings.encoder.layer.4.attention.self.query.bias', 'sci_embeddings.encoder.layer.4.attention.self.key.weight', 'sci_embeddings.encoder.layer.4.attention.self.key.bias', 'sci_embeddings.encoder.layer.4.attention.self.value.weight', 'sci_embeddings.encoder.layer.4.attention.self.value.bias', 'sci_embeddings.encoder.layer.4.attention.output.dense.weight', 'sci_embeddings.encoder.layer.4.attention.output.dense.bias', 'sci_embeddings.encoder.layer.4.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.4.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.4.intermediate.dense.weight', 'sci_embeddings.encoder.layer.4.intermediate.dense.bias', 'sci_embeddings.encoder.layer.4.output.dense.weight', 'sci_embeddings.encoder.layer.4.output.dense.bias', 'sci_embeddings.encoder.layer.4.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.4.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.5.attention.self.query.weight', 'sci_embeddings.encoder.layer.5.attention.self.query.bias', 'sci_embeddings.encoder.layer.5.attention.self.key.weight', 'sci_embeddings.encoder.layer.5.attention.self.key.bias', 'sci_embeddings.encoder.layer.5.attention.self.value.weight', 'sci_embeddings.encoder.layer.5.attention.self.value.bias', 'sci_embeddings.encoder.layer.5.attention.output.dense.weight', 'sci_embeddings.encoder.layer.5.attention.output.dense.bias', 'sci_embeddings.encoder.layer.5.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.5.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.5.intermediate.dense.weight', 'sci_embeddings.encoder.layer.5.intermediate.dense.bias', 'sci_embeddings.encoder.layer.5.output.dense.weight', 'sci_embeddings.encoder.layer.5.output.dense.bias', 'sci_embeddings.encoder.layer.5.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.5.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.6.attention.self.query.weight', 'sci_embeddings.encoder.layer.6.attention.self.query.bias', 'sci_embeddings.encoder.layer.6.attention.self.key.weight', 'sci_embeddings.encoder.layer.6.attention.self.key.bias', 'sci_embeddings.encoder.layer.6.attention.self.value.weight', 'sci_embeddings.encoder.layer.6.attention.self.value.bias', 'sci_embeddings.encoder.layer.6.attention.output.dense.weight', 'sci_embeddings.encoder.layer.6.attention.output.dense.bias', 'sci_embeddings.encoder.layer.6.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.6.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.6.intermediate.dense.weight', 'sci_embeddings.encoder.layer.6.intermediate.dense.bias', 'sci_embeddings.encoder.layer.6.output.dense.weight', 'sci_embeddings.encoder.layer.6.output.dense.bias', 'sci_embeddings.encoder.layer.6.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.6.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.7.attention.self.query.weight', 'sci_embeddings.encoder.layer.7.attention.self.query.bias', 'sci_embeddings.encoder.layer.7.attention.self.key.weight', 'sci_embeddings.encoder.layer.7.attention.self.key.bias', 'sci_embeddings.encoder.layer.7.attention.self.value.weight', 'sci_embeddings.encoder.layer.7.attention.self.value.bias', 'sci_embeddings.encoder.layer.7.attention.output.dense.weight', 'sci_embeddings.encoder.layer.7.attention.output.dense.bias', 'sci_embeddings.encoder.layer.7.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.7.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.7.intermediate.dense.weight', 'sci_embeddings.encoder.layer.7.intermediate.dense.bias', 'sci_embeddings.encoder.layer.7.output.dense.weight', 'sci_embeddings.encoder.layer.7.output.dense.bias', 'sci_embeddings.encoder.layer.7.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.7.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.8.attention.self.query.weight', 'sci_embeddings.encoder.layer.8.attention.self.query.bias', 'sci_embeddings.encoder.layer.8.attention.self.key.weight', 'sci_embeddings.encoder.layer.8.attention.self.key.bias', 'sci_embeddings.encoder.layer.8.attention.self.value.weight', 'sci_embeddings.encoder.layer.8.attention.self.value.bias', 'sci_embeddings.encoder.layer.8.attention.output.dense.weight', 'sci_embeddings.encoder.layer.8.attention.output.dense.bias', 'sci_embeddings.encoder.layer.8.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.8.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.8.intermediate.dense.weight', 'sci_embeddings.encoder.layer.8.intermediate.dense.bias', 'sci_embeddings.encoder.layer.8.output.dense.weight', 'sci_embeddings.encoder.layer.8.output.dense.bias', 'sci_embeddings.encoder.layer.8.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.8.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.9.attention.self.query.weight', 'sci_embeddings.encoder.layer.9.attention.self.query.bias', 'sci_embeddings.encoder.layer.9.attention.self.key.weight', 'sci_embeddings.encoder.layer.9.attention.self.key.bias', 'sci_embeddings.encoder.layer.9.attention.self.value.weight', 'sci_embeddings.encoder.layer.9.attention.self.value.bias', 'sci_embeddings.encoder.layer.9.attention.output.dense.weight', 'sci_embeddings.encoder.layer.9.attention.output.dense.bias', 'sci_embeddings.encoder.layer.9.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.9.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.9.intermediate.dense.weight', 'sci_embeddings.encoder.layer.9.intermediate.dense.bias', 'sci_embeddings.encoder.layer.9.output.dense.weight', 'sci_embeddings.encoder.layer.9.output.dense.bias', 'sci_embeddings.encoder.layer.9.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.9.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.10.attention.self.query.weight', 'sci_embeddings.encoder.layer.10.attention.self.query.bias', 'sci_embeddings.encoder.layer.10.attention.self.key.weight', 'sci_embeddings.encoder.layer.10.attention.self.key.bias', 'sci_embeddings.encoder.layer.10.attention.self.value.weight', 'sci_embeddings.encoder.layer.10.attention.self.value.bias', 'sci_embeddings.encoder.layer.10.attention.output.dense.weight', 'sci_embeddings.encoder.layer.10.attention.output.dense.bias', 'sci_embeddings.encoder.layer.10.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.10.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.10.intermediate.dense.weight', 'sci_embeddings.encoder.layer.10.intermediate.dense.bias', 'sci_embeddings.encoder.layer.10.output.dense.weight', 'sci_embeddings.encoder.layer.10.output.dense.bias', 'sci_embeddings.encoder.layer.10.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.10.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.11.attention.self.query.weight', 'sci_embeddings.encoder.layer.11.attention.self.query.bias', 'sci_embeddings.encoder.layer.11.attention.self.key.weight', 'sci_embeddings.encoder.layer.11.attention.self.key.bias', 'sci_embeddings.encoder.layer.11.attention.self.value.weight', 'sci_embeddings.encoder.layer.11.attention.self.value.bias', 'sci_embeddings.encoder.layer.11.attention.output.dense.weight', 'sci_embeddings.encoder.layer.11.attention.output.dense.bias', 'sci_embeddings.encoder.layer.11.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.11.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.11.intermediate.dense.weight', 'sci_embeddings.encoder.layer.11.intermediate.dense.bias', 'sci_embeddings.encoder.layer.11.output.dense.weight', 'sci_embeddings.encoder.layer.11.output.dense.bias', 'sci_embeddings.encoder.layer.11.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.11.output.LayerNorm.bias', 'sci_embeddings.pooler.dense.weight', 'sci_embeddings.pooler.dense.bias', 'ff.weight', 'ff.bias', 'lstm.weight_ih_l0', 'lstm.weight_hh_l0', 'lstm.bias_ih_l0', 'lstm.bias_hh_l0', 'lstm.weight_ih_l0_reverse', 'lstm.weight_hh_l0_reverse', 'lstm.bias_ih_l0_reverse', 'lstm.bias_hh_l0_reverse', 'classifier.weight', 'classifier.bias'])\n"]}]},{"cell_type":"code","metadata":{"id":"KftdO6GD2rWF"},"source":["torch.save(ner_model.state_dict(), 'trained_model_dic.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# download checkpoint file\n","files.download('trained_model_dic.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"n2xrcRkQbwvH","executionInfo":{"status":"ok","timestamp":1639143322986,"user_tz":360,"elapsed":8,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"724e6884-3d3f-440d-bbe2-2030ac185d8b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_d7f824df-1211-4d38-b2b6-dec4d84cde45\", \"trained_model_dic.pth\", 442559399)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l1hvL5Nb3kmo","executionInfo":{"status":"ok","timestamp":1637655465909,"user_tz":360,"elapsed":11,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"a2910628-2592-4edd-b135-c329d0352c5e"},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["checkpoint.pth\t  model-fold-1.pth  model-fold-4.pth  trained_model_dic.pth\n","dev.json\t  model-fold-2.pth  sample_data       trained_scibert_ner_model\n","model-fold-0.pth  model-fold-3.pth  test.json\t      train.json\n"]}]},{"cell_type":"markdown","metadata":{"id":"hQL7fqSY2x9e"},"source":["Loading the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ufmrdfeT6Qz","executionInfo":{"status":"ok","timestamp":1638565657653,"user_tz":360,"elapsed":324,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"fd7fd743-41b0-4b32-eefd-db4f427d5da0"},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sample_data  test_500_v2.conll\ttrain_1500_v2.conll  trained_model_dic.pth\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a4Eus2gmJ-bS","executionInfo":{"status":"ok","timestamp":1638831550021,"user_tz":360,"elapsed":10896,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"1e8838d1-d51c-47db-8ee2-c0bbb2bb3a0b"},"source":["state_dict = torch.load('trained_model_dic.pth')\n","print(state_dict.keys())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["odict_keys(['sci_embeddings.embeddings.position_ids', 'sci_embeddings.embeddings.word_embeddings.weight', 'sci_embeddings.embeddings.position_embeddings.weight', 'sci_embeddings.embeddings.token_type_embeddings.weight', 'sci_embeddings.embeddings.LayerNorm.weight', 'sci_embeddings.embeddings.LayerNorm.bias', 'sci_embeddings.encoder.layer.0.attention.self.query.weight', 'sci_embeddings.encoder.layer.0.attention.self.query.bias', 'sci_embeddings.encoder.layer.0.attention.self.key.weight', 'sci_embeddings.encoder.layer.0.attention.self.key.bias', 'sci_embeddings.encoder.layer.0.attention.self.value.weight', 'sci_embeddings.encoder.layer.0.attention.self.value.bias', 'sci_embeddings.encoder.layer.0.attention.output.dense.weight', 'sci_embeddings.encoder.layer.0.attention.output.dense.bias', 'sci_embeddings.encoder.layer.0.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.0.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.0.intermediate.dense.weight', 'sci_embeddings.encoder.layer.0.intermediate.dense.bias', 'sci_embeddings.encoder.layer.0.output.dense.weight', 'sci_embeddings.encoder.layer.0.output.dense.bias', 'sci_embeddings.encoder.layer.0.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.0.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.1.attention.self.query.weight', 'sci_embeddings.encoder.layer.1.attention.self.query.bias', 'sci_embeddings.encoder.layer.1.attention.self.key.weight', 'sci_embeddings.encoder.layer.1.attention.self.key.bias', 'sci_embeddings.encoder.layer.1.attention.self.value.weight', 'sci_embeddings.encoder.layer.1.attention.self.value.bias', 'sci_embeddings.encoder.layer.1.attention.output.dense.weight', 'sci_embeddings.encoder.layer.1.attention.output.dense.bias', 'sci_embeddings.encoder.layer.1.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.1.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.1.intermediate.dense.weight', 'sci_embeddings.encoder.layer.1.intermediate.dense.bias', 'sci_embeddings.encoder.layer.1.output.dense.weight', 'sci_embeddings.encoder.layer.1.output.dense.bias', 'sci_embeddings.encoder.layer.1.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.1.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.2.attention.self.query.weight', 'sci_embeddings.encoder.layer.2.attention.self.query.bias', 'sci_embeddings.encoder.layer.2.attention.self.key.weight', 'sci_embeddings.encoder.layer.2.attention.self.key.bias', 'sci_embeddings.encoder.layer.2.attention.self.value.weight', 'sci_embeddings.encoder.layer.2.attention.self.value.bias', 'sci_embeddings.encoder.layer.2.attention.output.dense.weight', 'sci_embeddings.encoder.layer.2.attention.output.dense.bias', 'sci_embeddings.encoder.layer.2.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.2.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.2.intermediate.dense.weight', 'sci_embeddings.encoder.layer.2.intermediate.dense.bias', 'sci_embeddings.encoder.layer.2.output.dense.weight', 'sci_embeddings.encoder.layer.2.output.dense.bias', 'sci_embeddings.encoder.layer.2.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.2.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.3.attention.self.query.weight', 'sci_embeddings.encoder.layer.3.attention.self.query.bias', 'sci_embeddings.encoder.layer.3.attention.self.key.weight', 'sci_embeddings.encoder.layer.3.attention.self.key.bias', 'sci_embeddings.encoder.layer.3.attention.self.value.weight', 'sci_embeddings.encoder.layer.3.attention.self.value.bias', 'sci_embeddings.encoder.layer.3.attention.output.dense.weight', 'sci_embeddings.encoder.layer.3.attention.output.dense.bias', 'sci_embeddings.encoder.layer.3.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.3.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.3.intermediate.dense.weight', 'sci_embeddings.encoder.layer.3.intermediate.dense.bias', 'sci_embeddings.encoder.layer.3.output.dense.weight', 'sci_embeddings.encoder.layer.3.output.dense.bias', 'sci_embeddings.encoder.layer.3.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.3.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.4.attention.self.query.weight', 'sci_embeddings.encoder.layer.4.attention.self.query.bias', 'sci_embeddings.encoder.layer.4.attention.self.key.weight', 'sci_embeddings.encoder.layer.4.attention.self.key.bias', 'sci_embeddings.encoder.layer.4.attention.self.value.weight', 'sci_embeddings.encoder.layer.4.attention.self.value.bias', 'sci_embeddings.encoder.layer.4.attention.output.dense.weight', 'sci_embeddings.encoder.layer.4.attention.output.dense.bias', 'sci_embeddings.encoder.layer.4.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.4.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.4.intermediate.dense.weight', 'sci_embeddings.encoder.layer.4.intermediate.dense.bias', 'sci_embeddings.encoder.layer.4.output.dense.weight', 'sci_embeddings.encoder.layer.4.output.dense.bias', 'sci_embeddings.encoder.layer.4.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.4.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.5.attention.self.query.weight', 'sci_embeddings.encoder.layer.5.attention.self.query.bias', 'sci_embeddings.encoder.layer.5.attention.self.key.weight', 'sci_embeddings.encoder.layer.5.attention.self.key.bias', 'sci_embeddings.encoder.layer.5.attention.self.value.weight', 'sci_embeddings.encoder.layer.5.attention.self.value.bias', 'sci_embeddings.encoder.layer.5.attention.output.dense.weight', 'sci_embeddings.encoder.layer.5.attention.output.dense.bias', 'sci_embeddings.encoder.layer.5.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.5.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.5.intermediate.dense.weight', 'sci_embeddings.encoder.layer.5.intermediate.dense.bias', 'sci_embeddings.encoder.layer.5.output.dense.weight', 'sci_embeddings.encoder.layer.5.output.dense.bias', 'sci_embeddings.encoder.layer.5.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.5.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.6.attention.self.query.weight', 'sci_embeddings.encoder.layer.6.attention.self.query.bias', 'sci_embeddings.encoder.layer.6.attention.self.key.weight', 'sci_embeddings.encoder.layer.6.attention.self.key.bias', 'sci_embeddings.encoder.layer.6.attention.self.value.weight', 'sci_embeddings.encoder.layer.6.attention.self.value.bias', 'sci_embeddings.encoder.layer.6.attention.output.dense.weight', 'sci_embeddings.encoder.layer.6.attention.output.dense.bias', 'sci_embeddings.encoder.layer.6.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.6.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.6.intermediate.dense.weight', 'sci_embeddings.encoder.layer.6.intermediate.dense.bias', 'sci_embeddings.encoder.layer.6.output.dense.weight', 'sci_embeddings.encoder.layer.6.output.dense.bias', 'sci_embeddings.encoder.layer.6.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.6.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.7.attention.self.query.weight', 'sci_embeddings.encoder.layer.7.attention.self.query.bias', 'sci_embeddings.encoder.layer.7.attention.self.key.weight', 'sci_embeddings.encoder.layer.7.attention.self.key.bias', 'sci_embeddings.encoder.layer.7.attention.self.value.weight', 'sci_embeddings.encoder.layer.7.attention.self.value.bias', 'sci_embeddings.encoder.layer.7.attention.output.dense.weight', 'sci_embeddings.encoder.layer.7.attention.output.dense.bias', 'sci_embeddings.encoder.layer.7.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.7.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.7.intermediate.dense.weight', 'sci_embeddings.encoder.layer.7.intermediate.dense.bias', 'sci_embeddings.encoder.layer.7.output.dense.weight', 'sci_embeddings.encoder.layer.7.output.dense.bias', 'sci_embeddings.encoder.layer.7.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.7.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.8.attention.self.query.weight', 'sci_embeddings.encoder.layer.8.attention.self.query.bias', 'sci_embeddings.encoder.layer.8.attention.self.key.weight', 'sci_embeddings.encoder.layer.8.attention.self.key.bias', 'sci_embeddings.encoder.layer.8.attention.self.value.weight', 'sci_embeddings.encoder.layer.8.attention.self.value.bias', 'sci_embeddings.encoder.layer.8.attention.output.dense.weight', 'sci_embeddings.encoder.layer.8.attention.output.dense.bias', 'sci_embeddings.encoder.layer.8.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.8.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.8.intermediate.dense.weight', 'sci_embeddings.encoder.layer.8.intermediate.dense.bias', 'sci_embeddings.encoder.layer.8.output.dense.weight', 'sci_embeddings.encoder.layer.8.output.dense.bias', 'sci_embeddings.encoder.layer.8.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.8.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.9.attention.self.query.weight', 'sci_embeddings.encoder.layer.9.attention.self.query.bias', 'sci_embeddings.encoder.layer.9.attention.self.key.weight', 'sci_embeddings.encoder.layer.9.attention.self.key.bias', 'sci_embeddings.encoder.layer.9.attention.self.value.weight', 'sci_embeddings.encoder.layer.9.attention.self.value.bias', 'sci_embeddings.encoder.layer.9.attention.output.dense.weight', 'sci_embeddings.encoder.layer.9.attention.output.dense.bias', 'sci_embeddings.encoder.layer.9.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.9.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.9.intermediate.dense.weight', 'sci_embeddings.encoder.layer.9.intermediate.dense.bias', 'sci_embeddings.encoder.layer.9.output.dense.weight', 'sci_embeddings.encoder.layer.9.output.dense.bias', 'sci_embeddings.encoder.layer.9.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.9.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.10.attention.self.query.weight', 'sci_embeddings.encoder.layer.10.attention.self.query.bias', 'sci_embeddings.encoder.layer.10.attention.self.key.weight', 'sci_embeddings.encoder.layer.10.attention.self.key.bias', 'sci_embeddings.encoder.layer.10.attention.self.value.weight', 'sci_embeddings.encoder.layer.10.attention.self.value.bias', 'sci_embeddings.encoder.layer.10.attention.output.dense.weight', 'sci_embeddings.encoder.layer.10.attention.output.dense.bias', 'sci_embeddings.encoder.layer.10.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.10.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.10.intermediate.dense.weight', 'sci_embeddings.encoder.layer.10.intermediate.dense.bias', 'sci_embeddings.encoder.layer.10.output.dense.weight', 'sci_embeddings.encoder.layer.10.output.dense.bias', 'sci_embeddings.encoder.layer.10.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.10.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.11.attention.self.query.weight', 'sci_embeddings.encoder.layer.11.attention.self.query.bias', 'sci_embeddings.encoder.layer.11.attention.self.key.weight', 'sci_embeddings.encoder.layer.11.attention.self.key.bias', 'sci_embeddings.encoder.layer.11.attention.self.value.weight', 'sci_embeddings.encoder.layer.11.attention.self.value.bias', 'sci_embeddings.encoder.layer.11.attention.output.dense.weight', 'sci_embeddings.encoder.layer.11.attention.output.dense.bias', 'sci_embeddings.encoder.layer.11.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.11.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.11.intermediate.dense.weight', 'sci_embeddings.encoder.layer.11.intermediate.dense.bias', 'sci_embeddings.encoder.layer.11.output.dense.weight', 'sci_embeddings.encoder.layer.11.output.dense.bias', 'sci_embeddings.encoder.layer.11.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.11.output.LayerNorm.bias', 'sci_embeddings.pooler.dense.weight', 'sci_embeddings.pooler.dense.bias', 'ff.weight', 'ff.bias', 'lstm.weight_ih_l0', 'lstm.weight_hh_l0', 'lstm.bias_ih_l0', 'lstm.bias_hh_l0', 'lstm.weight_ih_l0_reverse', 'lstm.weight_hh_l0_reverse', 'lstm.bias_ih_l0_reverse', 'lstm.bias_hh_l0_reverse', 'classifier.weight', 'classifier.bias'])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TCFtuyBv3ADq","executionInfo":{"status":"ok","timestamp":1638831550219,"user_tz":360,"elapsed":209,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"40928121-bd3b-422d-e0c7-53907b33e69b"},"source":["ner_model = NerModel(BertEmbModel).to('cuda')\n","ner_model.load_state_dict(state_dict)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"ymiejDO5srYE"},"source":["# Obtain datasets' weights values (Do not run - fixed values)"]},{"cell_type":"code","metadata":{"id":"GsRs55zcsxhk"},"source":["zero = 0\n","one=0\n","two=0 \n","three=0\n","four=0\n","five=0\n","six=0\n","local_set = train\n","for i in range(len(local_set)):\n","  for j in range(len(local_set[i]['labels'])):\n","    if local_set[i]['labels'][j] == 0:\n","      zero += 1\n","    elif local_set[i]['labels'][j] == 1:\n","      one += 1\n","    elif local_set[i]['labels'][j] == 2:\n","      two += 1\n","    elif local_set[i]['labels'][j] == 3:\n","      three += 1\n","    elif local_set[i]['labels'][j] == 4:\n","      four += 1\n","    elif local_set[i]['labels'][j] == 5:\n","      five += 1\n","    elif local_set[i]['labels'][j] == 6:\n","      six += 1\n","    \n","print('0: ', zero, '1: ', one, '2: ', two, '3: ', three, '4: ', four, '5: ', five, '6: ', six)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YzN52yRfsym4","executionInfo":{"status":"ok","timestamp":1639045440111,"user_tz":360,"elapsed":3574304,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"e643b9e7-6841-464f-b3c0-ee537eab0abf"},"source":["zero = 0\n","one=0\n","two=0 \n","three=0\n","four=0\n","five=0\n","six=0\n","local_set = test\n","for i in range(len(local_set)):\n","  for j in range(len(local_set[i]['labels'])):\n","    if local_set[i]['labels'][j] == 0:\n","      zero += 1\n","    elif local_set[i]['labels'][j] == 1:\n","      one += 1\n","    elif local_set[i]['labels'][j] == 2:\n","      two += 1\n","    elif local_set[i]['labels'][j] == 3:\n","      three += 1\n","    elif local_set[i]['labels'][j] == 4:\n","      four += 1\n","    elif local_set[i]['labels'][j] == 5:\n","      five += 1\n","    elif local_set[i]['labels'][j] == 6:\n","      six += 1\n","    \n","print('0: ', zero, '1: ', one, '2: ', two, '3: ', three, '4: ', four, '5: ', five, '6: ', six)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0:  26504 1:  1496 2:  1446 3:  0 4:  0 5:  0 6:  0\n"]}]},{"cell_type":"code","source":["zero = 0\n","one=0\n","two=0 \n","three=0\n","four=0\n","five=0\n","six=0\n","local_set = val\n","for i in range(len(local_set)):\n","  for j in range(len(local_set[i]['labels'])):\n","    if local_set[i]['labels'][j] == 0:\n","      zero += 1\n","    elif local_set[i]['labels'][j] == 1:\n","      one += 1\n","    elif local_set[i]['labels'][j] == 2:\n","      two += 1\n","    elif local_set[i]['labels'][j] == 3:\n","      three += 1\n","    elif local_set[i]['labels'][j] == 4:\n","      four += 1\n","    elif local_set[i]['labels'][j] == 5:\n","      five += 1\n","    elif local_set[i]['labels'][j] == 6:\n","      six += 1\n","    \n","print('0: ', zero, '1: ', one, '2: ', two, '3: ', three, '4: ', four, '5: ', five, '6: ', six)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B64qF5V-trfK","executionInfo":{"status":"ok","timestamp":1639049108439,"user_tz":360,"elapsed":3668338,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"060bcf71-222b-4c6a-80e3-635556aa3ff8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0:  25964 1:  1119 2:  1382 3:  0 4:  0 5:  0 6:  0\n"]}]},{"cell_type":"code","metadata":{"id":"eEKHdlDyy1T2"},"source":[""],"execution_count":null,"outputs":[]}]}