{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1634586672813,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"CQ6H5sYFfFCM","outputId":"e9f2f38b-5555-4419-dcb5-6c0a537a5538"},"outputs":[{"name":"stdout","output_type":"stream","text":["sample_data\n"]}],"source":["!ls"]},{"cell_type":"markdown","metadata":{"id":"LyMVIljFrioE"},"source":["#External Databases"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40477,"status":"ok","timestamp":1649118191388,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"},"user_tz":360},"id":"IeeP8a6fKXOX","outputId":"171a29c4-3a10-4914-a974-2c97fdf03c15"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/transformers.git\n","  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-5kuoewr6\n","  Running command git clone -q https://github.com/huggingface/transformers.git /tmp/pip-req-build-5kuoewr6\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (1.21.5)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 7.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (4.63.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (21.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.8 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 60.3 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (4.11.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 57.0 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0.dev0) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.18.0.dev0) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.18.0.dev0) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0.dev0) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0.dev0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0.dev0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0.dev0) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0.dev0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0.dev0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0.dev0) (1.1.0)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.18.0.dev0-py3-none-any.whl size=3958421 sha256=cd8764b9213f50063d35623e35920ee3dcc0a83f47f965ce2c92538af1b5dcaa\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-a3im961t/wheels/90/a5/44/6bcd83827c8a60628c5ad602f429cd5076bcce5f2a90054947\n","Successfully built transformers\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.18.0.dev0\n"]}],"source":["! pip install git+https://github.com/huggingface/transformers.git"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20952,"status":"ok","timestamp":1649118212332,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"},"user_tz":360},"id":"_L4bHxBGsZk_","outputId":"38a3e840-532c-45ce-9675-c6d4c5a31910"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ray[tune]\n","  Downloading ray-1.11.0-cp37-cp37m-manylinux2014_x86_64.whl (52.7 MB)\n","\u001b[K     |████████████████████████████████| 52.7 MB 129 kB/s \n","\u001b[?25hCollecting grpcio<=1.43.0,>=1.28.1\n","  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n","\u001b[K     |████████████████████████████████| 4.1 MB 45.4 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.6.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.0.3)\n","Collecting redis>=3.5.0\n","  Downloading redis-4.2.2-py3-none-any.whl (226 kB)\n","\u001b[K     |████████████████████████████████| 226 kB 58.3 MB/s \n","\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (7.1.2)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.3.3)\n","Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.17.3)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.21.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (6.0)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (21.4.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.8.9)\n","Collecting tensorboardX>=1.9\n","  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 60.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.3.5)\n","Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray[tune]) (1.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (3.10.0.2)\n","Collecting async-timeout>=4.0.2\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (4.11.3)\n","Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (21.3)\n","Collecting deprecated>=1.2.3\n","  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]) (1.14.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]) (3.7.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.4->redis>=3.5.0->ray[tune]) (3.0.7)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (5.4.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (0.18.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2018.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (3.0.4)\n","Installing collected packages: deprecated, async-timeout, redis, grpcio, tensorboardX, ray\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.44.0\n","    Uninstalling grpcio-1.44.0:\n","      Successfully uninstalled grpcio-1.44.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n","Successfully installed async-timeout-4.0.2 deprecated-1.2.13 grpcio-1.43.0 ray-1.11.0 redis-4.2.2 tensorboardX-2.5\n"]}],"source":["! pip install ray[tune]"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14714,"status":"ok","timestamp":1649118227040,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"},"user_tz":360},"id":"UI0tseYdav7D","outputId":"2cf23f5a-1173-49f9-b560-f47c4a9911ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 35.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 30 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 40 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████                           | 51 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 61 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 71 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 81 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 92 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 102 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 112 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 122 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 133 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 143 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 153 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 163 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 174 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 184 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 194 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 204 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 215 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 225 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 235 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 245 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 256 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 266 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 276 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 286 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 296 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 307 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 317 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 325 kB 7.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.63.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 44.4 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n","\u001b[K     |████████████████████████████████| 136 kB 54.6 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 50.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 56.7 MB/s \n","\u001b[?25hRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 2.1 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 54.2 MB/s \n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 54.4 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, aiosignal, fsspec, aiohttp, xxhash, responses, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 asynctest-0.13.0 datasets-2.0.0 frozenlist-1.3.0 fsspec-2022.3.0 multidict-6.0.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10002,"status":"ok","timestamp":1649118237025,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"},"user_tz":360},"id":"A4WLX8OtSc_G","outputId":"87443111-c01f-43fe-a278-8734eda4a5b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[?25l\r\u001b[K     |███████▌                        | 10 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20 kB 36.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30 kB 21.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=e939dab718498f4a59987b9c175e3cabf6c2dcf3ab5561a9270bb66f977ff74a\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n"]}],"source":["!pip install seqeval"]},{"cell_type":"markdown","metadata":{"id":"52t8l945rf1Y"},"source":["#Libraries"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["d1babbdfe74545bfb448fb75c4b80119","64d826f306b64b38b12c156d249e590d","07c12b9de7e24c88aa49e4f896eb88c1","dd1992e68745464bae6bd3ceee2199d4","e2f5af3d7f73446d80ecbfcc8ecc86d7","a4eba57639ea4230905eea22ddcacf2b","ae380a79666a4a9da4180ec4ecdff472","cb183a889d934df5b54e008eb90124e4","d2e339112b7f44599510877bcbd73730","4b1d337c322b4b56963ea554420bedf3","b4708bbf7a4d4c8e95710b5c20225c2a","945ccd2960c04154a70af387864d8833","b3427c1d31084dd89029928db44b9e7c","ae786aea764d4481be979a35c4f805d9","6719f8f34dc745d886ceeeca1fc27044","e384149a93a447a689b2ba88c9fce891","2e387e1a661a4509be3753874545c9bf","ba114c09e9fe4842888899d26eaddcb7","799bfc35d4a04c368b80f406b4333731","af3b99cfdd8f43bfbbdc9ff2b3b2d860","a9c2fc5473374187b46965352369bac6","adea7f07000a48c18bc9a9a17c4eb8d5","690c9db97e7447fd9ebbaf49a9e2aabd","c27024fad42445fdb8dce0ba865deb9c","17563b595bc44cbd87fcc19d1a203dfc","585dc7834caa486bbde0a97e79d7f0fc","b236960547ec4635a559da72221f1fb8","4f8d9474a3d74f5fb12be429efcb1fff","22c0eadfb39945e2aae02de390c35d24","673df43bed00462495b2dc1b47825724","a602b444404f40cebb34cc829b60af57","9cf4cbce024845e7a996e8342b0c0d9b","6124d9b458bb4ab5b24c4a9d553a9e5b"],"height":0},"executionInfo":{"elapsed":26616,"status":"ok","timestamp":1649118263629,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"},"user_tz":360},"id":"qSbdGMYCgquq","outputId":"c718382d-3dbe-4eaa-84f8-66c40c22553b"},"outputs":[{"output_type":"stream","name":"stdout","text":["4.18.0.dev0\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1babbdfe74545bfb448fb75c4b80119"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/223k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"945ccd2960c04154a70af387864d8833"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/422M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"690c9db97e7447fd9ebbaf49a9e2aabd"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["from google.colab import files\n","\n","import os\n","import re\n","import json\n","import string\n","\n","import torch\n","import torch.nn as nn\n","\n","import numpy as np\n","#import tensorflow as tf\n","#from tensorflow import keras\n","#from tensorflow.keras import layers\n","#from datasets import load_dataset\n","#from collections import Counter\n","#from conlleval import evaluate\n","\n","import tensorflow_hub as hub\n","from keras import backend as K\n","import torch.nn.functional as F\n","\n","import transformers\n","print(transformers.__version__)\n","from transformers import TrainingArguments\n","from transformers import Trainer\n","\n","from transformers import Trainer\n","from transformers.trainer_utils import EvalLoopOutput\n","\n","from seqeval.metrics import classification_report\n","from sklearn.metrics import precision_recall_fscore_support as prfs\n","from datasets import load_metric\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","\n","from transformers import AutoTokenizer, AutoModel\n","BertTokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n","BertEmbModel = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')"]},{"cell_type":"markdown","metadata":{"id":"-DBrafz0KqEq"},"source":["#Loading Dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","headers":[["content-type","application/javascript"]],"ok":true,"status":200,"status_text":""}},"height":145},"executionInfo":{"elapsed":64317,"status":"ok","timestamp":1649118327940,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"},"user_tz":360},"id":"ICN0rgXve6o1","outputId":"64f1f6ee-5b42-4fd8-e472-4365770fee57"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-6e17dbe8-533a-4142-b3f9-1a853241d088\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-6e17dbe8-533a-4142-b3f9-1a853241d088\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving dev.json to dev.json\n","Saving test.json to test.json\n","Saving train.json to train.json\n"]}],"source":["uploaded = files.upload()"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"IR8fDCLnap-m","executionInfo":{"status":"ok","timestamp":1649118328186,"user_tz":360,"elapsed":250,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}}},"outputs":[],"source":["class SciERCDataset(torch.utils.data.Dataset):\n","  def __init__(self, raw_data, entity_map, max_length=250):\n","    # Need to fix sentence offset for labels!!\n","    for i, sample in enumerate(raw_data):\n","      sent_offset = 0\n","      for j, sent in enumerate(sample['sentences']):\n","        for k, ner in enumerate(sample['ner'][j]):\n","          raw_data[i]['ner'][j][k] = [raw_data[i]['ner'][j][k][0] - sent_offset, \n","                                      raw_data[i]['ner'][j][k][1] - sent_offset, \n","                                      raw_data[i]['ner'][j][k][2]]\n","        sent_offset += len(sent)\n","\n","    sentences = [x['sentences'] for x in raw_data]\n","    self.raw_x = [sent for sublist in sentences for sent in sublist]\n","\n","    ners = [x['ner'] for x in raw_data]\n","    self.raw_y = [ner for sublist in ners for ner in sublist]\n","    \n","    self.entity_map = entity_map\n","    self.max_length = max_length\n","\n","  def tokenize_and_preserve_labels(self, sentence, text_labels):\n","    \"\"\"\n","    The tokenizer can split single words into multiple tokens - this breaks\n","    the labels, so we need to keep track of this!\n","    \"\"\"\n","    tokenized_sentence = []\n","    labels = []\n","    prev_label = 0\n","\n","    for word, label in zip(sentence, text_labels):\n","        # Tokenize the word and count # of subwords the word is broken into\n","        tokenized_word = BertTokenizer.tokenize(word)\n","        n_subwords = len(tokenized_word)\n","\n","        # Add the tokenized word to the final tokenized word list\n","        tokenized_sentence.extend(tokenized_word)\n","\n","        # Add the same label to the new list of labels `n_subwords` times\n","        if label != 0:  \n","          labels.extend([-100] * n_subwords)\n","          labels[-1 * n_subwords] = label\n","        else:\n","          labels.extend([label] * n_subwords)\n","        \n","        prev_label = label\n","\n","    return tokenized_sentence, labels\n","\n","  def __getitem__(self, idx):\n","    tokens = self.raw_x[idx]\n","    labels = np.zeros((len(tokens)))\n","\n","    #For Span\n","    for ner in self.raw_y[idx]:  # Returns [start_idx, end_idx, string label]\n","      assert len(tokens) >= ner[0], '{}, {}'.format(tokens, ner)\n","      ner_name = 'I-' + ner[-1]\n","      label = self.entity_map(ner_name)  # Get the integer label\n","      labels[ner[0]:ner[1]+1] = label\n","      #labels[ner[0]] = label - 1 \n","\n","    #For BIO\n","    #for ner in self.raw_y[idx]:  # Returns [start_idx, end_idx, string label]\n","    #  assert len(tokens) >= ner[0], '{}, {}'.format(tokens, ner)  # Double checking the labels are correct\n","    #  ner_name = 'I-' + ner[-1]  # assume all are \"I\" labels\n","    #  label = self.entity_map(ner_name)  # Get the integer label\n","    #  labels[ner[0]:ner[1]+1] = label  \n","    #  labels[ner[0]] = label - 1  # Change first one to \"B\" label\n","\n","    # This could be moved to __init__ to save time?\n","    tokens, labels = self.tokenize_and_preserve_labels(tokens, labels)\n","\n","    # Convert each token to an id number \n","    input_ids = BertTokenizer.convert_tokens_to_ids(tokens)\n","    \n","    # add and adjust for special tokens\n","    input_ids = [BertTokenizer.cls_token_id] + input_ids + [BertTokenizer.sep_token_id]  \n","    labels = [0] + labels + [0]\n","\n","    # Pad inputs\n","    input_ids = torch.tensor(np.pad(input_ids, [0, self.max_length-len(input_ids)]))\n","    labels = torch.tensor(np.pad(labels, [0, self.max_length-len(labels)], constant_values=-100))\n","\n","    attention_mask = torch.tensor([int(i != 0) for i in input_ids])\n","\n","    return {'input_ids': [input_ids], 'attention_mask': [attention_mask], 'labels': labels}\n","\n","  def __len__(self):\n","    return len(self.raw_y)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"TlMNAfW3gfGp","executionInfo":{"status":"ok","timestamp":1649118328186,"user_tz":360,"elapsed":17,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}}},"outputs":[],"source":["def Entity2ID(Sc_Entity):\n","  return {\n","        'I-Task': 1,\n","        'I-Method': 2,\n","        'I-Metric': 3,\n","        'I-Material': 4,\n","        'I-OtherScientificTerm': 5,\n","        'I-Generic': 6,\n","        'None': 0\n","    }[Sc_Entity]\n","\n","def ID2Entity(Sc_Entity):\n","  return {\n","        1: 'I-Task',\n","        2: 'I-Method',\n","        3: 'I-Metric',\n","        4: 'I-Material',\n","        5: 'I-OtherScientificTerm',\n","        6: 'I-Generic',\n","        0: 'O'\n","    }[Sc_Entity]"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1649118328187,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"},"user_tz":360},"id":"awzlXu9Ugool","outputId":"9cb98f08-bd94-48a2-94c4-027f5a5e0716"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(350, 100, 50)"]},"metadata":{},"execution_count":9}],"source":["train_data = []\n","with open('train.json','r') as f:\n","  for line in f:\n","    train_data.append(json.loads(line))\n","\n","test_data = []\n","with open('test.json','r') as f:\n","  for line in f:\n","    test_data.append(json.loads(line))\n","\n","val_data = []\n","with open('dev.json','r') as f:\n","  for line in f:\n","    val_data.append(json.loads(line))\n","\n","#train_data[3]['sentences'][0], train_data[3]['ner'][0], len(train_data[3]['sentences'][1])\n","len(train_data), len(test_data), len(val_data)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"y92WU6R3dltN","executionInfo":{"status":"ok","timestamp":1649118328187,"user_tz":360,"elapsed":12,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}}},"outputs":[],"source":["train = SciERCDataset(train_data, Entity2ID)\n","val = SciERCDataset(val_data, Entity2ID)\n","test = SciERCDataset(test_data, Entity2ID)"]},{"cell_type":"code","source":["len(train), len(test), len(val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9U1L1rMhGpPG","executionInfo":{"status":"ok","timestamp":1649118328187,"user_tz":360,"elapsed":11,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"502ca67c-9e0b-433f-911d-cdc0a668b803"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1861, 551, 275)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","execution_count":12,"metadata":{"id":"YyTtZEgcLv3C","executionInfo":{"status":"ok","timestamp":1649118328188,"user_tz":360,"elapsed":9,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}}},"outputs":[],"source":["#tokens = BertTokenizer.convert_ids_to_tokens(train[1]['input_ids'][0])\n","#labels = train[1]['labels']\n","#print(' '.join(tokens))\n","#print(labels)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1649118328188,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"},"user_tz":360},"id":"n-2wczlALa-p","outputId":"46f01bc3-2952-4cd7-fa49-bdf92c0781df"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n"," 'input_ids': [tensor([  102,  6170,   165,   817,   147,   195,   428,   579,  2220,   579,\n","           2159,   191,   111,  2525,   131,  7395, 30113,   131,   111,  1222,\n","           1211,   198,  3862,  8503, 13510,  2057,   579,  8595,  4111,   205,\n","            103,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0])],\n"," 'labels': tensor([   0.,    4.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","            0.,    0.,    0.,    0.,    0.,    5., -100.,    0.,    0.,    0.,\n","            0.,    0.,    0.,    5.,    5.,    5., -100., -100.,    5.,    0.,\n","            0., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.],\n","        dtype=torch.float64)}"]},"metadata":{},"execution_count":13}],"source":["train[0]"]},{"cell_type":"markdown","metadata":{"id":"oGYV8ipcJ5fU"},"source":["# Pytorch Model Definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eFp2ZFd25KwK"},"outputs":[],"source":["class NerModel(nn.Module):\n","  def __init__(self, b_embeddings, emb_dims=768, ff_dims=14, out_dims=7):\n","    super(NerModel, self).__init__()\n","    self.sci_embeddings = b_embeddings\n","    self.embd_dropout = nn.Dropout(0.1)\n","    self.ff_dropout = nn.Dropout(0.1)\n","    self.ff = nn.Linear(emb_dims, ff_dims)\n","    self.tanh = nn.Tanh()\n","    self.lstm = nn.LSTM(emb_dims, 100, 1, bidirectional=True)\n","    self.lstm_drop = nn.Dropout(0.4)\n","    self.ff = nn.Linear(200, ff_dims)\n","    self.ff_act = nn.ReLU()\n","    self.classifier = nn.Linear(ff_dims, out_dims)\n","  def forward(self, **inputs):\n","    embds = self.sci_embeddings(**inputs)['last_hidden_state']\n","    out = self.embd_dropout(embds)\n","    out, _ = self.lstm(out)\n","    out = self.tanh(out)\n","    out = self.lstm_drop(out)\n","    out = self.ff(out)\n","    out = self.ff_act(out)\n","    out = self.ff_dropout(out)\n","    out = self.classifier(out)\n","    return out\n"]},{"cell_type":"markdown","metadata":{"id":"7LthVVOhx_Sz"},"source":["# Metrics and Configs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VZJjqYf2AKA8"},"outputs":[],"source":["def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    #print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","\n","import math\n","\n","def load_param():\n","  for n, v in best_run.hyperparameters.items():\n","    if n == 'seed':\n","      setattr(trainer.args, n, math.ceil(v))\n","      print(n, math.ceil(v))\n","    else:\n","      setattr(trainer.args, n, v)\n","      print(n, v)   "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qjMXqFluyLCW"},"outputs":[],"source":["batch_size = 4\n","training_args = TrainingArguments(\n","    \"trained_scibert_ner_model\", # output dir\n","    learning_rate=1e-5, \n","    num_train_epochs=10, \n","    dataloader_drop_last=True,\n","    per_device_eval_batch_size=batch_size, \n","    per_device_train_batch_size=batch_size,\n","    logging_steps=50,\n","    save_steps=len(train) // batch_size,\n","    lr_scheduler_type='cosine',\n","    evaluation_strategy='steps',\n","    eval_steps=len(train) // batch_size)\n","#print(training_args)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fabdHzMRybBR"},"outputs":[],"source":["def collator(batch):\n","  out =  {\n","      'input_ids': torch.stack([(x['input_ids'][0]) for x in batch]),\n","      'attention_mask': torch.stack([x['attention_mask'][0] for x in batch]),\n","      'labels': torch.stack([x['labels'].clone().detach() for x in batch])\n","  }\n","  return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dZluJPsy2eb5"},"outputs":[],"source":["class FocalLoss(nn.modules.loss._WeightedLoss):\n","    def __init__(self, weight, gamma, reduction='mean'):\n","        super(FocalLoss, self).__init__(weight,reduction=reduction)\n","        self.gamma = gamma\n","        self.weight = weight #weight parameter will act as the alpha parameter to balance class weights\n","\n","    def forward(self, input, target):\n","        ce_loss = F.cross_entropy(input, target, ignore_index=-100, reduction=self.reduction, weight=self.weight)\n","        pt = torch.exp(-ce_loss)\n","        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n","        return focal_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLbpwNckLvV6"},"outputs":[],"source":["class MultilabelTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False, num_labels=7):\n","        labels = inputs.pop(\"labels\")\n","        outputs = model(**inputs)\n","        logits = outputs\n","        \n","        #weights = torch.tensor([0.1, 1.5, 1.55, 1.9, 1.75, 1.65, 1.9]).cuda()  # The no-class label has too many examples, we need to weight the loss - this probably needs further tuning \n","        \n","        #weights = torch.tensor([0.1, 1.5, 1.2, 1.9, 1.75, 1.3, 1.85]).cuda()\n","\n","        #weights = torch.tensor([0.89, 1.73, 1.69, 1.79, 1.76, 1.7, 1.77]).cuda()\n","\n","        #weights = torch.tensor([0.89, 1.69, 1.65, 1.84, 1.75, 1.66, 1.77]).cuda()\n","\n","        #weights = torch.tensor([0.95, 1.6, 1.5, 1.94, 1.7, 1.55, 1.83]).cuda()\n","\n","        #weights = torch.tensor([0.12, 0.83, 0.78, 1.0, 0.88, 0.8, 0.95]).cuda()\n","\n","        #weights = torch.tensor([0.42, 1.5, 1.2, 2.0, 1.6, 1.4, 1.8]).cuda()\n","\n","        #weights = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]).cuda()\n","\n","        #weights = torch.tensor([0.1, 1.36, 0.93, 7.45, 2.66, 1.01, 3.51]).cuda()\n","\n","        weights = torch.tensor([0.26, 0.95, 0.92, 0.99, 0.97, 0.93, 0.98]).cuda()\n","\n","        gamma=5\n","        loss_fct = FocalLoss(weight=weights, gamma=gamma)\n","        loss = loss_fct(logits.view(-1, num_labels), labels.long().view(-1))\n","        return (loss, outputs) if return_outputs else loss\n","\n","    def evaluation_loop(self, dataloader, description, prediction_loss_only=None, ignore_keys=None, metric_key_prefix=\"eval\", num_labels=7):\n","      args = self.args\n","      prediction_loss_only = prediction_loss_only if prediction_loss_only is not None else args.prediction_loss_only\n","\n","      self.model.eval()\n","\n","      all_losses = []\n","      all_preds = []\n","      all_labels = []\n","      for step, sample in enumerate(dataloader):\n","        for i in range(0, len(sample['labels'])):\n","          inputs = {}\n","          inputs['input_ids'] = torch.stack([sample['input_ids'][i].cuda()])\n","          inputs['attention_mask'] = torch.stack([sample['attention_mask'][i].cuda()])\n","          inputs['labels'] = torch.stack([sample['labels'][i].cuda()])\n","          labels = inputs['labels'][0].cpu().numpy()\n","          \n","          (loss, logits) = self.compute_loss(self.model, inputs, return_outputs=True)\n","          logits = logits[0].cpu().detach().numpy()\n","          preds = np.argmax(nn.Softmax(dim=-1)(torch.tensor(logits)).numpy(), axis=-1)\n","\n","          all_losses = np.concatenate((all_losses, [loss.detach().cpu().numpy()]), axis=0)\n","\n","          preds = preds[labels != -100]\n","          labels = labels[labels != -100]\n","          all_preds = np.concatenate((all_preds, preds))\n","          all_labels = np.concatenate((all_labels, labels))\n","\n","      metrics = {}\n","      metrics['macro_f1'] = f1_score(all_labels, all_preds, average='macro')\n","      metrics['macro_precision'] = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n","      metrics['macro_recall'] = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n","      metrics['micro_f1'] = f1_score(all_labels, all_preds, average='micro')\n","      metrics['micro_precision'] = precision_score(all_labels, all_preds, average='micro', zero_division=0)\n","      metrics['micro_recall'] = recall_score(all_labels, all_preds, average='micro', zero_division=0)\n","\n","      metrics['macro_f1_no_o'] = f1_score(all_labels, all_preds, average='macro', labels=[1, 2, 3, 4, 5, 6])\n","      metrics['macro_precision_no_o'] = precision_score(all_labels, all_preds, average='macro', labels=[1, 2, 3, 4, 5, 6], zero_division=0)\n","      metrics['macro_recall_no_o'] = recall_score(all_labels, all_preds, average='macro', labels=[1, 2, 3, 4, 5, 6], zero_division=0)\n","      metrics['micro_f1_no_o'] = f1_score(all_labels, all_preds, average='micro', labels=[1, 2, 3, 4, 5, 6])\n","      metrics['micro_precision_no_o'] = precision_score(all_labels, all_preds, average='micro', labels=[1, 2, 3, 4, 5, 6], zero_division=0)\n","      metrics['micro_recall_no_o'] = recall_score(all_labels, all_preds, average='micro', labels=[1, 2, 3, 4, 5, 6], zero_division=0)\n","\n","      for key in list(metrics.keys()):\n","        if not key.startswith(metric_key_prefix):\n","          metrics[metric_key_prefix + '_' + key] = metrics.pop(key)\n","      \n","      metrics[metric_key_prefix + '_loss'] = all_losses.mean().item()\n","\n","      return EvalLoopOutput(predictions=all_preds, label_ids=all_labels, metrics=metrics, num_samples=len(dataloader))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"infNapI_OmFr"},"outputs":[],"source":["def my_hp_space_ray(trial):\n","    from ray import tune\n","\n","    return {\n","        \"learning_rate\": tune.loguniform(9e-6, 1e-4),\n","        \"num_train_epochs\": tune.choice(range(5, 25)),\n","        \"weight_decay\": tune.uniform(0.0, 0.2),\n","        \"per_device_train_batch_size\": tune.choice([4, 8, 16]),  #<16 definetly not working\n","    }"]},{"cell_type":"markdown","metadata":{"id":"1Nh8Lcpvb_F4"},"source":["# Hyperparameter Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6AqbEPyPK7O"},"outputs":[],"source":["def model_init():\n","    x = NerModel(BertEmbModel)\n","    x.sci_embeddings.requires_grad = False\n","    return x\n","\n","trainer = MultilabelTrainer(model_init=model_init,\n","                            args=training_args,\n","                            train_dataset=train,\n","                            eval_dataset=val,\n","                            data_collator=collator  # defines how to merge data into batches, using the collator function above\n","                            )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IGyHLY640NRz"},"outputs":[],"source":["from ray.tune.suggest.hyperopt import HyperOptSearch\n","from ray.tune.schedulers import ASHAScheduler\n","\n","best_run = trainer.hyperparameter_search(backend=\"ray\", \n","                                         resources_per_trial={\"gpu\": 1, \"cpu\": 0},\n","                                         n_trials=18, \n","                                         direction=\"maximize\", \n","                                         hp_space=my_hp_space_ray,\n","                                         search_alg=HyperOptSearch(metric='eval_micro_recall_no_o', mode=\"max\"),  #'eval_*f1_micro'\n","                                         scheduler=ASHAScheduler(metric='eval_micro_recall_no_o', mode=\"max\")\n","                                         )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zH0H8agAbzZi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645138018290,"user_tz":360,"elapsed":7,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"b7087d0e-7ccd-44b5-f32a-ddc9276c014a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["BestRun(run_id='0b9563ea', objective=9.572004533254779, hyperparameters={'learning_rate': 2.5923213776958604e-05, 'num_train_epochs': 20, 'weight_decay': 0.028135787671833536, 'per_device_train_batch_size': 16})"]},"metadata":{},"execution_count":22}],"source":["best_run"]},{"cell_type":"markdown","metadata":{"id":"kv6pGzbGpv2D"},"source":["# Cossvalidation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LhipElJSzRUF"},"outputs":[],"source":["#import tensorflow as tf\n","from torch.utils.data import DataLoader, ConcatDataset\n","from sklearn.model_selection import KFold\n","from torch import nn\n","from transformers import Trainer\n","\n","#print('GPU detected:', tf.config.list_physical_devices('GPU'))\n","k_folds = 5\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","results = np.zeros(5)\n","resultss = np.zeros(5)\n","dataset = ConcatDataset([train, test])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zQyLOxyMjZq2","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1646895313663,"user_tz":360,"elapsed":5347226,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"1326cd18-c050-4a93-f690-658f45b015ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["FOLD 0\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1929\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2400\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2400' max='2400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2400/2400 17:28, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.088200</td>\n","      <td>0.166238</td>\n","      <td>0.704257</td>\n","      <td>0.699223</td>\n","      <td>0.725757</td>\n","      <td>0.881141</td>\n","      <td>0.881141</td>\n","      <td>0.881141</td>\n","      <td>0.662846</td>\n","      <td>0.653983</td>\n","      <td>0.690811</td>\n","      <td>0.694170</td>\n","      <td>0.662194</td>\n","      <td>0.729392</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.021700</td>\n","      <td>0.127322</td>\n","      <td>0.734887</td>\n","      <td>0.702372</td>\n","      <td>0.780138</td>\n","      <td>0.892900</td>\n","      <td>0.892900</td>\n","      <td>0.892900</td>\n","      <td>0.697567</td>\n","      <td>0.657153</td>\n","      <td>0.752765</td>\n","      <td>0.718767</td>\n","      <td>0.690876</td>\n","      <td>0.749005</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.010800</td>\n","      <td>0.114582</td>\n","      <td>0.752670</td>\n","      <td>0.733069</td>\n","      <td>0.777347</td>\n","      <td>0.897169</td>\n","      <td>0.897169</td>\n","      <td>0.897169</td>\n","      <td>0.718250</td>\n","      <td>0.693425</td>\n","      <td>0.748949</td>\n","      <td>0.731399</td>\n","      <td>0.708500</td>\n","      <td>0.755827</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.007100</td>\n","      <td>0.112511</td>\n","      <td>0.747570</td>\n","      <td>0.721543</td>\n","      <td>0.782701</td>\n","      <td>0.896794</td>\n","      <td>0.896794</td>\n","      <td>0.896794</td>\n","      <td>0.712255</td>\n","      <td>0.679563</td>\n","      <td>0.755501</td>\n","      <td>0.730654</td>\n","      <td>0.703899</td>\n","      <td>0.759522</td>\n","    </tr>\n","    <tr>\n","      <td>2325</td>\n","      <td>0.006400</td>\n","      <td>0.112283</td>\n","      <td>0.737827</td>\n","      <td>0.706369</td>\n","      <td>0.780746</td>\n","      <td>0.893649</td>\n","      <td>0.893649</td>\n","      <td>0.893649</td>\n","      <td>0.701077</td>\n","      <td>0.661837</td>\n","      <td>0.753610</td>\n","      <td>0.722987</td>\n","      <td>0.694321</td>\n","      <td>0.754122</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2325\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.7380146694507802, 'eval_macro_precision': 0.7066210372689362, 'eval_macro_recall': 0.7807462081901918, 'eval_micro_f1': 0.8936488915518275, 'eval_micro_precision': 0.8936488915518275, 'eval_micro_recall': 0.8936488915518275, 'eval_macro_f1_no_o': 0.7012959679611025, 'eval_macro_precision_no_o': 0.6621312164423391, 'eval_macro_recall_no_o': 0.7536100515117014, 'eval_micro_f1_no_o': 0.722986782940455, 'eval_micro_precision_no_o': 0.6943208584140277, 'eval_micro_recall_no_o': 0.7541216600341103, 'eval_loss': 0.11228734726673792, 'eval_runtime': 5.9796, 'eval_samples_per_second': 5.017, 'eval_steps_per_second': 0.334, 'epoch': 20.0}\n","Accuracy for fold  0 :  0.722986782940455\n","--------------------------------\n","FOLD 1\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1929\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2400\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2400' max='2400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2400/2400 17:29, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.073900</td>\n","      <td>0.090634</td>\n","      <td>0.910602</td>\n","      <td>0.892874</td>\n","      <td>0.930701</td>\n","      <td>0.966267</td>\n","      <td>0.966267</td>\n","      <td>0.966267</td>\n","      <td>0.898034</td>\n","      <td>0.876029</td>\n","      <td>0.922785</td>\n","      <td>0.908550</td>\n","      <td>0.887823</td>\n","      <td>0.930268</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.020500</td>\n","      <td>0.040740</td>\n","      <td>0.913258</td>\n","      <td>0.898679</td>\n","      <td>0.930143</td>\n","      <td>0.966495</td>\n","      <td>0.966495</td>\n","      <td>0.966495</td>\n","      <td>0.901247</td>\n","      <td>0.882666</td>\n","      <td>0.922487</td>\n","      <td>0.911756</td>\n","      <td>0.887320</td>\n","      <td>0.937576</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.010900</td>\n","      <td>0.030373</td>\n","      <td>0.916400</td>\n","      <td>0.906370</td>\n","      <td>0.927257</td>\n","      <td>0.969754</td>\n","      <td>0.969754</td>\n","      <td>0.969754</td>\n","      <td>0.904578</td>\n","      <td>0.892239</td>\n","      <td>0.917875</td>\n","      <td>0.917520</td>\n","      <td>0.907143</td>\n","      <td>0.928136</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.007400</td>\n","      <td>0.025919</td>\n","      <td>0.918512</td>\n","      <td>0.905818</td>\n","      <td>0.933050</td>\n","      <td>0.969982</td>\n","      <td>0.969982</td>\n","      <td>0.969982</td>\n","      <td>0.907073</td>\n","      <td>0.891094</td>\n","      <td>0.925188</td>\n","      <td>0.919636</td>\n","      <td>0.900964</td>\n","      <td>0.939099</td>\n","    </tr>\n","    <tr>\n","      <td>2325</td>\n","      <td>0.007200</td>\n","      <td>0.025689</td>\n","      <td>0.918038</td>\n","      <td>0.907355</td>\n","      <td>0.930274</td>\n","      <td>0.970058</td>\n","      <td>0.970058</td>\n","      <td>0.970058</td>\n","      <td>0.906518</td>\n","      <td>0.893122</td>\n","      <td>0.921715</td>\n","      <td>0.919599</td>\n","      <td>0.904566</td>\n","      <td>0.935140</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2325\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.9180383819076718, 'eval_macro_precision': 0.9073546389905337, 'eval_macro_recall': 0.9302743149842237, 'eval_micro_f1': 0.9700576106731352, 'eval_micro_precision': 0.9700576106731352, 'eval_micro_recall': 0.9700576106731352, 'eval_macro_f1_no_o': 0.9065180090369171, 'eval_macro_precision_no_o': 0.8931215982329932, 'eval_macro_recall_no_o': 0.9217148666068803, 'eval_micro_f1_no_o': 0.9195987423266957, 'eval_micro_precision_no_o': 0.9045655375552283, 'eval_micro_recall_no_o': 0.9351400730816078, 'eval_loss': 0.025688963839396214, 'eval_runtime': 5.9616, 'eval_samples_per_second': 5.032, 'eval_steps_per_second': 0.335, 'epoch': 20.0}\n","Accuracy for fold  1 :  0.9195987423266957\n","--------------------------------\n","FOLD 2\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1930\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2400\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2400' max='2400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2400/2400 17:29, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.049500</td>\n","      <td>0.052560</td>\n","      <td>0.957545</td>\n","      <td>0.936554</td>\n","      <td>0.982265</td>\n","      <td>0.984525</td>\n","      <td>0.984525</td>\n","      <td>0.984525</td>\n","      <td>0.951894</td>\n","      <td>0.926235</td>\n","      <td>0.981888</td>\n","      <td>0.964196</td>\n","      <td>0.944687</td>\n","      <td>0.984527</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.016500</td>\n","      <td>0.020772</td>\n","      <td>0.961748</td>\n","      <td>0.944221</td>\n","      <td>0.981397</td>\n","      <td>0.986110</td>\n","      <td>0.986110</td>\n","      <td>0.986110</td>\n","      <td>0.956602</td>\n","      <td>0.935230</td>\n","      <td>0.980440</td>\n","      <td>0.966876</td>\n","      <td>0.951262</td>\n","      <td>0.983010</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.008700</td>\n","      <td>0.013160</td>\n","      <td>0.963723</td>\n","      <td>0.947456</td>\n","      <td>0.982135</td>\n","      <td>0.987167</td>\n","      <td>0.987167</td>\n","      <td>0.987167</td>\n","      <td>0.958847</td>\n","      <td>0.939037</td>\n","      <td>0.981150</td>\n","      <td>0.969960</td>\n","      <td>0.955817</td>\n","      <td>0.984527</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.006300</td>\n","      <td>0.011043</td>\n","      <td>0.964176</td>\n","      <td>0.947610</td>\n","      <td>0.982823</td>\n","      <td>0.987469</td>\n","      <td>0.987469</td>\n","      <td>0.987469</td>\n","      <td>0.959334</td>\n","      <td>0.939167</td>\n","      <td>0.981920</td>\n","      <td>0.970412</td>\n","      <td>0.956125</td>\n","      <td>0.985133</td>\n","    </tr>\n","    <tr>\n","      <td>2325</td>\n","      <td>0.007900</td>\n","      <td>0.010605</td>\n","      <td>0.964409</td>\n","      <td>0.947994</td>\n","      <td>0.982837</td>\n","      <td>0.987544</td>\n","      <td>0.987544</td>\n","      <td>0.987544</td>\n","      <td>0.959596</td>\n","      <td>0.939614</td>\n","      <td>0.981920</td>\n","      <td>0.970557</td>\n","      <td>0.956406</td>\n","      <td>0.985133</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2325\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.96440856511848, 'eval_macro_precision': 0.9479941507221205, 'eval_macro_recall': 0.9828374433008614, 'eval_micro_f1': 0.9875443496640749, 'eval_micro_precision': 0.9875443496640749, 'eval_micro_recall': 0.9875443496640749, 'eval_macro_f1_no_o': 0.9595960183245706, 'eval_macro_precision_no_o': 0.9396140988361131, 'eval_macro_recall_no_o': 0.981919870498913, 'eval_micro_f1_no_o': 0.9705574652518308, 'eval_micro_precision_no_o': 0.9564064801178204, 'eval_micro_recall_no_o': 0.9851334951456311, 'eval_loss': 0.01060348430534456, 'eval_runtime': 5.9842, 'eval_samples_per_second': 5.013, 'eval_steps_per_second': 0.334, 'epoch': 20.0}\n","Accuracy for fold  2 :  0.9705574652518308\n","--------------------------------\n","FOLD 3\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1930\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2400\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2400' max='2400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2400/2400 17:28, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.044400</td>\n","      <td>0.054563</td>\n","      <td>0.962022</td>\n","      <td>0.959396</td>\n","      <td>0.965089</td>\n","      <td>0.986476</td>\n","      <td>0.986476</td>\n","      <td>0.986476</td>\n","      <td>0.956623</td>\n","      <td>0.953157</td>\n","      <td>0.960602</td>\n","      <td>0.964169</td>\n","      <td>0.957647</td>\n","      <td>0.970781</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.016200</td>\n","      <td>0.023185</td>\n","      <td>0.966149</td>\n","      <td>0.964788</td>\n","      <td>0.967826</td>\n","      <td>0.987642</td>\n","      <td>0.987642</td>\n","      <td>0.987642</td>\n","      <td>0.961386</td>\n","      <td>0.959359</td>\n","      <td>0.963778</td>\n","      <td>0.967742</td>\n","      <td>0.960635</td>\n","      <td>0.974955</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.008700</td>\n","      <td>0.016024</td>\n","      <td>0.965666</td>\n","      <td>0.964543</td>\n","      <td>0.967133</td>\n","      <td>0.987409</td>\n","      <td>0.987409</td>\n","      <td>0.987409</td>\n","      <td>0.960822</td>\n","      <td>0.959057</td>\n","      <td>0.962986</td>\n","      <td>0.966864</td>\n","      <td>0.959483</td>\n","      <td>0.974359</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.006700</td>\n","      <td>0.013759</td>\n","      <td>0.965281</td>\n","      <td>0.963702</td>\n","      <td>0.967212</td>\n","      <td>0.987642</td>\n","      <td>0.987642</td>\n","      <td>0.987642</td>\n","      <td>0.960355</td>\n","      <td>0.958075</td>\n","      <td>0.963044</td>\n","      <td>0.967446</td>\n","      <td>0.960341</td>\n","      <td>0.974657</td>\n","    </tr>\n","    <tr>\n","      <td>2325</td>\n","      <td>0.006100</td>\n","      <td>0.013329</td>\n","      <td>0.965363</td>\n","      <td>0.963845</td>\n","      <td>0.967227</td>\n","      <td>0.987720</td>\n","      <td>0.987720</td>\n","      <td>0.987720</td>\n","      <td>0.960442</td>\n","      <td>0.958242</td>\n","      <td>0.963044</td>\n","      <td>0.967589</td>\n","      <td>0.960623</td>\n","      <td>0.974657</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2325\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.9653625368667559, 'eval_macro_precision': 0.963844921441649, 'eval_macro_recall': 0.9672274607332901, 'eval_micro_f1': 0.9877195709622261, 'eval_micro_precision': 0.9877195709622261, 'eval_micro_recall': 0.9877195709622261, 'eval_macro_f1_no_o': 0.9604416245878511, 'eval_macro_precision_no_o': 0.9582417739479423, 'eval_macro_recall_no_o': 0.9630444569222277, 'eval_micro_f1_no_o': 0.9675891667899955, 'eval_micro_precision_no_o': 0.9606229797237732, 'eval_micro_recall_no_o': 0.9746571258199165, 'eval_loss': 0.013327692839569256, 'eval_runtime': 5.9777, 'eval_samples_per_second': 5.019, 'eval_steps_per_second': 0.335, 'epoch': 20.0}\n","Accuracy for fold  3 :  0.9675891667899955\n","--------------------------------\n","FOLD 4\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1930\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2400\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2400' max='2400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2400/2400 17:28, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.041200</td>\n","      <td>0.048911</td>\n","      <td>0.972312</td>\n","      <td>0.961618</td>\n","      <td>0.983504</td>\n","      <td>0.990557</td>\n","      <td>0.990557</td>\n","      <td>0.990557</td>\n","      <td>0.968444</td>\n","      <td>0.955452</td>\n","      <td>0.982015</td>\n","      <td>0.975796</td>\n","      <td>0.966860</td>\n","      <td>0.984898</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.015700</td>\n","      <td>0.019438</td>\n","      <td>0.972349</td>\n","      <td>0.960683</td>\n","      <td>0.984586</td>\n","      <td>0.990557</td>\n","      <td>0.990557</td>\n","      <td>0.990557</td>\n","      <td>0.968513</td>\n","      <td>0.954345</td>\n","      <td>0.983344</td>\n","      <td>0.976253</td>\n","      <td>0.966618</td>\n","      <td>0.986082</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.008500</td>\n","      <td>0.013874</td>\n","      <td>0.969098</td>\n","      <td>0.956217</td>\n","      <td>0.982832</td>\n","      <td>0.990114</td>\n","      <td>0.990114</td>\n","      <td>0.990114</td>\n","      <td>0.964711</td>\n","      <td>0.949167</td>\n","      <td>0.981248</td>\n","      <td>0.974329</td>\n","      <td>0.965407</td>\n","      <td>0.983417</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.006400</td>\n","      <td>0.010461</td>\n","      <td>0.973510</td>\n","      <td>0.963802</td>\n","      <td>0.983583</td>\n","      <td>0.990778</td>\n","      <td>0.990778</td>\n","      <td>0.990778</td>\n","      <td>0.969825</td>\n","      <td>0.958016</td>\n","      <td>0.982058</td>\n","      <td>0.976369</td>\n","      <td>0.967986</td>\n","      <td>0.984898</td>\n","    </tr>\n","    <tr>\n","      <td>2325</td>\n","      <td>0.006200</td>\n","      <td>0.010288</td>\n","      <td>0.973450</td>\n","      <td>0.963683</td>\n","      <td>0.983583</td>\n","      <td>0.990778</td>\n","      <td>0.990778</td>\n","      <td>0.990778</td>\n","      <td>0.969756</td>\n","      <td>0.957878</td>\n","      <td>0.982058</td>\n","      <td>0.976369</td>\n","      <td>0.967986</td>\n","      <td>0.984898</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-2325\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.9734503131960354, 'eval_macro_precision': 0.9636834153478006, 'eval_macro_recall': 0.9835828129294909, 'eval_micro_f1': 0.9907783105864995, 'eval_micro_precision': 0.9907783105864995, 'eval_micro_recall': 0.9907783105864995, 'eval_macro_f1_no_o': 0.9697561794729888, 'eval_macro_precision_no_o': 0.9578777112252652, 'eval_macro_recall_no_o': 0.9820583790196914, 'eval_micro_f1_no_o': 0.9763687068838984, 'eval_micro_precision_no_o': 0.9679860302677532, 'eval_micro_recall_no_o': 0.9848978383180338, 'eval_loss': 0.010286054790291625, 'eval_runtime': 5.9773, 'eval_samples_per_second': 5.019, 'eval_steps_per_second': 0.335, 'epoch': 20.0}\n","Accuracy for fold  4 :  0.9763687068838984\n","--------------------------------\n"]}],"source":["for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    #train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    #test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    local_train = []\n","    #i = 0\n","    for idx in train_ids:\n","      #if i <= 1920:\n","        local_train.append(dataset[idx])\n","      #i += 1\n","    \n","    local_test = []\n","    #i = 0\n","    for idx in test_ids:\n","      #if i <= 480:\n","        local_test.append(dataset[idx])\n","      #i += 1\n","\n","    training_args = TrainingArguments(\"trained_scibert_ner_model\", # output dir\n","                                      learning_rate=2.5923213776958604e-05, \n","                                      num_train_epochs=20, \n","                                      per_device_eval_batch_size=16, \n","                                      per_device_train_batch_size=16,\n","                                      logging_steps=50,\n","                                      save_steps=len(train) // batch_size,\n","                                      lr_scheduler_type='cosine',\n","                                      evaluation_strategy='steps',\n","                                      weight_decay=0.028135787671833536,\n","                                      dataloader_drop_last=True,\n","                                      eval_steps=len(train) // batch_size\n","                                      )\n","\n","    #learning_rate 2.5923213776958604e-05\n","    #num_train_epochs 20\n","    #weight_decay 0.028135787671833536\n","    #per_device_train_batch_size 16\n","\n","    # Init the neural network\n","    ner_model = NerModel(BertEmbModel).to('cuda')  # make sure we move the model to the GPU for training\n","    \n","    trainer = MultilabelTrainer(model=ner_model,\n","                                args=training_args,\n","                                train_dataset=local_train,\n","                                eval_dataset=local_test,\n","                                data_collator=collator  # defines how to merge data into batches, using the collator function above\n","                                )\n","\n","    ##Loading Best parameters\n","    #load_param()\n","\n","    #Training\n","    trainer.train()\n","          \n","    # Process is complete.\n","    print('Training process has finished. Saving trained model.')\n","\n","    # Print about testing\n","    print('Starting testing')\n","    \n","    # Saving the model\n","    save_path = f'./model-fold-{fold}.pth'\n","    torch.save(ner_model.state_dict(), save_path)\n","\n","    # Evaluationfor this fold\n","    #correct, total = 0, 0\n","    with torch.no_grad():\n","      result = trainer.evaluate(local_test)\n","      print(result)\n","\n","      # Print accuracy\n","      print('Accuracy for fold ', fold, ': ', result['eval_micro_f1_no_o'])\n","      print('--------------------------------')\n","      results[fold] = result['eval_micro_f1_no_o']\n","      resultss[fold] = result['eval_micro_f1']\n","      del result\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"BBA4owXH8oS1"},"source":["# Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dhusoblW-oCA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646895313663,"user_tz":360,"elapsed":18,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"f562816e-c38a-40ba-deb1-143098963472"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.72298678, 0.91959874, 0.97055747, 0.96758917, 0.97636871])"]},"metadata":{},"execution_count":22}],"source":["results"]},{"cell_type":"code","source":["resultss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xeeO0R_XKmZo","executionInfo":{"status":"ok","timestamp":1646895313664,"user_tz":360,"elapsed":9,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"a61360c0-6097-4773-b74a-42be39f2d7f5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.89364889, 0.97005761, 0.98754435, 0.98771957, 0.99077831])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yPIH-gt_-foF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646895313664,"user_tz":360,"elapsed":7,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"bb8e3e7d-ee96-4477-8109-1e2b08e0c0f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n","--------------------------------\n","Fold 0: 0.722986782940455 %\n","Fold 1: 0.9195987423266957 %\n","Fold 2: 0.9705574652518308 %\n","Fold 3: 0.9675891667899955 %\n","Fold 4: 0.9763687068838984 %\n","Average: 0.9114201728385751 %\n"]}],"source":["# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","key = 0\n","for value in results:\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","  key += 1\n","print(f'Average: {sum/len(results)} %')"]},{"cell_type":"markdown","metadata":{"id":"1DkDHptAhniL"},"source":["# Pytorch Training - Loop UPDT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rirS-e83GVn0"},"outputs":[],"source":["device = 'cuda'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KSDdzo_so0vk"},"outputs":[],"source":["training_args = TrainingArguments(\"trained_scibert_ner_model\", # output dir\n","                                      learning_rate=2.5923213776958604e-05, \n","                                      weight_decay=0.028135787671833536,\n","                                      num_train_epochs=20, \n","                                      per_device_eval_batch_size=16,\n","                                      per_device_train_batch_size=16,\n","                                      logging_steps=50,\n","                                      dataloader_drop_last=True,\n","                                      save_steps=len(train) // batch_size,\n","                                      eval_steps=len(train) // batch_size,\n","                                      lr_scheduler_type='cosine',\n","                                      evaluation_strategy='steps',\n","                                      report_to='all'#,\n","                                      #warmup_ratio=0.2\n","                                      )\n","\n","#learning_rate 2.5923213776958604e-05\n","#num_train_epochs 20\n","#weight_decay 0.028135787671833536\n","#per_device_train_batch_size 16\n","\n","#load_param()"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d787455d-68b0-48f0-85b5-c8018e09b381","id":"nZR3aDuKyUqy","executionInfo":{"status":"ok","timestamp":1647127220523,"user_tz":360,"elapsed":14522326,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"source":["loop_val = 10\n","loop_results = np.zeros(loop_val)\n","loop_resultss = np.zeros(loop_val)\n","for r in range(loop_val):\n","\n","  ner_model = NerModel(BertEmbModel).to('cuda')  # make sure we move the model to the GPU for training\n","\n","  trainer = MultilabelTrainer(\n","      model=ner_model, \n","      args=training_args, \n","      train_dataset=train, \n","      eval_dataset=test,\n","      data_collator=collator  # defines how to merge data into batches, using the collator function above\n","  )\n","\n","  # Print\n","  print(f'Train run #{r}')\n","  print('--------------------------------')\n","\n","  trainer.train()\n","\n","  # Process is complete.\n","  print('Training process has finished.')\n","\n","  # Print about testing\n","  print('Starting testing')\n","\n","  with torch.no_grad():\n","    result = trainer.evaluate(test)\n","    print(result)\n","\n","    # Print accuracy\n","    print('Accuracy for fold ', r, ': ', result['eval_micro_f1_no_o'], ' -- ', result['eval_micro_f1'])\n","    print('--------------------------------')\n","    loop_results[r] = result['eval_micro_f1_no_o']\n","    loop_resultss[r] = result['eval_micro_f1']\n","    del result\n","\n","  if r > 0:\n","    if loop_results[r] < loop_results[r-1]:\n","      save_path = f'./model-fold-{r}.pth'\n","      torch.save(ner_model.state_dict(), save_path)\n","\n","  print('Testing process has finished.')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2320\n"]},{"output_type":"stream","name":"stdout","text":["Train run #0\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2320/2320 35:51, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.043100</td>\n","      <td>0.112553</td>\n","      <td>0.634953</td>\n","      <td>0.608368</td>\n","      <td>0.672703</td>\n","      <td>0.886966</td>\n","      <td>0.886966</td>\n","      <td>0.886966</td>\n","      <td>0.580817</td>\n","      <td>0.547576</td>\n","      <td>0.627023</td>\n","      <td>0.689484</td>\n","      <td>0.664754</td>\n","      <td>0.716126</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.012300</td>\n","      <td>0.078683</td>\n","      <td>0.642579</td>\n","      <td>0.605309</td>\n","      <td>0.696520</td>\n","      <td>0.886632</td>\n","      <td>0.886632</td>\n","      <td>0.886632</td>\n","      <td>0.590127</td>\n","      <td>0.542561</td>\n","      <td>0.656944</td>\n","      <td>0.702553</td>\n","      <td>0.659656</td>\n","      <td>0.751417</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.006800</td>\n","      <td>0.079707</td>\n","      <td>0.642687</td>\n","      <td>0.611882</td>\n","      <td>0.689004</td>\n","      <td>0.891309</td>\n","      <td>0.891309</td>\n","      <td>0.891309</td>\n","      <td>0.589665</td>\n","      <td>0.551092</td>\n","      <td>0.646251</td>\n","      <td>0.704447</td>\n","      <td>0.675089</td>\n","      <td>0.736476</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.005000</td>\n","      <td>0.078377</td>\n","      <td>0.649642</td>\n","      <td>0.622049</td>\n","      <td>0.687444</td>\n","      <td>0.893780</td>\n","      <td>0.893780</td>\n","      <td>0.893780</td>\n","      <td>0.597510</td>\n","      <td>0.562928</td>\n","      <td>0.643935</td>\n","      <td>0.708225</td>\n","      <td>0.681180</td>\n","      <td>0.737506</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2320\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_macro_f1': 0.6491221439722131, 'eval_macro_precision': 0.6212911739714586, 'eval_macro_recall': 0.6872948343378331, 'eval_micro_f1': 0.8938472843877346, 'eval_micro_precision': 0.8938472843877346, 'eval_micro_recall': 0.8938472843877346, 'eval_macro_f1_no_o': 0.5969067902812537, 'eval_macro_precision_no_o': 0.5621762512371274, 'eval_macro_recall_no_o': 0.6436406722306137, 'eval_micro_f1_no_o': 0.7079821517104611, 'eval_micro_precision_no_o': 0.6822742474916388, 'eval_micro_recall_no_o': 0.7357032457496137, 'eval_loss': 0.07871574303129926, 'eval_runtime': 17.8756, 'eval_samples_per_second': 1.902, 'eval_steps_per_second': 0.168, 'epoch': 20.0}\n","Accuracy for fold  0 :  0.7079821517104611  --  0.8938472843877346\n","--------------------------------\n","Testing process has finished.\n","Train run #1\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2320/2320 30:52, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.027600</td>\n","      <td>0.133964</td>\n","      <td>0.740995</td>\n","      <td>0.706528</td>\n","      <td>0.789184</td>\n","      <td>0.892511</td>\n","      <td>0.892511</td>\n","      <td>0.892511</td>\n","      <td>0.704371</td>\n","      <td>0.661573</td>\n","      <td>0.763097</td>\n","      <td>0.708914</td>\n","      <td>0.679830</td>\n","      <td>0.740598</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.009400</td>\n","      <td>0.110268</td>\n","      <td>0.743547</td>\n","      <td>0.708976</td>\n","      <td>0.796506</td>\n","      <td>0.897254</td>\n","      <td>0.897254</td>\n","      <td>0.897254</td>\n","      <td>0.706976</td>\n","      <td>0.664426</td>\n","      <td>0.770919</td>\n","      <td>0.718928</td>\n","      <td>0.693301</td>\n","      <td>0.746522</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.005400</td>\n","      <td>0.093216</td>\n","      <td>0.757352</td>\n","      <td>0.727480</td>\n","      <td>0.794081</td>\n","      <td>0.902331</td>\n","      <td>0.902331</td>\n","      <td>0.902331</td>\n","      <td>0.723072</td>\n","      <td>0.685852</td>\n","      <td>0.768224</td>\n","      <td>0.738184</td>\n","      <td>0.710238</td>\n","      <td>0.768418</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.004000</td>\n","      <td>0.097977</td>\n","      <td>0.759603</td>\n","      <td>0.734710</td>\n","      <td>0.790611</td>\n","      <td>0.903467</td>\n","      <td>0.903467</td>\n","      <td>0.903467</td>\n","      <td>0.725552</td>\n","      <td>0.694823</td>\n","      <td>0.763379</td>\n","      <td>0.737487</td>\n","      <td>0.717032</td>\n","      <td>0.759145</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2320\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_macro_f1': 0.7615951095470415, 'eval_macro_precision': 0.7402064854193501, 'eval_macro_recall': 0.7881304095387488, 'eval_micro_f1': 0.9040016033135148, 'eval_micro_precision': 0.9040016033135146, 'eval_micro_recall': 0.9040016033135146, 'eval_macro_f1_no_o': 0.7278583496171559, 'eval_macro_precision_no_o': 0.7012785978860241, 'eval_macro_recall_no_o': 0.7604102846260297, 'eval_micro_f1_no_o': 0.7389779559118237, 'eval_micro_precision_no_o': 0.7191613846903949, 'eval_micro_recall_no_o': 0.7599175682637815, 'eval_loss': 0.09610259697996405, 'eval_runtime': 18.784, 'eval_samples_per_second': 1.81, 'eval_steps_per_second': 0.16, 'epoch': 20.0}\n","Accuracy for fold  1 :  0.7389779559118237  --  0.9040016033135148\n","--------------------------------\n","Testing process has finished.\n","Train run #2\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2320/2320 33:40, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.017700</td>\n","      <td>0.117935</td>\n","      <td>0.759655</td>\n","      <td>0.744527</td>\n","      <td>0.783828</td>\n","      <td>0.898657</td>\n","      <td>0.898657</td>\n","      <td>0.898657</td>\n","      <td>0.725903</td>\n","      <td>0.705717</td>\n","      <td>0.756563</td>\n","      <td>0.727542</td>\n","      <td>0.698247</td>\n","      <td>0.759402</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.006700</td>\n","      <td>0.100786</td>\n","      <td>0.758039</td>\n","      <td>0.724172</td>\n","      <td>0.799677</td>\n","      <td>0.897388</td>\n","      <td>0.897388</td>\n","      <td>0.897388</td>\n","      <td>0.724215</td>\n","      <td>0.681409</td>\n","      <td>0.775956</td>\n","      <td>0.728847</td>\n","      <td>0.691898</td>\n","      <td>0.769964</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.004100</td>\n","      <td>0.100723</td>\n","      <td>0.761205</td>\n","      <td>0.740413</td>\n","      <td>0.786878</td>\n","      <td>0.902064</td>\n","      <td>0.902064</td>\n","      <td>0.902064</td>\n","      <td>0.727550</td>\n","      <td>0.701176</td>\n","      <td>0.759565</td>\n","      <td>0.735992</td>\n","      <td>0.710823</td>\n","      <td>0.763009</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.003100</td>\n","      <td>0.101803</td>\n","      <td>0.761354</td>\n","      <td>0.736382</td>\n","      <td>0.792045</td>\n","      <td>0.902198</td>\n","      <td>0.902198</td>\n","      <td>0.902198</td>\n","      <td>0.727621</td>\n","      <td>0.696703</td>\n","      <td>0.765172</td>\n","      <td>0.733542</td>\n","      <td>0.712103</td>\n","      <td>0.756311</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.7616267030870538, 'eval_macro_precision': 0.7328995051947513, 'eval_macro_recall': 0.7972543407149761, 'eval_micro_f1': 0.9021310708798183, 'eval_micro_precision': 0.9021310708798183, 'eval_micro_recall': 0.9021310708798183, 'eval_macro_f1_no_o': 0.7278811947087155, 'eval_macro_precision_no_o': 0.6922845481089069, 'eval_macro_recall_no_o': 0.771475784380334, 'eval_micro_f1_no_o': 0.7334659373446047, 'eval_micro_precision_no_o': 0.7087938491110043, 'eval_micro_recall_no_o': 0.7599175682637815, 'eval_loss': 0.10070674285110298, 'eval_runtime': 20.887, 'eval_samples_per_second': 1.628, 'eval_steps_per_second': 0.144, 'epoch': 20.0}\n","Accuracy for fold  2 :  0.7334659373446047  --  0.9021310708798183\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2320\n"]},{"output_type":"stream","name":"stdout","text":["Testing process has finished.\n","Train run #3\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2320/2320 25:39, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.017100</td>\n","      <td>0.119026</td>\n","      <td>0.761921</td>\n","      <td>0.728469</td>\n","      <td>0.806222</td>\n","      <td>0.901864</td>\n","      <td>0.901864</td>\n","      <td>0.901864</td>\n","      <td>0.728087</td>\n","      <td>0.686755</td>\n","      <td>0.782014</td>\n","      <td>0.731079</td>\n","      <td>0.704128</td>\n","      <td>0.760175</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.006300</td>\n","      <td>0.103800</td>\n","      <td>0.775002</td>\n","      <td>0.758778</td>\n","      <td>0.796242</td>\n","      <td>0.904202</td>\n","      <td>0.904202</td>\n","      <td>0.904202</td>\n","      <td>0.743792</td>\n","      <td>0.722726</td>\n","      <td>0.770655</td>\n","      <td>0.746398</td>\n","      <td>0.720624</td>\n","      <td>0.774086</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.004000</td>\n","      <td>0.102846</td>\n","      <td>0.763727</td>\n","      <td>0.741003</td>\n","      <td>0.792003</td>\n","      <td>0.901797</td>\n","      <td>0.901797</td>\n","      <td>0.901797</td>\n","      <td>0.730562</td>\n","      <td>0.702321</td>\n","      <td>0.765244</td>\n","      <td>0.734684</td>\n","      <td>0.713800</td>\n","      <td>0.756826</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.003000</td>\n","      <td>0.098245</td>\n","      <td>0.770899</td>\n","      <td>0.750528</td>\n","      <td>0.797000</td>\n","      <td>0.905204</td>\n","      <td>0.905204</td>\n","      <td>0.905204</td>\n","      <td>0.738757</td>\n","      <td>0.713409</td>\n","      <td>0.770759</td>\n","      <td>0.744046</td>\n","      <td>0.724609</td>\n","      <td>0.764554</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2320\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_macro_f1': 0.7722964733686241, 'eval_macro_precision': 0.7545086452395656, 'eval_macro_recall': 0.7948576781825656, 'eval_micro_f1': 0.9060725499365355, 'eval_micro_precision': 0.9060725499365355, 'eval_micro_recall': 0.9060725499365355, 'eval_macro_f1_no_o': 0.7403104468566375, 'eval_macro_precision_no_o': 0.7182094624884684, 'eval_macro_recall_no_o': 0.7679581122947406, 'eval_micro_f1_no_o': 0.7451868629671574, 'eval_micro_precision_no_o': 0.7284132841328413, 'eval_micro_recall_no_o': 0.7627511591962906, 'eval_loss': 0.09831665345133361, 'eval_runtime': 8.6498, 'eval_samples_per_second': 3.931, 'eval_steps_per_second': 0.347, 'epoch': 20.0}\n","Accuracy for fold  3 :  0.7451868629671574  --  0.9060725499365355\n","--------------------------------\n","Testing process has finished.\n","Train run #4\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2320/2320 19:02, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.015800</td>\n","      <td>0.121515</td>\n","      <td>0.756521</td>\n","      <td>0.737809</td>\n","      <td>0.780659</td>\n","      <td>0.902465</td>\n","      <td>0.902465</td>\n","      <td>0.902465</td>\n","      <td>0.721857</td>\n","      <td>0.698768</td>\n","      <td>0.751258</td>\n","      <td>0.730435</td>\n","      <td>0.715026</td>\n","      <td>0.746522</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.006100</td>\n","      <td>0.106014</td>\n","      <td>0.759665</td>\n","      <td>0.731754</td>\n","      <td>0.794650</td>\n","      <td>0.896920</td>\n","      <td>0.896920</td>\n","      <td>0.896920</td>\n","      <td>0.726337</td>\n","      <td>0.690414</td>\n","      <td>0.770377</td>\n","      <td>0.730971</td>\n","      <td>0.693232</td>\n","      <td>0.773055</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.003700</td>\n","      <td>0.103157</td>\n","      <td>0.767189</td>\n","      <td>0.742360</td>\n","      <td>0.796835</td>\n","      <td>0.903000</td>\n","      <td>0.903000</td>\n","      <td>0.903000</td>\n","      <td>0.734527</td>\n","      <td>0.703358</td>\n","      <td>0.771257</td>\n","      <td>0.739702</td>\n","      <td>0.713499</td>\n","      <td>0.767903</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.002900</td>\n","      <td>0.104072</td>\n","      <td>0.766776</td>\n","      <td>0.744386</td>\n","      <td>0.795628</td>\n","      <td>0.904603</td>\n","      <td>0.904603</td>\n","      <td>0.904603</td>\n","      <td>0.733831</td>\n","      <td>0.705961</td>\n","      <td>0.769202</td>\n","      <td>0.740500</td>\n","      <td>0.719281</td>\n","      <td>0.763009</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.7695484931519047, 'eval_macro_precision': 0.7473076736779632, 'eval_macro_recall': 0.7971720936252479, 'eval_micro_f1': 0.9049368695303628, 'eval_micro_precision': 0.9049368695303628, 'eval_micro_recall': 0.9049368695303628, 'eval_macro_f1_no_o': 0.7370909324357156, 'eval_macro_precision_no_o': 0.7093274393733527, 'eval_macro_recall_no_o': 0.7710942096473626, 'eval_micro_f1_no_o': 0.7424147833687103, 'eval_micro_precision_no_o': 0.7203779985461595, 'eval_micro_recall_no_o': 0.7658423493044823, 'eval_loss': 0.10202517103543333, 'eval_runtime': 8.5697, 'eval_samples_per_second': 3.967, 'eval_steps_per_second': 0.35, 'epoch': 20.0}\n","Accuracy for fold  4 :  0.7424147833687103  --  0.9049368695303628\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2320\n"]},{"output_type":"stream","name":"stdout","text":["Testing process has finished.\n","Train run #5\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2320/2320 18:59, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.015500</td>\n","      <td>0.129363</td>\n","      <td>0.737461</td>\n","      <td>0.760897</td>\n","      <td>0.734184</td>\n","      <td>0.892778</td>\n","      <td>0.892778</td>\n","      <td>0.892778</td>\n","      <td>0.700710</td>\n","      <td>0.725203</td>\n","      <td>0.699638</td>\n","      <td>0.718389</td>\n","      <td>0.686210</td>\n","      <td>0.753735</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.005600</td>\n","      <td>0.121374</td>\n","      <td>0.764937</td>\n","      <td>0.756555</td>\n","      <td>0.780945</td>\n","      <td>0.900461</td>\n","      <td>0.900461</td>\n","      <td>0.900461</td>\n","      <td>0.731936</td>\n","      <td>0.720419</td>\n","      <td>0.752312</td>\n","      <td>0.729091</td>\n","      <td>0.708283</td>\n","      <td>0.751159</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.003400</td>\n","      <td>0.114593</td>\n","      <td>0.763863</td>\n","      <td>0.743508</td>\n","      <td>0.790084</td>\n","      <td>0.901931</td>\n","      <td>0.901931</td>\n","      <td>0.901931</td>\n","      <td>0.730618</td>\n","      <td>0.705267</td>\n","      <td>0.762780</td>\n","      <td>0.732991</td>\n","      <td>0.713589</td>\n","      <td>0.753478</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.002700</td>\n","      <td>0.107632</td>\n","      <td>0.762495</td>\n","      <td>0.745124</td>\n","      <td>0.785314</td>\n","      <td>0.900862</td>\n","      <td>0.900862</td>\n","      <td>0.900862</td>\n","      <td>0.729139</td>\n","      <td>0.706983</td>\n","      <td>0.757606</td>\n","      <td>0.732011</td>\n","      <td>0.709451</td>\n","      <td>0.756054</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.7649533293138192, 'eval_macro_precision': 0.7481919326735821, 'eval_macro_recall': 0.7859877292217574, 'eval_micro_f1': 0.9018638519607188, 'eval_micro_precision': 0.9018638519607188, 'eval_micro_recall': 0.9018638519607188, 'eval_macro_f1_no_o': 0.7319539769779433, 'eval_macro_precision_no_o': 0.7104871652115546, 'eval_macro_recall_no_o': 0.7583614695464863, 'eval_micro_f1_no_o': 0.7349788082772376, 'eval_micro_precision_no_o': 0.7120772946859903, 'eval_micro_recall_no_o': 0.7594023699124163, 'eval_loss': 0.10358966046870217, 'eval_runtime': 8.5853, 'eval_samples_per_second': 3.96, 'eval_steps_per_second': 0.349, 'epoch': 20.0}\n","Accuracy for fold  5 :  0.7349788082772376  --  0.9018638519607188\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2320\n"]},{"output_type":"stream","name":"stdout","text":["Testing process has finished.\n","Train run #6\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2320/2320 18:56, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.014500</td>\n","      <td>0.131154</td>\n","      <td>0.756536</td>\n","      <td>0.754448</td>\n","      <td>0.765375</td>\n","      <td>0.901263</td>\n","      <td>0.901263</td>\n","      <td>0.901263</td>\n","      <td>0.722007</td>\n","      <td>0.718403</td>\n","      <td>0.733472</td>\n","      <td>0.727755</td>\n","      <td>0.713437</td>\n","      <td>0.742658</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.005300</td>\n","      <td>0.110929</td>\n","      <td>0.755425</td>\n","      <td>0.725255</td>\n","      <td>0.794099</td>\n","      <td>0.897522</td>\n","      <td>0.897522</td>\n","      <td>0.897522</td>\n","      <td>0.721123</td>\n","      <td>0.683120</td>\n","      <td>0.768953</td>\n","      <td>0.726871</td>\n","      <td>0.694856</td>\n","      <td>0.761978</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.003300</td>\n","      <td>0.105179</td>\n","      <td>0.760952</td>\n","      <td>0.742038</td>\n","      <td>0.784061</td>\n","      <td>0.900862</td>\n","      <td>0.900862</td>\n","      <td>0.900862</td>\n","      <td>0.727357</td>\n","      <td>0.702884</td>\n","      <td>0.756655</td>\n","      <td>0.734265</td>\n","      <td>0.706064</td>\n","      <td>0.764812</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.002600</td>\n","      <td>0.104466</td>\n","      <td>0.762081</td>\n","      <td>0.737903</td>\n","      <td>0.791577</td>\n","      <td>0.902599</td>\n","      <td>0.902599</td>\n","      <td>0.902599</td>\n","      <td>0.728488</td>\n","      <td>0.698609</td>\n","      <td>0.764536</td>\n","      <td>0.734919</td>\n","      <td>0.714703</td>\n","      <td>0.756311</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.7605085090963813, 'eval_macro_precision': 0.7371476840695407, 'eval_macro_recall': 0.7894040132787293, 'eval_micro_f1': 0.9025318992584676, 'eval_micro_precision': 0.9025318992584676, 'eval_micro_recall': 0.9025318992584676, 'eval_macro_f1_no_o': 0.7265990614111936, 'eval_macro_precision_no_o': 0.6976958621459319, 'eval_macro_recall_no_o': 0.7619262208975813, 'eval_micro_f1_no_o': 0.7336922499060975, 'eval_micro_precision_no_o': 0.7137637028014616, 'eval_micro_recall_no_o': 0.7547655847501288, 'eval_loss': 0.10458462496610403, 'eval_runtime': 8.6522, 'eval_samples_per_second': 3.93, 'eval_steps_per_second': 0.347, 'epoch': 20.0}\n","Accuracy for fold  6 :  0.7336922499060975  --  0.9025318992584676\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2320\n"]},{"output_type":"stream","name":"stdout","text":["Testing process has finished.\n","Train run #7\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2320/2320 18:54, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.014300</td>\n","      <td>0.122295</td>\n","      <td>0.759980</td>\n","      <td>0.747404</td>\n","      <td>0.776045</td>\n","      <td>0.899927</td>\n","      <td>0.899927</td>\n","      <td>0.899927</td>\n","      <td>0.726303</td>\n","      <td>0.709546</td>\n","      <td>0.747077</td>\n","      <td>0.730889</td>\n","      <td>0.706221</td>\n","      <td>0.757342</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.005300</td>\n","      <td>0.121499</td>\n","      <td>0.758739</td>\n","      <td>0.742659</td>\n","      <td>0.779974</td>\n","      <td>0.899325</td>\n","      <td>0.899325</td>\n","      <td>0.899325</td>\n","      <td>0.724756</td>\n","      <td>0.704108</td>\n","      <td>0.751376</td>\n","      <td>0.726275</td>\n","      <td>0.703892</td>\n","      <td>0.750129</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.003200</td>\n","      <td>0.113973</td>\n","      <td>0.762345</td>\n","      <td>0.735656</td>\n","      <td>0.796501</td>\n","      <td>0.897989</td>\n","      <td>0.897989</td>\n","      <td>0.897989</td>\n","      <td>0.729187</td>\n","      <td>0.695090</td>\n","      <td>0.771890</td>\n","      <td>0.729011</td>\n","      <td>0.695347</td>\n","      <td>0.766100</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.002600</td>\n","      <td>0.116619</td>\n","      <td>0.758687</td>\n","      <td>0.737623</td>\n","      <td>0.784888</td>\n","      <td>0.901396</td>\n","      <td>0.901396</td>\n","      <td>0.901396</td>\n","      <td>0.724507</td>\n","      <td>0.698209</td>\n","      <td>0.756763</td>\n","      <td>0.730274</td>\n","      <td>0.709599</td>\n","      <td>0.752190</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.7613363568399147, 'eval_macro_precision': 0.7419616948152253, 'eval_macro_recall': 0.7850076049875749, 'eval_micro_f1': 0.9023314850691428, 'eval_micro_precision': 0.9023314850691428, 'eval_micro_recall': 0.9023314850691428, 'eval_macro_f1_no_o': 0.7275103795123594, 'eval_macro_precision_no_o': 0.7032948696081637, 'eval_macro_recall_no_o': 0.7567068821665117, 'eval_micro_f1_no_o': 0.7318967677273867, 'eval_micro_precision_no_o': 0.7124390243902439, 'eval_micro_recall_no_o': 0.752447192168985, 'eval_loss': 0.11650891274631944, 'eval_runtime': 8.4967, 'eval_samples_per_second': 4.002, 'eval_steps_per_second': 0.353, 'epoch': 20.0}\n","Accuracy for fold  7 :  0.7318967677273867  --  0.9023314850691428\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2320\n"]},{"output_type":"stream","name":"stdout","text":["Testing process has finished.\n","Train run #8\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2320/2320 18:53, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.014600</td>\n","      <td>0.139431</td>\n","      <td>0.738310</td>\n","      <td>0.701990</td>\n","      <td>0.793614</td>\n","      <td>0.890373</td>\n","      <td>0.890373</td>\n","      <td>0.890373</td>\n","      <td>0.701362</td>\n","      <td>0.655792</td>\n","      <td>0.768958</td>\n","      <td>0.705495</td>\n","      <td>0.670613</td>\n","      <td>0.744204</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.005200</td>\n","      <td>0.121177</td>\n","      <td>0.757305</td>\n","      <td>0.740154</td>\n","      <td>0.779330</td>\n","      <td>0.899392</td>\n","      <td>0.899392</td>\n","      <td>0.899392</td>\n","      <td>0.722943</td>\n","      <td>0.701149</td>\n","      <td>0.750384</td>\n","      <td>0.723798</td>\n","      <td>0.702644</td>\n","      <td>0.746265</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.003200</td>\n","      <td>0.115763</td>\n","      <td>0.758796</td>\n","      <td>0.735948</td>\n","      <td>0.788665</td>\n","      <td>0.901396</td>\n","      <td>0.901396</td>\n","      <td>0.901396</td>\n","      <td>0.724577</td>\n","      <td>0.696076</td>\n","      <td>0.761229</td>\n","      <td>0.729814</td>\n","      <td>0.707819</td>\n","      <td>0.753220</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.002500</td>\n","      <td>0.117288</td>\n","      <td>0.756441</td>\n","      <td>0.733687</td>\n","      <td>0.784762</td>\n","      <td>0.899258</td>\n","      <td>0.899258</td>\n","      <td>0.899258</td>\n","      <td>0.722006</td>\n","      <td>0.693402</td>\n","      <td>0.757052</td>\n","      <td>0.725532</td>\n","      <td>0.701371</td>\n","      <td>0.751417</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.7568041216657531, 'eval_macro_precision': 0.7336501895365161, 'eval_macro_recall': 0.7849774402403787, 'eval_micro_f1': 0.8993920769590487, 'eval_micro_precision': 0.8993920769590487, 'eval_micro_recall': 0.8993920769590487, 'eval_macro_f1_no_o': 0.722367644051542, 'eval_macro_precision_no_o': 0.6933126918374902, 'eval_macro_recall_no_o': 0.7572278969305725, 'eval_micro_f1_no_o': 0.7249657917651449, 'eval_micro_precision_no_o': 0.7009862881885975, 'eval_micro_recall_no_o': 0.7506439979392066, 'eval_loss': 0.11552489366402048, 'eval_runtime': 8.466, 'eval_samples_per_second': 4.016, 'eval_steps_per_second': 0.354, 'epoch': 20.0}\n","Accuracy for fold  8 :  0.7249657917651449  --  0.8993920769590487\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2320\n"]},{"output_type":"stream","name":"stdout","text":["Testing process has finished.\n","Train run #9\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2320/2320 18:52, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.013700</td>\n","      <td>0.133977</td>\n","      <td>0.757216</td>\n","      <td>0.738611</td>\n","      <td>0.782000</td>\n","      <td>0.902331</td>\n","      <td>0.902331</td>\n","      <td>0.902331</td>\n","      <td>0.722322</td>\n","      <td>0.699482</td>\n","      <td>0.752357</td>\n","      <td>0.723668</td>\n","      <td>0.709861</td>\n","      <td>0.738022</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.005200</td>\n","      <td>0.109011</td>\n","      <td>0.752938</td>\n","      <td>0.725180</td>\n","      <td>0.787692</td>\n","      <td>0.900528</td>\n","      <td>0.900528</td>\n","      <td>0.900528</td>\n","      <td>0.717695</td>\n","      <td>0.683569</td>\n","      <td>0.759944</td>\n","      <td>0.725341</td>\n","      <td>0.704639</td>\n","      <td>0.747295</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.003200</td>\n","      <td>0.117796</td>\n","      <td>0.757492</td>\n","      <td>0.735058</td>\n","      <td>0.786350</td>\n","      <td>0.899392</td>\n","      <td>0.899392</td>\n","      <td>0.899392</td>\n","      <td>0.723093</td>\n","      <td>0.695113</td>\n","      <td>0.758528</td>\n","      <td>0.722777</td>\n","      <td>0.701406</td>\n","      <td>0.745492</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.002500</td>\n","      <td>0.117814</td>\n","      <td>0.762498</td>\n","      <td>0.742793</td>\n","      <td>0.786038</td>\n","      <td>0.900862</td>\n","      <td>0.900862</td>\n","      <td>0.900862</td>\n","      <td>0.728935</td>\n","      <td>0.704297</td>\n","      <td>0.758014</td>\n","      <td>0.727682</td>\n","      <td>0.707917</td>\n","      <td>0.748583</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.7599838958188091, 'eval_macro_precision': 0.7376085113138944, 'eval_macro_recall': 0.7868553026705827, 'eval_micro_f1': 0.9001269289865722, 'eval_micro_precision': 0.9001269289865722, 'eval_micro_recall': 0.9001269289865722, 'eval_macro_f1_no_o': 0.7260302117278167, 'eval_macro_precision_no_o': 0.6981335505823619, 'eval_macro_recall_no_o': 0.7591331166375221, 'eval_micro_f1_no_o': 0.7259555333499874, 'eval_micro_precision_no_o': 0.7046556741028128, 'eval_micro_recall_no_o': 0.7485832045337455, 'eval_loss': 0.11795840750967139, 'eval_runtime': 8.445, 'eval_samples_per_second': 4.026, 'eval_steps_per_second': 0.355, 'epoch': 20.0}\n","Accuracy for fold  9 :  0.7259555333499874  --  0.9001269289865722\n","--------------------------------\n","Testing process has finished.\n"]}]},{"cell_type":"code","source":["loop_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"37joGfcX7dI-","executionInfo":{"status":"ok","timestamp":1647127220524,"user_tz":360,"elapsed":24,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"f3541808-6a71-4bbd-dd73-ba904c3eb761"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.70798215, 0.73897796, 0.73346594, 0.74518686, 0.74241478,\n","       0.73497881, 0.73369225, 0.73189677, 0.72496579, 0.72595553])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["loop_resultss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bq6V4lU77dFo","executionInfo":{"status":"ok","timestamp":1647127220525,"user_tz":360,"elapsed":16,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"f99c3faf-47a7-4d65-a241-e9bc09c68680"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.89384728, 0.9040016 , 0.90213107, 0.90607255, 0.90493687,\n","       0.90186385, 0.9025319 , 0.90233149, 0.89939208, 0.90012693])"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["sum = 0.0\n","for value in loop_results:\n","  sum += value\n","print(f'Average micro_f1_no_o: {sum/len(loop_results)} %')\n","\n","sum = 0.0\n","for value in loop_resultss:\n","  sum += value\n","print(f'Average micro_f1: {sum/len(loop_results)} %')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nbQeF-7e7dC2","executionInfo":{"status":"ok","timestamp":1647127220525,"user_tz":360,"elapsed":15,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"c98345ed-71d9-43ad-9cf4-e2a0f9259919"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average micro_f1_no_o: 0.7319516842328612 %\n","Average micro_f1: 0.9017235620281914 %\n"]}]},{"cell_type":"code","source":["ner_model = NerModel(BertEmbModel).to('cuda')  # make sure we move the model to the GPU for training\n","ner_model.load_state_dict(torch.load(save_path))\n","ner_model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DyHCTh__7c__","executionInfo":{"status":"ok","timestamp":1647127222370,"user_tz":360,"elapsed":1859,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"9c1c0a71-9755-4beb-9b1c-7b90813b1dcb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NerModel(\n","  (sci_embeddings): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (embd_dropout): Dropout(p=0.1, inplace=False)\n","  (ff_dropout): Dropout(p=0.1, inplace=False)\n","  (ff): Linear(in_features=200, out_features=14, bias=True)\n","  (tanh): Tanh()\n","  (lstm): LSTM(768, 100, bidirectional=True)\n","  (lstm_drop): Dropout(p=0.4, inplace=False)\n","  (ff_act): ReLU()\n","  (classifier): Linear(in_features=14, out_features=7, bias=True)\n",")"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"dcdDIwq0kXy2"},"source":["# Get Values of Thruth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uCnsc2rplFzW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647127222371,"user_tz":360,"elapsed":16,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"368ceff2-e62f-4f0a-b13c-b817cd5da14a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["NerModel(\n","  (sci_embeddings): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (embd_dropout): Dropout(p=0.1, inplace=False)\n","  (ff_dropout): Dropout(p=0.1, inplace=False)\n","  (ff): Linear(in_features=200, out_features=14, bias=True)\n","  (tanh): Tanh()\n","  (lstm): LSTM(768, 100, bidirectional=True)\n","  (lstm_drop): Dropout(p=0.4, inplace=False)\n","  (ff_act): ReLU()\n","  (classifier): Linear(in_features=14, out_features=7, bias=True)\n",")"]},"metadata":{},"execution_count":27}],"source":["# Pytorch thing (if we aren't training, do this)\n","ner_model.eval()\n","ner_model.to('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FVfjoHmcI0pL"},"outputs":[],"source":["output_preds = []\n","output_real = []\n","for x in range(len(test)):\n","  inputs1 = test[x]['input_ids'][0].clone().detach().to(torch.long).unsqueeze(0).to('cuda')\n","  inputs2 = test[x]['attention_mask'][0].clone().detach().to(torch.long).unsqueeze(0).to('cuda')\n","  inputs = {'input_ids': inputs1,  'attention_mask': inputs2}\n","  #print(inputs)\n","\n","  temp_test = test[x]\n","  temp_out = temp_test.pop(\"labels\")\n","  output_real.append(np.array(temp_out[temp_out != -100])) \n","\n","  gen_preds = ner_model(**inputs)\n","  label_preds = np.argmax(gen_preds.cpu().detach().numpy(), axis=-1)[0]\n","  output_preds.append(label_preds[temp_out != -100])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mXBvXjpP-VGh"},"outputs":[],"source":["for x in range(len(output_real)):\n","  output_real[x] = [ID2Entity(y) for y in output_real[x]]\n","  output_preds[x] = [ID2Entity(z) for z in output_preds[x]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pd1Xl1giQ7z7"},"outputs":[],"source":["#output_real[28]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5rslGT68vvC8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647127272938,"user_tz":360,"elapsed":1107,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"fb9990b8-48f0-4a2b-f046-f56aec14ca83"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[10669    52    31    23    53   319    70]\n"," [   53   562    72     4    17    59     0]\n"," [   43    92   904    15     1   104    18]\n"," [   12     2     1   110     0    14     1]\n"," [   30    19     0     0   278    46     2]\n"," [   91    73    86    18    48   896     6]\n"," [   40     4     8     0     1     3   201]]\n"]},{"output_type":"execute_result","data":{"text/plain":["<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f706be3fb50>"]},"metadata":{},"execution_count":31},{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x936 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["from sklearn.metrics import mean_squared_error, multilabel_confusion_matrix, confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support\n","import matplotlib.pyplot as plt\n","\n","plt.rcParams['figure.figsize'] = [15, 13]\n","plt.rcParams[\"figure.autolayout\"] = True\n","plt.rcParams.update({'font.size': 13})\n","\n","labels = [\"O\", \"I-Task\", \"I-Method\", \"I-Metric\", \"I-Material\", \"I-OtherScientificTerm\", \"I-Generic\"]\n","cm = confusion_matrix(output_real[0], output_preds[0], labels=labels)\n","for x in range(len(output_real)-1):\n","  cm += confusion_matrix(output_real[x+1], output_preds[x+1], labels=labels)\n","print(cm)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n","disp.plot(cmap=plt.cm.Blues)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m10aBi5x5Hdb"},"outputs":[],"source":["del cm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fgGd1XfheERK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647127272941,"user_tz":360,"elapsed":25,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"1cd62395-255f-4828-e4c3-dc9d47524957"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["551"]},"metadata":{},"execution_count":33}],"source":["len(output_real)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fHlg1QV3eZCa"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"k0w9Lc0d3iOT"},"source":["# Test over Text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mgNM3p1q3hrf"},"outputs":[],"source":["def prepare_input(txt):\n","  inputs = BertTokenizer(txt, return_tensors='pt', padding='max_length', truncation=True, max_length=150).to('cuda')\n","  return inputs\n","\n","input_text = [\"English is shown to be trans-context-free on the basis of coordinations of the respectively type that involve strictly syntactic cross-serial agreement.\"]\n","#input_text = [\"The transient analysis of gyro-elastic structured media, composed of periodically placed masses interconnected by elastic rods and attached to gyroscopic spinners, is presented.\"] \n","#input_text = [\"The results indicated that thermal curing promoted the early strength of mortars, while decreased the late strength of mortars.\"] \n","#input_text = [\"A wide variety of processes are attested in the literature, and we find different forms of clippings in our data, including mixtures of different clippings, homophone respellings, phonetic respellings in-cluding informal oral forms, initialisms (but no acronyms), and mixtures of clipping together with homo-phone and phonetic respellings.\"] \n","\n","input_text = [\"The goal is to accurately predict the running time of applications for task scheduling and job migration.\"] \n","input_text = [\"This paper reports on the development of a cross-domain framework for describing complex design practices.\"] \n","input_text = [\"Studies of inequality in China typically ignore cost of liv-ing differences between areas.\"] \n","input_text = [\"The present study was designed to explore the long-term differences be-tween three mouse models for depression.\"]\n","input_text = [\"Finally, regarding professional competencies, teachers appeared to be largely unprepared to conduct language assessments consistent with the LAR demands.\"] \n","\n","#input_text = [\"propose a fast and reliable restoration method of virtual resources on OpenStack when physical servers or virtual machines are down.\"] \n","#input_text = [\"The results from our simulations reveal that the network assisted adaptation clearly outperforms the purely client-based DASH heuristics in some of the metrics, not all of them, particularly, in situations when the achievable throughput is moderately high or the link quality of the mobile clients does not differ from each other substantially.\"] \n","#input_text = [\"For hard rock drilling in coal mine, the drilling efficiency and service life of polycrystalline diamond compact bit are very low.\"] \n","#input_text = [\"Capturing changes in foreign reserves and exchange rates through the exchange market pressure, this article investigates whether economic policy uncertainty plays any role in exchange market pressure movements while controlling for the effects of domestic and external factors.\"] \n","#input_text = [\"This paper presents design of an self contained actuators unit in wide area damping control of power system in stabilizing system response for both nominal system condition and during actuator faults.\"] \n","\n","#input_text = [\"Ultrasound-based brain stimulation techniques may become a powerful new technique to modulate the human brain in a focal and targeted manner.\"] \n","input_text = [\"Recent work pre-training Transformers with self-supervised objectives on large text corpora has shown great success when fine-tuned on downstream NLP tasks including text summarization.\"]\n","\n","# Tokenize + pad\n","inputs = prepare_input(input_text)\n","\n","#inputs\n","#print(inputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":187,"status":"ok","timestamp":1638235287124,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"jaG1vUq58BFI","outputId":"a7e17b9a-f8fa-45e9-a800-bb3401398c6b"},"outputs":[{"name":"stdout","output_type":"stream","text":["recent -> None\n","work -> None\n","pre -> None\n","- -> None\n","training -> None\n","transformers -> None\n","with -> None\n","self -> None\n","- -> None\n","supervised -> None\n","objectives -> None\n","on -> None\n","large -> Material\n","text -> Material\n","corpora -> Material\n","has -> None\n","shown -> None\n","great -> None\n","success -> None\n","when -> None\n","fine -> None\n","- -> None\n","tuned -> None\n","on -> None\n","downstream -> None\n","nl -> Task\n","##p -> Task\n","tasks -> None\n","including -> None\n","text -> Task\n","summar -> Task\n","##ization -> Task\n",". -> None\n"]}],"source":["# Pytorch thing (if we aren't training, do this)\n","ner_model.eval()\n","\n","# Get predictions\n","preds = ner_model(**inputs).cpu().detach().numpy()\n","preds = np.argmax(preds, axis=-1)[0]\n","pred_labels = [ID2Entity(x) for x in preds]\n","\n","# Convert token ids to text\n","tokens = BertTokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n","\n","# Display result\n","for token, label in zip(tokens, pred_labels):\n","  if token == '[SEP]':\n","    break\n","  if token == '[CLS]':\n","    continue\n","  print('{} -> {}'.format(token, label))"]},{"cell_type":"markdown","metadata":{"id":"hC35X0v72kXB"},"source":["# Model Save and Load"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":158,"status":"ok","timestamp":1637844465024,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"AnK4H5vP2kJU","outputId":"73e317f0-1cc0-4962-a048-cc7352855f38"},"outputs":[{"name":"stdout","output_type":"stream","text":["Our model: \n","\n"," NerModel(\n","  (sci_embeddings): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (embd_dropout): Dropout(p=0.1, inplace=False)\n","  (ff_dropout): Dropout(p=0.1, inplace=False)\n","  (ff): Linear(in_features=200, out_features=14, bias=True)\n","  (tanh): Tanh()\n","  (lstm): LSTM(768, 100, bidirectional=True)\n","  (lstm_drop): Dropout(p=0.4, inplace=False)\n","  (ff_act): ReLU()\n","  (classifier): Linear(in_features=14, out_features=7, bias=True)\n",") \n","\n","The state dict keys: \n","\n"," odict_keys(['sci_embeddings.embeddings.position_ids', 'sci_embeddings.embeddings.word_embeddings.weight', 'sci_embeddings.embeddings.position_embeddings.weight', 'sci_embeddings.embeddings.token_type_embeddings.weight', 'sci_embeddings.embeddings.LayerNorm.weight', 'sci_embeddings.embeddings.LayerNorm.bias', 'sci_embeddings.encoder.layer.0.attention.self.query.weight', 'sci_embeddings.encoder.layer.0.attention.self.query.bias', 'sci_embeddings.encoder.layer.0.attention.self.key.weight', 'sci_embeddings.encoder.layer.0.attention.self.key.bias', 'sci_embeddings.encoder.layer.0.attention.self.value.weight', 'sci_embeddings.encoder.layer.0.attention.self.value.bias', 'sci_embeddings.encoder.layer.0.attention.output.dense.weight', 'sci_embeddings.encoder.layer.0.attention.output.dense.bias', 'sci_embeddings.encoder.layer.0.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.0.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.0.intermediate.dense.weight', 'sci_embeddings.encoder.layer.0.intermediate.dense.bias', 'sci_embeddings.encoder.layer.0.output.dense.weight', 'sci_embeddings.encoder.layer.0.output.dense.bias', 'sci_embeddings.encoder.layer.0.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.0.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.1.attention.self.query.weight', 'sci_embeddings.encoder.layer.1.attention.self.query.bias', 'sci_embeddings.encoder.layer.1.attention.self.key.weight', 'sci_embeddings.encoder.layer.1.attention.self.key.bias', 'sci_embeddings.encoder.layer.1.attention.self.value.weight', 'sci_embeddings.encoder.layer.1.attention.self.value.bias', 'sci_embeddings.encoder.layer.1.attention.output.dense.weight', 'sci_embeddings.encoder.layer.1.attention.output.dense.bias', 'sci_embeddings.encoder.layer.1.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.1.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.1.intermediate.dense.weight', 'sci_embeddings.encoder.layer.1.intermediate.dense.bias', 'sci_embeddings.encoder.layer.1.output.dense.weight', 'sci_embeddings.encoder.layer.1.output.dense.bias', 'sci_embeddings.encoder.layer.1.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.1.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.2.attention.self.query.weight', 'sci_embeddings.encoder.layer.2.attention.self.query.bias', 'sci_embeddings.encoder.layer.2.attention.self.key.weight', 'sci_embeddings.encoder.layer.2.attention.self.key.bias', 'sci_embeddings.encoder.layer.2.attention.self.value.weight', 'sci_embeddings.encoder.layer.2.attention.self.value.bias', 'sci_embeddings.encoder.layer.2.attention.output.dense.weight', 'sci_embeddings.encoder.layer.2.attention.output.dense.bias', 'sci_embeddings.encoder.layer.2.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.2.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.2.intermediate.dense.weight', 'sci_embeddings.encoder.layer.2.intermediate.dense.bias', 'sci_embeddings.encoder.layer.2.output.dense.weight', 'sci_embeddings.encoder.layer.2.output.dense.bias', 'sci_embeddings.encoder.layer.2.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.2.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.3.attention.self.query.weight', 'sci_embeddings.encoder.layer.3.attention.self.query.bias', 'sci_embeddings.encoder.layer.3.attention.self.key.weight', 'sci_embeddings.encoder.layer.3.attention.self.key.bias', 'sci_embeddings.encoder.layer.3.attention.self.value.weight', 'sci_embeddings.encoder.layer.3.attention.self.value.bias', 'sci_embeddings.encoder.layer.3.attention.output.dense.weight', 'sci_embeddings.encoder.layer.3.attention.output.dense.bias', 'sci_embeddings.encoder.layer.3.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.3.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.3.intermediate.dense.weight', 'sci_embeddings.encoder.layer.3.intermediate.dense.bias', 'sci_embeddings.encoder.layer.3.output.dense.weight', 'sci_embeddings.encoder.layer.3.output.dense.bias', 'sci_embeddings.encoder.layer.3.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.3.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.4.attention.self.query.weight', 'sci_embeddings.encoder.layer.4.attention.self.query.bias', 'sci_embeddings.encoder.layer.4.attention.self.key.weight', 'sci_embeddings.encoder.layer.4.attention.self.key.bias', 'sci_embeddings.encoder.layer.4.attention.self.value.weight', 'sci_embeddings.encoder.layer.4.attention.self.value.bias', 'sci_embeddings.encoder.layer.4.attention.output.dense.weight', 'sci_embeddings.encoder.layer.4.attention.output.dense.bias', 'sci_embeddings.encoder.layer.4.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.4.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.4.intermediate.dense.weight', 'sci_embeddings.encoder.layer.4.intermediate.dense.bias', 'sci_embeddings.encoder.layer.4.output.dense.weight', 'sci_embeddings.encoder.layer.4.output.dense.bias', 'sci_embeddings.encoder.layer.4.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.4.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.5.attention.self.query.weight', 'sci_embeddings.encoder.layer.5.attention.self.query.bias', 'sci_embeddings.encoder.layer.5.attention.self.key.weight', 'sci_embeddings.encoder.layer.5.attention.self.key.bias', 'sci_embeddings.encoder.layer.5.attention.self.value.weight', 'sci_embeddings.encoder.layer.5.attention.self.value.bias', 'sci_embeddings.encoder.layer.5.attention.output.dense.weight', 'sci_embeddings.encoder.layer.5.attention.output.dense.bias', 'sci_embeddings.encoder.layer.5.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.5.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.5.intermediate.dense.weight', 'sci_embeddings.encoder.layer.5.intermediate.dense.bias', 'sci_embeddings.encoder.layer.5.output.dense.weight', 'sci_embeddings.encoder.layer.5.output.dense.bias', 'sci_embeddings.encoder.layer.5.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.5.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.6.attention.self.query.weight', 'sci_embeddings.encoder.layer.6.attention.self.query.bias', 'sci_embeddings.encoder.layer.6.attention.self.key.weight', 'sci_embeddings.encoder.layer.6.attention.self.key.bias', 'sci_embeddings.encoder.layer.6.attention.self.value.weight', 'sci_embeddings.encoder.layer.6.attention.self.value.bias', 'sci_embeddings.encoder.layer.6.attention.output.dense.weight', 'sci_embeddings.encoder.layer.6.attention.output.dense.bias', 'sci_embeddings.encoder.layer.6.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.6.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.6.intermediate.dense.weight', 'sci_embeddings.encoder.layer.6.intermediate.dense.bias', 'sci_embeddings.encoder.layer.6.output.dense.weight', 'sci_embeddings.encoder.layer.6.output.dense.bias', 'sci_embeddings.encoder.layer.6.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.6.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.7.attention.self.query.weight', 'sci_embeddings.encoder.layer.7.attention.self.query.bias', 'sci_embeddings.encoder.layer.7.attention.self.key.weight', 'sci_embeddings.encoder.layer.7.attention.self.key.bias', 'sci_embeddings.encoder.layer.7.attention.self.value.weight', 'sci_embeddings.encoder.layer.7.attention.self.value.bias', 'sci_embeddings.encoder.layer.7.attention.output.dense.weight', 'sci_embeddings.encoder.layer.7.attention.output.dense.bias', 'sci_embeddings.encoder.layer.7.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.7.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.7.intermediate.dense.weight', 'sci_embeddings.encoder.layer.7.intermediate.dense.bias', 'sci_embeddings.encoder.layer.7.output.dense.weight', 'sci_embeddings.encoder.layer.7.output.dense.bias', 'sci_embeddings.encoder.layer.7.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.7.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.8.attention.self.query.weight', 'sci_embeddings.encoder.layer.8.attention.self.query.bias', 'sci_embeddings.encoder.layer.8.attention.self.key.weight', 'sci_embeddings.encoder.layer.8.attention.self.key.bias', 'sci_embeddings.encoder.layer.8.attention.self.value.weight', 'sci_embeddings.encoder.layer.8.attention.self.value.bias', 'sci_embeddings.encoder.layer.8.attention.output.dense.weight', 'sci_embeddings.encoder.layer.8.attention.output.dense.bias', 'sci_embeddings.encoder.layer.8.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.8.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.8.intermediate.dense.weight', 'sci_embeddings.encoder.layer.8.intermediate.dense.bias', 'sci_embeddings.encoder.layer.8.output.dense.weight', 'sci_embeddings.encoder.layer.8.output.dense.bias', 'sci_embeddings.encoder.layer.8.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.8.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.9.attention.self.query.weight', 'sci_embeddings.encoder.layer.9.attention.self.query.bias', 'sci_embeddings.encoder.layer.9.attention.self.key.weight', 'sci_embeddings.encoder.layer.9.attention.self.key.bias', 'sci_embeddings.encoder.layer.9.attention.self.value.weight', 'sci_embeddings.encoder.layer.9.attention.self.value.bias', 'sci_embeddings.encoder.layer.9.attention.output.dense.weight', 'sci_embeddings.encoder.layer.9.attention.output.dense.bias', 'sci_embeddings.encoder.layer.9.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.9.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.9.intermediate.dense.weight', 'sci_embeddings.encoder.layer.9.intermediate.dense.bias', 'sci_embeddings.encoder.layer.9.output.dense.weight', 'sci_embeddings.encoder.layer.9.output.dense.bias', 'sci_embeddings.encoder.layer.9.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.9.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.10.attention.self.query.weight', 'sci_embeddings.encoder.layer.10.attention.self.query.bias', 'sci_embeddings.encoder.layer.10.attention.self.key.weight', 'sci_embeddings.encoder.layer.10.attention.self.key.bias', 'sci_embeddings.encoder.layer.10.attention.self.value.weight', 'sci_embeddings.encoder.layer.10.attention.self.value.bias', 'sci_embeddings.encoder.layer.10.attention.output.dense.weight', 'sci_embeddings.encoder.layer.10.attention.output.dense.bias', 'sci_embeddings.encoder.layer.10.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.10.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.10.intermediate.dense.weight', 'sci_embeddings.encoder.layer.10.intermediate.dense.bias', 'sci_embeddings.encoder.layer.10.output.dense.weight', 'sci_embeddings.encoder.layer.10.output.dense.bias', 'sci_embeddings.encoder.layer.10.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.10.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.11.attention.self.query.weight', 'sci_embeddings.encoder.layer.11.attention.self.query.bias', 'sci_embeddings.encoder.layer.11.attention.self.key.weight', 'sci_embeddings.encoder.layer.11.attention.self.key.bias', 'sci_embeddings.encoder.layer.11.attention.self.value.weight', 'sci_embeddings.encoder.layer.11.attention.self.value.bias', 'sci_embeddings.encoder.layer.11.attention.output.dense.weight', 'sci_embeddings.encoder.layer.11.attention.output.dense.bias', 'sci_embeddings.encoder.layer.11.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.11.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.11.intermediate.dense.weight', 'sci_embeddings.encoder.layer.11.intermediate.dense.bias', 'sci_embeddings.encoder.layer.11.output.dense.weight', 'sci_embeddings.encoder.layer.11.output.dense.bias', 'sci_embeddings.encoder.layer.11.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.11.output.LayerNorm.bias', 'sci_embeddings.pooler.dense.weight', 'sci_embeddings.pooler.dense.bias', 'ff.weight', 'ff.bias', 'lstm.weight_ih_l0', 'lstm.weight_hh_l0', 'lstm.bias_ih_l0', 'lstm.bias_hh_l0', 'lstm.weight_ih_l0_reverse', 'lstm.weight_hh_l0_reverse', 'lstm.bias_ih_l0_reverse', 'lstm.bias_hh_l0_reverse', 'classifier.weight', 'classifier.bias'])\n"]}],"source":["print(\"Our model: \\n\\n\", ner_model, '\\n')\n","print(\"The state dict keys: \\n\\n\", ner_model.state_dict().keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KftdO6GD2rWF"},"outputs":[],"source":["torch.save(ner_model.state_dict(), 'trained_model_dic.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1637655583613,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"kd4NJxK14P14","outputId":"8a1acc1b-ac77-4f86-f888-de233967043d"},"outputs":[{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_c004abdd-a72a-4d8d-94ca-c82c3c4c2640\", \"trained_model_dic.pth\", 442559655)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["# download checkpoint file\n","files.download('trained_model_dic.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1637655465909,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"l1hvL5Nb3kmo","outputId":"a2910628-2592-4edd-b135-c329d0352c5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["checkpoint.pth\t  model-fold-1.pth  model-fold-4.pth  trained_model_dic.pth\n","dev.json\t  model-fold-2.pth  sample_data       trained_scibert_ner_model\n","model-fold-0.pth  model-fold-3.pth  test.json\t      train.json\n"]}],"source":["!ls"]},{"cell_type":"markdown","metadata":{"id":"hQL7fqSY2x9e"},"source":["Loading the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":374,"status":"ok","timestamp":1638229478125,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"2ufmrdfeT6Qz","outputId":"a0fce754-147a-4881-e006-0e812e6bbdeb"},"outputs":[{"name":"stdout","output_type":"stream","text":["dev.json  sample_data  test.json  trained_model_dic.pth  train.json\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10317,"status":"ok","timestamp":1638229490872,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"a4Eus2gmJ-bS","outputId":"a7212f4c-979a-40fe-afc6-937b5651e87b"},"outputs":[{"name":"stdout","output_type":"stream","text":["odict_keys(['sci_embeddings.embeddings.position_ids', 'sci_embeddings.embeddings.word_embeddings.weight', 'sci_embeddings.embeddings.position_embeddings.weight', 'sci_embeddings.embeddings.token_type_embeddings.weight', 'sci_embeddings.embeddings.LayerNorm.weight', 'sci_embeddings.embeddings.LayerNorm.bias', 'sci_embeddings.encoder.layer.0.attention.self.query.weight', 'sci_embeddings.encoder.layer.0.attention.self.query.bias', 'sci_embeddings.encoder.layer.0.attention.self.key.weight', 'sci_embeddings.encoder.layer.0.attention.self.key.bias', 'sci_embeddings.encoder.layer.0.attention.self.value.weight', 'sci_embeddings.encoder.layer.0.attention.self.value.bias', 'sci_embeddings.encoder.layer.0.attention.output.dense.weight', 'sci_embeddings.encoder.layer.0.attention.output.dense.bias', 'sci_embeddings.encoder.layer.0.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.0.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.0.intermediate.dense.weight', 'sci_embeddings.encoder.layer.0.intermediate.dense.bias', 'sci_embeddings.encoder.layer.0.output.dense.weight', 'sci_embeddings.encoder.layer.0.output.dense.bias', 'sci_embeddings.encoder.layer.0.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.0.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.1.attention.self.query.weight', 'sci_embeddings.encoder.layer.1.attention.self.query.bias', 'sci_embeddings.encoder.layer.1.attention.self.key.weight', 'sci_embeddings.encoder.layer.1.attention.self.key.bias', 'sci_embeddings.encoder.layer.1.attention.self.value.weight', 'sci_embeddings.encoder.layer.1.attention.self.value.bias', 'sci_embeddings.encoder.layer.1.attention.output.dense.weight', 'sci_embeddings.encoder.layer.1.attention.output.dense.bias', 'sci_embeddings.encoder.layer.1.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.1.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.1.intermediate.dense.weight', 'sci_embeddings.encoder.layer.1.intermediate.dense.bias', 'sci_embeddings.encoder.layer.1.output.dense.weight', 'sci_embeddings.encoder.layer.1.output.dense.bias', 'sci_embeddings.encoder.layer.1.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.1.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.2.attention.self.query.weight', 'sci_embeddings.encoder.layer.2.attention.self.query.bias', 'sci_embeddings.encoder.layer.2.attention.self.key.weight', 'sci_embeddings.encoder.layer.2.attention.self.key.bias', 'sci_embeddings.encoder.layer.2.attention.self.value.weight', 'sci_embeddings.encoder.layer.2.attention.self.value.bias', 'sci_embeddings.encoder.layer.2.attention.output.dense.weight', 'sci_embeddings.encoder.layer.2.attention.output.dense.bias', 'sci_embeddings.encoder.layer.2.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.2.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.2.intermediate.dense.weight', 'sci_embeddings.encoder.layer.2.intermediate.dense.bias', 'sci_embeddings.encoder.layer.2.output.dense.weight', 'sci_embeddings.encoder.layer.2.output.dense.bias', 'sci_embeddings.encoder.layer.2.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.2.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.3.attention.self.query.weight', 'sci_embeddings.encoder.layer.3.attention.self.query.bias', 'sci_embeddings.encoder.layer.3.attention.self.key.weight', 'sci_embeddings.encoder.layer.3.attention.self.key.bias', 'sci_embeddings.encoder.layer.3.attention.self.value.weight', 'sci_embeddings.encoder.layer.3.attention.self.value.bias', 'sci_embeddings.encoder.layer.3.attention.output.dense.weight', 'sci_embeddings.encoder.layer.3.attention.output.dense.bias', 'sci_embeddings.encoder.layer.3.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.3.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.3.intermediate.dense.weight', 'sci_embeddings.encoder.layer.3.intermediate.dense.bias', 'sci_embeddings.encoder.layer.3.output.dense.weight', 'sci_embeddings.encoder.layer.3.output.dense.bias', 'sci_embeddings.encoder.layer.3.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.3.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.4.attention.self.query.weight', 'sci_embeddings.encoder.layer.4.attention.self.query.bias', 'sci_embeddings.encoder.layer.4.attention.self.key.weight', 'sci_embeddings.encoder.layer.4.attention.self.key.bias', 'sci_embeddings.encoder.layer.4.attention.self.value.weight', 'sci_embeddings.encoder.layer.4.attention.self.value.bias', 'sci_embeddings.encoder.layer.4.attention.output.dense.weight', 'sci_embeddings.encoder.layer.4.attention.output.dense.bias', 'sci_embeddings.encoder.layer.4.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.4.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.4.intermediate.dense.weight', 'sci_embeddings.encoder.layer.4.intermediate.dense.bias', 'sci_embeddings.encoder.layer.4.output.dense.weight', 'sci_embeddings.encoder.layer.4.output.dense.bias', 'sci_embeddings.encoder.layer.4.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.4.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.5.attention.self.query.weight', 'sci_embeddings.encoder.layer.5.attention.self.query.bias', 'sci_embeddings.encoder.layer.5.attention.self.key.weight', 'sci_embeddings.encoder.layer.5.attention.self.key.bias', 'sci_embeddings.encoder.layer.5.attention.self.value.weight', 'sci_embeddings.encoder.layer.5.attention.self.value.bias', 'sci_embeddings.encoder.layer.5.attention.output.dense.weight', 'sci_embeddings.encoder.layer.5.attention.output.dense.bias', 'sci_embeddings.encoder.layer.5.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.5.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.5.intermediate.dense.weight', 'sci_embeddings.encoder.layer.5.intermediate.dense.bias', 'sci_embeddings.encoder.layer.5.output.dense.weight', 'sci_embeddings.encoder.layer.5.output.dense.bias', 'sci_embeddings.encoder.layer.5.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.5.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.6.attention.self.query.weight', 'sci_embeddings.encoder.layer.6.attention.self.query.bias', 'sci_embeddings.encoder.layer.6.attention.self.key.weight', 'sci_embeddings.encoder.layer.6.attention.self.key.bias', 'sci_embeddings.encoder.layer.6.attention.self.value.weight', 'sci_embeddings.encoder.layer.6.attention.self.value.bias', 'sci_embeddings.encoder.layer.6.attention.output.dense.weight', 'sci_embeddings.encoder.layer.6.attention.output.dense.bias', 'sci_embeddings.encoder.layer.6.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.6.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.6.intermediate.dense.weight', 'sci_embeddings.encoder.layer.6.intermediate.dense.bias', 'sci_embeddings.encoder.layer.6.output.dense.weight', 'sci_embeddings.encoder.layer.6.output.dense.bias', 'sci_embeddings.encoder.layer.6.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.6.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.7.attention.self.query.weight', 'sci_embeddings.encoder.layer.7.attention.self.query.bias', 'sci_embeddings.encoder.layer.7.attention.self.key.weight', 'sci_embeddings.encoder.layer.7.attention.self.key.bias', 'sci_embeddings.encoder.layer.7.attention.self.value.weight', 'sci_embeddings.encoder.layer.7.attention.self.value.bias', 'sci_embeddings.encoder.layer.7.attention.output.dense.weight', 'sci_embeddings.encoder.layer.7.attention.output.dense.bias', 'sci_embeddings.encoder.layer.7.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.7.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.7.intermediate.dense.weight', 'sci_embeddings.encoder.layer.7.intermediate.dense.bias', 'sci_embeddings.encoder.layer.7.output.dense.weight', 'sci_embeddings.encoder.layer.7.output.dense.bias', 'sci_embeddings.encoder.layer.7.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.7.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.8.attention.self.query.weight', 'sci_embeddings.encoder.layer.8.attention.self.query.bias', 'sci_embeddings.encoder.layer.8.attention.self.key.weight', 'sci_embeddings.encoder.layer.8.attention.self.key.bias', 'sci_embeddings.encoder.layer.8.attention.self.value.weight', 'sci_embeddings.encoder.layer.8.attention.self.value.bias', 'sci_embeddings.encoder.layer.8.attention.output.dense.weight', 'sci_embeddings.encoder.layer.8.attention.output.dense.bias', 'sci_embeddings.encoder.layer.8.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.8.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.8.intermediate.dense.weight', 'sci_embeddings.encoder.layer.8.intermediate.dense.bias', 'sci_embeddings.encoder.layer.8.output.dense.weight', 'sci_embeddings.encoder.layer.8.output.dense.bias', 'sci_embeddings.encoder.layer.8.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.8.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.9.attention.self.query.weight', 'sci_embeddings.encoder.layer.9.attention.self.query.bias', 'sci_embeddings.encoder.layer.9.attention.self.key.weight', 'sci_embeddings.encoder.layer.9.attention.self.key.bias', 'sci_embeddings.encoder.layer.9.attention.self.value.weight', 'sci_embeddings.encoder.layer.9.attention.self.value.bias', 'sci_embeddings.encoder.layer.9.attention.output.dense.weight', 'sci_embeddings.encoder.layer.9.attention.output.dense.bias', 'sci_embeddings.encoder.layer.9.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.9.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.9.intermediate.dense.weight', 'sci_embeddings.encoder.layer.9.intermediate.dense.bias', 'sci_embeddings.encoder.layer.9.output.dense.weight', 'sci_embeddings.encoder.layer.9.output.dense.bias', 'sci_embeddings.encoder.layer.9.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.9.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.10.attention.self.query.weight', 'sci_embeddings.encoder.layer.10.attention.self.query.bias', 'sci_embeddings.encoder.layer.10.attention.self.key.weight', 'sci_embeddings.encoder.layer.10.attention.self.key.bias', 'sci_embeddings.encoder.layer.10.attention.self.value.weight', 'sci_embeddings.encoder.layer.10.attention.self.value.bias', 'sci_embeddings.encoder.layer.10.attention.output.dense.weight', 'sci_embeddings.encoder.layer.10.attention.output.dense.bias', 'sci_embeddings.encoder.layer.10.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.10.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.10.intermediate.dense.weight', 'sci_embeddings.encoder.layer.10.intermediate.dense.bias', 'sci_embeddings.encoder.layer.10.output.dense.weight', 'sci_embeddings.encoder.layer.10.output.dense.bias', 'sci_embeddings.encoder.layer.10.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.10.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.11.attention.self.query.weight', 'sci_embeddings.encoder.layer.11.attention.self.query.bias', 'sci_embeddings.encoder.layer.11.attention.self.key.weight', 'sci_embeddings.encoder.layer.11.attention.self.key.bias', 'sci_embeddings.encoder.layer.11.attention.self.value.weight', 'sci_embeddings.encoder.layer.11.attention.self.value.bias', 'sci_embeddings.encoder.layer.11.attention.output.dense.weight', 'sci_embeddings.encoder.layer.11.attention.output.dense.bias', 'sci_embeddings.encoder.layer.11.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.11.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.11.intermediate.dense.weight', 'sci_embeddings.encoder.layer.11.intermediate.dense.bias', 'sci_embeddings.encoder.layer.11.output.dense.weight', 'sci_embeddings.encoder.layer.11.output.dense.bias', 'sci_embeddings.encoder.layer.11.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.11.output.LayerNorm.bias', 'sci_embeddings.pooler.dense.weight', 'sci_embeddings.pooler.dense.bias', 'ff.weight', 'ff.bias', 'lstm.weight_ih_l0', 'lstm.weight_hh_l0', 'lstm.bias_ih_l0', 'lstm.bias_hh_l0', 'lstm.weight_ih_l0_reverse', 'lstm.weight_hh_l0_reverse', 'lstm.bias_ih_l0_reverse', 'lstm.bias_hh_l0_reverse', 'classifier.weight', 'classifier.bias'])\n"]}],"source":["state_dict = torch.load('trained_model_dic.pth')\n","print(state_dict.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":188,"status":"ok","timestamp":1638229491048,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"TCFtuyBv3ADq","outputId":"926a21bc-7488-4417-d42b-29f9fa5a07ae"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["ner_model = NerModel(BertEmbModel).to('cuda')\n","ner_model.load_state_dict(state_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VSkY_QSCz3tC"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"ymiejDO5srYE"},"source":["# Obtain datasets' weights values (Do not run - fixed values)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12925204,"status":"ok","timestamp":1643841545009,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"GsRs55zcsxhk","outputId":"7b7e68ff-757f-4f55-fa11-27adb3024105"},"outputs":[{"name":"stdout","output_type":"stream","text":["0:  36134 1:  2658 2:  3905 3:  485 4:  1356 5:  3567 6:  1029\n"]}],"source":["zero = 0\n","one=0\n","two=0 \n","three=0\n","four=0\n","five=0\n","six=0\n","local_set = train\n","for i in range(len(local_set)):\n","  for j in range(len(local_set[i]['labels'])):\n","    if local_set[i]['labels'][j] == 0:\n","      zero += 1\n","    elif local_set[i]['labels'][j] == 1:\n","      one += 1\n","    elif local_set[i]['labels'][j] == 2:\n","      two += 1\n","    elif local_set[i]['labels'][j] == 3:\n","      three += 1\n","    elif local_set[i]['labels'][j] == 4:\n","      four += 1\n","    elif local_set[i]['labels'][j] == 5:\n","      five += 1\n","    elif local_set[i]['labels'][j] == 6:\n","      six += 1\n","    \n","print('0: ', zero, '1: ', one, '2: ', two, '3: ', three, '4: ', four, '5: ', five, '6: ', six)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YzN52yRfsym4"},"outputs":[],"source":["zero = 0\n","one=0\n","two=0 \n","three=0\n","four=0\n","five=0\n","six=0\n","local_set = test\n","for i in range(len(local_set)):\n","  for j in range(len(local_set[i]['labels'])):\n","    if local_set[i]['labels'][j] == 0:\n","      zero += 1\n","    elif local_set[i]['labels'][j] == 1:\n","      one += 1\n","    elif local_set[i]['labels'][j] == 2:\n","      two += 1\n","    elif local_set[i]['labels'][j] == 3:\n","      three += 1\n","    elif local_set[i]['labels'][j] == 4:\n","      four += 1\n","    elif local_set[i]['labels'][j] == 5:\n","      five += 1\n","    elif local_set[i]['labels'][j] == 6:\n","      six += 1\n","    \n","print('0: ', zero, '1: ', one, '2: ', two, '3: ', three, '4: ', four, '5: ', five, '6: ', six)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B64qF5V-trfK"},"outputs":[],"source":["zero = 0\n","one=0\n","two=0 \n","three=0\n","four=0\n","five=0\n","six=0\n","local_set = val\n","for i in range(len(local_set)):\n","  for j in range(len(local_set[i]['labels'])):\n","    if local_set[i]['labels'][j] == 0:\n","      zero += 1\n","    elif local_set[i]['labels'][j] == 1:\n","      one += 1\n","    elif local_set[i]['labels'][j] == 2:\n","      two += 1\n","    elif local_set[i]['labels'][j] == 3:\n","      three += 1\n","    elif local_set[i]['labels'][j] == 4:\n","      four += 1\n","    elif local_set[i]['labels'][j] == 5:\n","      five += 1\n","    elif local_set[i]['labels'][j] == 6:\n","      six += 1\n","    \n","print('0: ', zero, '1: ', one, '2: ', two, '3: ', three, '4: ', four, '5: ', five, '6: ', six)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eEKHdlDyy1T2"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["LyMVIljFrioE","52t8l945rf1Y","-DBrafz0KqEq","oGYV8ipcJ5fU","7LthVVOhx_Sz","1Nh8Lcpvb_F4","kv6pGzbGpv2D","BBA4owXH8oS1","dcdDIwq0kXy2","k0w9Lc0d3iOT","hC35X0v72kXB","ymiejDO5srYE"],"name":"SciECR+SciModel-Spans.ipynb","provenance":[{"file_id":"1apRBKJ_i2t4gsKy0TfRAM0Gih4gDkI15","timestamp":1634538734401}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d1babbdfe74545bfb448fb75c4b80119":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_64d826f306b64b38b12c156d249e590d","IPY_MODEL_07c12b9de7e24c88aa49e4f896eb88c1","IPY_MODEL_dd1992e68745464bae6bd3ceee2199d4"],"layout":"IPY_MODEL_e2f5af3d7f73446d80ecbfcc8ecc86d7"}},"64d826f306b64b38b12c156d249e590d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4eba57639ea4230905eea22ddcacf2b","placeholder":"​","style":"IPY_MODEL_ae380a79666a4a9da4180ec4ecdff472","value":"Downloading: 100%"}},"07c12b9de7e24c88aa49e4f896eb88c1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb183a889d934df5b54e008eb90124e4","max":385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d2e339112b7f44599510877bcbd73730","value":385}},"dd1992e68745464bae6bd3ceee2199d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b1d337c322b4b56963ea554420bedf3","placeholder":"​","style":"IPY_MODEL_b4708bbf7a4d4c8e95710b5c20225c2a","value":" 385/385 [00:00&lt;00:00, 3.02kB/s]"}},"e2f5af3d7f73446d80ecbfcc8ecc86d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4eba57639ea4230905eea22ddcacf2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae380a79666a4a9da4180ec4ecdff472":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb183a889d934df5b54e008eb90124e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2e339112b7f44599510877bcbd73730":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4b1d337c322b4b56963ea554420bedf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4708bbf7a4d4c8e95710b5c20225c2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"945ccd2960c04154a70af387864d8833":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b3427c1d31084dd89029928db44b9e7c","IPY_MODEL_ae786aea764d4481be979a35c4f805d9","IPY_MODEL_6719f8f34dc745d886ceeeca1fc27044"],"layout":"IPY_MODEL_e384149a93a447a689b2ba88c9fce891"}},"b3427c1d31084dd89029928db44b9e7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e387e1a661a4509be3753874545c9bf","placeholder":"​","style":"IPY_MODEL_ba114c09e9fe4842888899d26eaddcb7","value":"Downloading: 100%"}},"ae786aea764d4481be979a35c4f805d9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_799bfc35d4a04c368b80f406b4333731","max":227845,"min":0,"orientation":"horizontal","style":"IPY_MODEL_af3b99cfdd8f43bfbbdc9ff2b3b2d860","value":227845}},"6719f8f34dc745d886ceeeca1fc27044":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9c2fc5473374187b46965352369bac6","placeholder":"​","style":"IPY_MODEL_adea7f07000a48c18bc9a9a17c4eb8d5","value":" 223k/223k [00:00&lt;00:00, 746kB/s]"}},"e384149a93a447a689b2ba88c9fce891":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e387e1a661a4509be3753874545c9bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba114c09e9fe4842888899d26eaddcb7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"799bfc35d4a04c368b80f406b4333731":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af3b99cfdd8f43bfbbdc9ff2b3b2d860":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a9c2fc5473374187b46965352369bac6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adea7f07000a48c18bc9a9a17c4eb8d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"690c9db97e7447fd9ebbaf49a9e2aabd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c27024fad42445fdb8dce0ba865deb9c","IPY_MODEL_17563b595bc44cbd87fcc19d1a203dfc","IPY_MODEL_585dc7834caa486bbde0a97e79d7f0fc"],"layout":"IPY_MODEL_b236960547ec4635a559da72221f1fb8"}},"c27024fad42445fdb8dce0ba865deb9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f8d9474a3d74f5fb12be429efcb1fff","placeholder":"​","style":"IPY_MODEL_22c0eadfb39945e2aae02de390c35d24","value":"Downloading: 100%"}},"17563b595bc44cbd87fcc19d1a203dfc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_673df43bed00462495b2dc1b47825724","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a602b444404f40cebb34cc829b60af57","value":442221694}},"585dc7834caa486bbde0a97e79d7f0fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cf4cbce024845e7a996e8342b0c0d9b","placeholder":"​","style":"IPY_MODEL_6124d9b458bb4ab5b24c4a9d553a9e5b","value":" 422M/422M [00:08&lt;00:00, 55.0MB/s]"}},"b236960547ec4635a559da72221f1fb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f8d9474a3d74f5fb12be429efcb1fff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22c0eadfb39945e2aae02de390c35d24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"673df43bed00462495b2dc1b47825724":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a602b444404f40cebb34cc829b60af57":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9cf4cbce024845e7a996e8342b0c0d9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6124d9b458bb4ab5b24c4a9d553a9e5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}