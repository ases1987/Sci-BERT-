{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1634586672813,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"CQ6H5sYFfFCM","outputId":"e9f2f38b-5555-4419-dcb5-6c0a537a5538"},"outputs":[{"name":"stdout","output_type":"stream","text":["sample_data\n"]}],"source":["!ls"]},{"cell_type":"markdown","metadata":{"id":"LyMVIljFrioE"},"source":["#External Databases"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34354,"status":"ok","timestamp":1647112557269,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"IeeP8a6fKXOX","outputId":"bcf1c2f8-2ec5-4bfd-aade-caf6ac346029"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/transformers.git\n","  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-nxv72twk\n","  Running command git clone -q https://github.com/huggingface/transformers.git /tmp/pip-req-build-nxv72twk\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (4.11.2)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 8.5 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (4.63.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (3.6.0)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 58.5 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 49.2 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (1.21.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0.dev0) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.18.0.dev0) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.18.0.dev0) (3.7.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0.dev0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0.dev0) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0.dev0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0.dev0) (1.24.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0.dev0) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0.dev0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0.dev0) (7.1.2)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.18.0.dev0-py3-none-any.whl size=3836030 sha256=bbd8ff614d59993b228c32410dddb51254c95cf0f50ef3ea40cb360fb2a588ff\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-7bzmlzbz/wheels/90/a5/44/6bcd83827c8a60628c5ad602f429cd5076bcce5f2a90054947\n","Successfully built transformers\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.6 transformers-4.18.0.dev0\n"]}],"source":["! pip install git+https://github.com/huggingface/transformers.git"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19688,"status":"ok","timestamp":1647112576949,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"_L4bHxBGsZk_","outputId":"c64ed36c-f55b-4aea-ca45-25e94af68110"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ray[tune]\n","  Downloading ray-1.11.0-cp37-cp37m-manylinux2014_x86_64.whl (52.7 MB)\n","\u001b[K     |████████████████████████████████| 52.7 MB 59 kB/s \n","\u001b[?25hCollecting grpcio<=1.43.0,>=1.28.1\n","  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n","\u001b[K     |████████████████████████████████| 4.1 MB 49.0 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.6.0)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.3.3)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.21.5)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (7.1.2)\n","Collecting redis>=3.5.0\n","  Downloading redis-4.1.4-py3-none-any.whl (175 kB)\n","\u001b[K     |████████████████████████████████| 175 kB 57.1 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (6.0)\n","Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.17.3)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.0.3)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (21.4.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.8.9)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.3.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.23.0)\n","Collecting tensorboardX>=1.9\n","  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 66.4 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray[tune]) (1.15.0)\n","Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (4.11.2)\n","Collecting deprecated>=1.2.3\n","  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (21.3)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]) (1.13.3)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]) (3.7.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.4->redis>=3.5.0->ray[tune]) (3.0.7)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (0.18.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (5.4.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2.8.2)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2.10)\n","Installing collected packages: deprecated, redis, grpcio, tensorboardX, ray\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.44.0\n","    Uninstalling grpcio-1.44.0:\n","      Successfully uninstalled grpcio-1.44.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n","Successfully installed deprecated-1.2.13 grpcio-1.43.0 ray-1.11.0 redis-4.1.4 tensorboardX-2.5\n"]}],"source":["! pip install ray[tune]"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14800,"status":"ok","timestamp":1647112591744,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"UI0tseYdav7D","outputId":"6607d16b-5108-4c49-fe80-73ad55bacb20"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-1.18.4-py3-none-any.whl (312 kB)\n","\u001b[K     |████████████████████████████████| 312 kB 7.4 MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 63.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n","\u001b[K     |████████████████████████████████| 134 kB 71.2 MB/s \n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 9.4 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.63.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 57.9 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 53.3 MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.2 MB/s \n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 56.5 MB/s \n","\u001b[?25hCollecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-1.18.4 frozenlist-1.3.0 fsspec-2022.2.0 multidict-6.0.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9749,"status":"ok","timestamp":1647112601481,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"A4WLX8OtSc_G","outputId":"309815f6-15c8-4dbc-9def-ec617709fce2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[?25l\r\u001b[K     |███████▌                        | 10 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20 kB 33.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 43 kB 1.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=090264e704a407dfeebe2cbab5bb12359ab77834446a1f8de706fbc048e19b1b\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n"]}],"source":["!pip install seqeval"]},{"cell_type":"markdown","metadata":{"id":"52t8l945rf1Y"},"source":["#Libraries"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0,"referenced_widgets":["a1476d25d48345149c175868fed7d274","f0b2c3cf8d094954bab8e5e56f0bf872","9639c6fea41f4bca8363aee422ba0737","8a8f1805e92e4653a905f60ff2030e1a","b62351b64d5e4e8eabab5932764756a7","dec757c9dc3e4233a5ea706cee022bed","64a7da0e64b942de9b06b9b32f9bb806","829e228cc1034b9d9510ffbf546aaae4","4d9bc8b9fada4bfa8c89310e4152e348","212f9fa896524b19bace9fd386715f41","85d96ce17fa84003bd86d076cefb2ec3","8d4fbdcb0ed745988516414b03f44c12","bb160682acbc40e0bfa1da5829424cef","84295e5ba2a546f599fc220cddc7e534","33fbb598805141fa900ffe7433c92b91","ae795a36a39f4686b93ea7cd42f059e3","d10a5eeb33644970837ab0b60d229e26","365f1298dc57485ca9b809893014fbd1","4260bdee1e184e4586aec375f496e7f8","ae7f5214c63d4117b528ca228a306242","4f65b051125c406ea39378607bed1808","db6ef86ad5f04ee5a6a1b92f6485ec04","2f849d11d04041e88436f980f9cad4ac","4268ed26baa2430b9b4c6fa382a74d1e","3474686a610e430697d9cf3f46d8a684","5ae1a0f5a2144220b0c56f0ef1c06863","d4aa92747e86433cad4aea2f6d8f3b41","2d5f3b964d694d6aaa65258cfbe0f498","ae287321f976431c8566b9734aab57fc","230efeb81e6e4841b78961409b7aa79f","07cdb291e89b4557bca2ec866333b374","0ab291a3ca664382afa5b12c6c886ec3","86af2d663b014f3caae282f0a42154cb"]},"executionInfo":{"elapsed":27069,"status":"ok","timestamp":1647112628538,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"qSbdGMYCgquq","outputId":"c0a37e17-d7d5-403c-c676-25308fa08f52"},"outputs":[{"output_type":"stream","name":"stdout","text":["4.18.0.dev0\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1476d25d48345149c175868fed7d274"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/223k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d4fbdcb0ed745988516414b03f44c12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/422M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f849d11d04041e88436f980f9cad4ac"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["from google.colab import files\n","\n","import os\n","import re\n","import json\n","import string\n","\n","import torch\n","import torch.nn as nn\n","\n","import numpy as np\n","#import tensorflow as tf\n","#from tensorflow import keras\n","#from tensorflow.keras import layers\n","#from datasets import load_dataset\n","#from collections import Counter\n","#from conlleval import evaluate\n","\n","import tensorflow_hub as hub\n","from keras import backend as K\n","import torch.nn.functional as F\n","\n","import transformers\n","print(transformers.__version__)\n","from transformers import TrainingArguments\n","from transformers import Trainer\n","\n","from transformers import Trainer\n","from transformers.trainer_utils import EvalLoopOutput\n","\n","from seqeval.metrics import classification_report\n","from sklearn.metrics import precision_recall_fscore_support as prfs\n","from datasets import load_metric\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","\n","from transformers import AutoTokenizer, AutoModel\n","BertTokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n","BertEmbModel = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')"]},{"cell_type":"markdown","metadata":{"id":"-DBrafz0KqEq"},"source":["#Loading Dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0,"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK","headers":[["content-type","application/javascript"]],"ok":true,"status":200,"status_text":""}}},"executionInfo":{"elapsed":73848,"status":"ok","timestamp":1647112702371,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"ICN0rgXve6o1","outputId":"ea6994f9-cb99-4f21-8fb3-4ef38ef9fd1a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-c7935dd3-9b0d-4cbe-9692-3b18bffa6471\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-c7935dd3-9b0d-4cbe-9692-3b18bffa6471\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving dev.json to dev.json\n","Saving test.json to test.json\n","Saving train.json to train.json\n"]}],"source":["uploaded = files.upload()"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1647112702372,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"IR8fDCLnap-m"},"outputs":[],"source":["class SciERCDataset(torch.utils.data.Dataset):\n","  def __init__(self, raw_data, entity_map, max_length=250):\n","    # Need to fix sentence offset for labels!!\n","    for i, sample in enumerate(raw_data):\n","      sent_offset = 0\n","      for j, sent in enumerate(sample['sentences']):\n","        for k, ner in enumerate(sample['ner'][j]):\n","          raw_data[i]['ner'][j][k] = [raw_data[i]['ner'][j][k][0] - sent_offset, \n","                                      raw_data[i]['ner'][j][k][1] - sent_offset, \n","                                      raw_data[i]['ner'][j][k][2]]\n","        sent_offset += len(sent)\n","\n","    sentences = [x['sentences'] for x in raw_data]\n","    self.raw_x = [sent for sublist in sentences for sent in sublist]\n","\n","    ners = [x['ner'] for x in raw_data]\n","    self.raw_y = [ner for sublist in ners for ner in sublist]\n","    \n","    self.entity_map = entity_map\n","    self.max_length = max_length\n","\n","  def tokenize_and_preserve_labels(self, sentence, text_labels):\n","    \"\"\"\n","    The tokenizer can split single words into multiple tokens - this breaks\n","    the labels, so we need to keep track of this!\n","    \"\"\"\n","    tokenized_sentence = []\n","    labels = []\n","    prev_label = 0\n","\n","    for word, label in zip(sentence, text_labels):\n","        # Tokenize the word and count # of subwords the word is broken into\n","        tokenized_word = BertTokenizer.tokenize(word)\n","        n_subwords = len(tokenized_word)\n","\n","        # Add the tokenized word to the final tokenized word list\n","        tokenized_sentence.extend(tokenized_word)\n","\n","        # Add the same label to the new list of labels `n_subwords` times\n","        if label != 0:  \n","          labels.extend([-100] * n_subwords)\n","          labels[-1 * n_subwords] = label\n","        else:\n","          labels.extend([label] * n_subwords)\n","        \n","        prev_label = label\n","\n","    return tokenized_sentence, labels\n","\n","  def __getitem__(self, idx):\n","    tokens = self.raw_x[idx]\n","    labels = np.zeros((len(tokens)))\n","\n","    #For Span\n","    for ner in self.raw_y[idx]:  # Returns [start_idx, end_idx, string label]\n","      assert len(tokens) >= ner[0], '{}, {}'.format(tokens, ner)\n","      ner_name = 'I-' + ner[-1]\n","      label = self.entity_map(ner_name)  # Get the integer label\n","      labels[ner[0]:ner[1]+1] = label\n","      labels[ner[0]] = label - 1 \n","\n","    #For BIO\n","    #for ner in self.raw_y[idx]:  # Returns [start_idx, end_idx, string label]\n","    #  assert len(tokens) >= ner[0], '{}, {}'.format(tokens, ner)  # Double checking the labels are correct\n","    #  ner_name = 'I-' + ner[-1]  # assume all are \"I\" labels\n","    #  label = self.entity_map(ner_name)  # Get the integer label\n","    #  labels[ner[0]:ner[1]+1] = label  \n","    #  labels[ner[0]] = label - 1  # Change first one to \"B\" label\n","\n","    # This could be moved to __init__ to save time?\n","    tokens, labels = self.tokenize_and_preserve_labels(tokens, labels)\n","\n","    # Convert each token to an id number \n","    input_ids = BertTokenizer.convert_tokens_to_ids(tokens)\n","    \n","    # add and adjust for special tokens\n","    input_ids = [BertTokenizer.cls_token_id] + input_ids + [BertTokenizer.sep_token_id]  \n","    labels = [0] + labels + [0]\n","\n","    # Pad inputs\n","    input_ids = torch.tensor(np.pad(input_ids, [0, self.max_length-len(input_ids)]))\n","    labels = torch.tensor(np.pad(labels, [0, self.max_length-len(labels)], constant_values=-100))\n","\n","    attention_mask = torch.tensor([int(i != 0) for i in input_ids])\n","\n","    return {'input_ids': [input_ids], 'attention_mask': [attention_mask], 'labels': labels}\n","\n","  def __len__(self):\n","    return len(self.raw_y)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1647112702373,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"TlMNAfW3gfGp"},"outputs":[],"source":["def Entity2ID(Sc_Entity):\n","  return {\n","        'B-Task': 1,\n","        'I-Task': 2,\n","        'B-Method': 3,\n","        'I-Method': 4,\n","        'B-Metric': 5,\n","        'I-Metric': 6,\n","        'B-Material': 7,\n","        'I-Material': 8,\n","        'B-OtherScientificTerm': 9,\n","        'I-OtherScientificTerm': 10,\n","        'B-Generic': 11,\n","        'I-Generic': 12,\n","        'None': 0\n","    }[Sc_Entity]\n","\n","def ID2Entity(Sc_Entity):\n","  return {\n","        1: 'B-Task',\n","        2: 'I-Task',\n","        3: 'B-Method',\n","        4: 'I-Method',\n","        5: 'B-Metric',\n","        6: 'I-Metric',\n","        7: 'B-Material',\n","        8: 'I-Material',\n","        9: 'B-OtherScientificTerm',\n","        10: 'I-OtherScientificTerm',\n","        11: 'B-Generic',\n","        12: 'I-Generic',\n","        0: 'O'\n","    }[Sc_Entity]"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":195,"status":"ok","timestamp":1647112702563,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"awzlXu9Ugool","outputId":"e6337ee4-f124-412d-aec3-a4111f805101"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["350"]},"metadata":{},"execution_count":9}],"source":["train_data = []\n","with open('train.json','r') as f:\n","  for line in f:\n","    train_data.append(json.loads(line))\n","\n","test_data = []\n","with open('test.json','r') as f:\n","  for line in f:\n","    test_data.append(json.loads(line))\n","\n","val_data = []\n","with open('dev.json','r') as f:\n","  for line in f:\n","    val_data.append(json.loads(line))\n","\n","#train_data[3]['sentences'][0], train_data[3]['ner'][0], len(train_data[3]['sentences'][1])\n","len(train_data)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1647112702565,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"y92WU6R3dltN"},"outputs":[],"source":["train = SciERCDataset(train_data, Entity2ID)\n","val = SciERCDataset(val_data, Entity2ID)\n","test = SciERCDataset(test_data, Entity2ID)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1647112702567,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"YyTtZEgcLv3C"},"outputs":[],"source":["#tokens = BertTokenizer.convert_ids_to_tokens(train[1]['input_ids'][0])\n","#labels = train[1]['labels']\n","#print(' '.join(tokens))\n","#print(labels)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1647112702567,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"n-2wczlALa-p","outputId":"98acfe7e-453b-45d6-e702-f67732f73f6b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n"," 'input_ids': [tensor([  102,  6170,   165,   817,   147,   195,   428,   579,  2220,   579,\n","           2159,   191,   111,  2525,   131,  7395, 30113,   131,   111,  1222,\n","           1211,   198,  3862,  8503, 13510,  2057,   579,  8595,  4111,   205,\n","            103,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0])],\n"," 'labels': tensor([   0.,    7.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","            0.,    0.,    0.,    0.,    0.,    9., -100.,    0.,    0.,    0.,\n","            0.,    0.,    0.,    9.,   10.,   10., -100., -100.,   10.,    0.,\n","            0., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.],\n","        dtype=torch.float64)}"]},"metadata":{},"execution_count":12}],"source":["train[0]"]},{"cell_type":"markdown","metadata":{"id":"oGYV8ipcJ5fU"},"source":["# Pytorch Model Definition"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1647112702567,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"eFp2ZFd25KwK"},"outputs":[],"source":["class NerModel(nn.Module):\n","  def __init__(self, b_embeddings, emb_dims=768, ff_dims=14, out_dims=13):\n","    super(NerModel, self).__init__()\n","    self.sci_embeddings = b_embeddings\n","    self.embd_dropout = nn.Dropout(0.1)\n","    self.ff_dropout = nn.Dropout(0.1)\n","    self.ff = nn.Linear(emb_dims, ff_dims)\n","    self.tanh = nn.Tanh()\n","    self.lstm = nn.LSTM(emb_dims, 100, 1, bidirectional=True)\n","    self.lstm_drop = nn.Dropout(0.4)\n","    self.ff = nn.Linear(200, ff_dims)\n","    self.ff_act = nn.ReLU()\n","    self.classifier = nn.Linear(ff_dims, out_dims)\n","  def forward(self, **inputs):\n","    embds = self.sci_embeddings(**inputs)['last_hidden_state']\n","    out = self.embd_dropout(embds)\n","    out, _ = self.lstm(out)\n","    out = self.tanh(out)\n","    out = self.lstm_drop(out)\n","    out = self.ff(out)\n","    out = self.ff_act(out)\n","    out = self.ff_dropout(out)\n","    out = self.classifier(out)\n","    return out\n"]},{"cell_type":"markdown","metadata":{"id":"7LthVVOhx_Sz"},"source":["# Metrics and Configs"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1647112702568,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"VZJjqYf2AKA8"},"outputs":[],"source":["def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    #print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","\n","import math\n","\n","def load_param():\n","  for n, v in best_run.hyperparameters.items():\n","    if n == 'seed':\n","      setattr(trainer.args, n, math.ceil(v))\n","      print(n, math.ceil(v))\n","    else:\n","      setattr(trainer.args, n, v)\n","      print(n, v)   "]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":180,"status":"ok","timestamp":1647112702740,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"qjMXqFluyLCW"},"outputs":[],"source":["batch_size = 4\n","training_args = TrainingArguments(\n","    \"trained_scibert_ner_model\", # output dir\n","    learning_rate=1e-5, \n","    num_train_epochs=10, \n","    dataloader_drop_last=True,\n","    per_device_eval_batch_size=batch_size, \n","    per_device_train_batch_size=batch_size,\n","    logging_steps=50,\n","    save_steps=len(train) // batch_size,\n","    lr_scheduler_type='cosine',\n","    evaluation_strategy='steps',\n","    eval_steps=len(train) // batch_size)\n","#print(training_args)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1647112702741,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"fabdHzMRybBR"},"outputs":[],"source":["def collator(batch):\n","  out =  {\n","      'input_ids': torch.stack([(x['input_ids'][0]) for x in batch]),\n","      'attention_mask': torch.stack([x['attention_mask'][0] for x in batch]),\n","      'labels': torch.stack([x['labels'].clone().detach() for x in batch])\n","  }\n","  return out"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1647112702741,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"dZluJPsy2eb5"},"outputs":[],"source":["class FocalLoss(nn.modules.loss._WeightedLoss):\n","    def __init__(self, weight, gamma, reduction='mean'):\n","        super(FocalLoss, self).__init__(weight,reduction=reduction)\n","        self.gamma = gamma\n","        self.weight = weight #weight parameter will act as the alpha parameter to balance class weights\n","\n","    def forward(self, input, target):\n","        ce_loss = F.cross_entropy(input, target, ignore_index=-100, reduction=self.reduction, weight=self.weight)\n","        pt = torch.exp(-ce_loss)\n","        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n","        return focal_loss"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1647112702742,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"QLbpwNckLvV6"},"outputs":[],"source":["class MultilabelTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False, num_labels=13):\n","        labels = inputs.pop(\"labels\")\n","        outputs = model(**inputs)\n","        logits = outputs\n","        \n","        #weights = torch.tensor([0.1, 1.5, 1.55, 1.9, 1.75, 1.65, 1.9]).cuda()  # The no-class label has too many examples, we need to weight the loss - this probably needs further tuning \n","        \n","        #weights = torch.tensor([0.1, 1.5, 1.2, 1.9, 1.75, 1.3, 1.85]).cuda()\n","\n","        #weights = torch.tensor([0.89, 1.73, 1.69, 1.79, 1.76, 1.7, 1.77]).cuda()\n","\n","        #weights = torch.tensor([0.89, 1.69, 1.65, 1.84, 1.75, 1.66, 1.77]).cuda()\n","\n","        #weights = torch.tensor([0.95, 1.6, 1.5, 1.94, 1.7, 1.55, 1.83]).cuda()\n","\n","        #weights = torch.tensor([0.12, 0.83, 0.78, 1.0, 0.88, 0.8, 0.95]).cuda()\n","\n","        #weights = torch.tensor([0.42, 1.5, 1.2, 2.0, 1.6, 1.4, 1.8]).cuda()\n","\n","        #weights = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]).cuda()\n","\n","        #weights = torch.tensor([0.1, 1.36, 0.93, 7.45, 2.66, 1.01, 3.51]).cuda()\n","\n","        #weights = torch.tensor([0.26, 0.95, 0.92, 0.99, 0.97, 0.93, 0.98]).cuda()\n","\n","        weights = torch.tensor([0.25, 0.98, 0.97, 0.97, 0.95, 1.0, 1.0, 0.99, 0.98, 0.97, 0.96, 0.98, 1.2]).cuda()\n","\n","        gamma=5\n","        loss_fct = FocalLoss(weight=weights, gamma=gamma)\n","        loss = loss_fct(logits.view(-1, num_labels), labels.long().view(-1))\n","        return (loss, outputs) if return_outputs else loss\n","\n","    def evaluation_loop(self, dataloader, description, prediction_loss_only=None, ignore_keys=None, metric_key_prefix=\"eval\", num_labels=7):\n","      args = self.args\n","      prediction_loss_only = prediction_loss_only if prediction_loss_only is not None else args.prediction_loss_only\n","\n","      self.model.eval()\n","\n","      all_losses = []\n","      all_preds = []\n","      all_labels = []\n","      for step, sample in enumerate(dataloader):\n","        for i in range(0, len(sample['labels'])):\n","          inputs = {}\n","          inputs['input_ids'] = torch.stack([sample['input_ids'][i].cuda()])\n","          inputs['attention_mask'] = torch.stack([sample['attention_mask'][i].cuda()])\n","          inputs['labels'] = torch.stack([sample['labels'][i].cuda()])\n","          labels = inputs['labels'][0].cpu().numpy()\n","          \n","          (loss, logits) = self.compute_loss(self.model, inputs, return_outputs=True)\n","          logits = logits[0].cpu().detach().numpy()\n","          preds = np.argmax(nn.Softmax(dim=-1)(torch.tensor(logits)).numpy(), axis=-1)\n","\n","          all_losses = np.concatenate((all_losses, [loss.detach().cpu().numpy()]), axis=0)\n","\n","          preds = preds[labels != -100]\n","          labels = labels[labels != -100]\n","          all_preds = np.concatenate((all_preds, preds))\n","          all_labels = np.concatenate((all_labels, labels))\n","\n","      metrics = {}\n","      metrics['macro_f1'] = f1_score(all_labels, all_preds, average='macro')\n","      metrics['macro_precision'] = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n","      metrics['macro_recall'] = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n","      metrics['micro_f1'] = f1_score(all_labels, all_preds, average='micro')\n","      metrics['micro_precision'] = precision_score(all_labels, all_preds, average='micro', zero_division=0)\n","      metrics['micro_recall'] = recall_score(all_labels, all_preds, average='micro', zero_division=0)\n","\n","      metrics['macro_f1_no_o'] = f1_score(all_labels, all_preds, average='macro', labels=[1, 2, 3, 4, 5, 6])\n","      metrics['macro_precision_no_o'] = precision_score(all_labels, all_preds, average='macro', labels=[1, 2, 3, 4, 5, 6], zero_division=0)\n","      metrics['macro_recall_no_o'] = recall_score(all_labels, all_preds, average='macro', labels=[1, 2, 3, 4, 5, 6], zero_division=0)\n","      metrics['micro_f1_no_o'] = f1_score(all_labels, all_preds, average='micro', labels=[1, 2, 3, 4, 5, 6])\n","      metrics['micro_precision_no_o'] = precision_score(all_labels, all_preds, average='micro', labels=[1, 2, 3, 4, 5, 6], zero_division=0)\n","      metrics['micro_recall_no_o'] = recall_score(all_labels, all_preds, average='micro', labels=[1, 2, 3, 4, 5, 6], zero_division=0)\n","\n","      for key in list(metrics.keys()):\n","        if not key.startswith(metric_key_prefix):\n","          metrics[metric_key_prefix + '_' + key] = metrics.pop(key)\n","      \n","      metrics[metric_key_prefix + '_loss'] = all_losses.mean().item()\n","\n","      return EvalLoopOutput(predictions=all_preds, label_ids=all_labels, metrics=metrics, num_samples=len(dataloader))"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":226,"status":"ok","timestamp":1647112702963,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"infNapI_OmFr"},"outputs":[],"source":["def my_hp_space_ray(trial):\n","    from ray import tune\n","\n","    return {\n","        \"learning_rate\": tune.loguniform(9e-6, 1e-4),\n","        \"num_train_epochs\": tune.choice(range(5, 25)),\n","        \"weight_decay\": tune.uniform(0.0, 0.2),\n","        \"per_device_train_batch_size\": tune.choice([4, 8, 16]),  #<16 definetly not working\n","    }"]},{"cell_type":"markdown","metadata":{"id":"1Nh8Lcpvb_F4"},"source":["# Hyperparameter Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6AqbEPyPK7O"},"outputs":[],"source":["def model_init():\n","    x = NerModel(BertEmbModel)\n","    x.sci_embeddings.requires_grad = False\n","    return x\n","\n","trainer = MultilabelTrainer(model_init=model_init,\n","                            args=training_args,\n","                            train_dataset=train,\n","                            eval_dataset=val,\n","                            data_collator=collator  # defines how to merge data into batches, using the collator function above\n","                            )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1Zvatys9MnXSO9nNnnMBvJSGV3r3gWG1R"},"id":"IGyHLY640NRz","outputId":"3a84af87-a9bd-449f-999a-6beb0cbc65e6","executionInfo":{"status":"ok","timestamp":1646032941540,"user_tz":360,"elapsed":4922825,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["from ray.tune.suggest.hyperopt import HyperOptSearch\n","from ray.tune.schedulers import ASHAScheduler\n","\n","best_run = trainer.hyperparameter_search(backend=\"ray\", \n","                                         resources_per_trial={\"gpu\": 1, \"cpu\": 0},\n","                                         n_trials=18, \n","                                         direction=\"maximize\", \n","                                         hp_space=my_hp_space_ray,\n","                                         search_alg=HyperOptSearch(metric='eval_micro_recall_no_o', mode=\"max\"),  #'eval_*f1_micro'\n","                                         scheduler=ASHAScheduler(metric='eval_micro_recall_no_o', mode=\"max\")\n","                                         )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zH0H8agAbzZi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646032941541,"user_tz":360,"elapsed":15,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"57687abc-b271-480b-daa2-4577d7e22fbe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["BestRun(run_id='28622108', objective=9.177820413486334, hyperparameters={'learning_rate': 7.312253480818096e-05, 'num_train_epochs': 18, 'weight_decay': 0.10007182333796912, 'per_device_train_batch_size': 16})"]},"metadata":{},"execution_count":22}],"source":["best_run"]},{"cell_type":"markdown","metadata":{"id":"kv6pGzbGpv2D"},"source":["# Cossvalidation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LhipElJSzRUF"},"outputs":[],"source":["#import tensorflow as tf\n","from torch.utils.data import DataLoader, ConcatDataset\n","from sklearn.model_selection import KFold\n","from torch import nn\n","from transformers import Trainer\n","\n","#print('GPU detected:', tf.config.list_physical_devices('GPU'))\n","k_folds = 5\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","results = np.zeros(5)\n","resultss = np.zeros(5)\n","dataset = ConcatDataset([train, test])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zQyLOxyMjZq2","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1646900226749,"user_tz":360,"elapsed":8118763,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"667deb2e-dd6f-4624-f3ca-a940e09bcb03"},"outputs":[{"output_type":"stream","name":"stdout","text":["FOLD 0\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1929\n","  Num Epochs = 18\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2160\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2160' max='2160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2160/2160 26:24, Epoch 18/18]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.065000</td>\n","      <td>0.171029</td>\n","      <td>0.587020</td>\n","      <td>0.619856</td>\n","      <td>0.632515</td>\n","      <td>0.876687</td>\n","      <td>0.876687</td>\n","      <td>0.876687</td>\n","      <td>0.671532</td>\n","      <td>0.726232</td>\n","      <td>0.668853</td>\n","      <td>0.709741</td>\n","      <td>0.672430</td>\n","      <td>0.751436</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.013100</td>\n","      <td>0.129928</td>\n","      <td>0.686688</td>\n","      <td>0.656899</td>\n","      <td>0.723412</td>\n","      <td>0.898093</td>\n","      <td>0.898093</td>\n","      <td>0.898093</td>\n","      <td>0.739013</td>\n","      <td>0.707607</td>\n","      <td>0.777949</td>\n","      <td>0.756797</td>\n","      <td>0.718442</td>\n","      <td>0.799478</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.005500</td>\n","      <td>0.139280</td>\n","      <td>0.697149</td>\n","      <td>0.681289</td>\n","      <td>0.716114</td>\n","      <td>0.905932</td>\n","      <td>0.905932</td>\n","      <td>0.905932</td>\n","      <td>0.745681</td>\n","      <td>0.736505</td>\n","      <td>0.756811</td>\n","      <td>0.772343</td>\n","      <td>0.757789</td>\n","      <td>0.787467</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.004700</td>\n","      <td>0.142525</td>\n","      <td>0.699938</td>\n","      <td>0.683235</td>\n","      <td>0.719838</td>\n","      <td>0.906837</td>\n","      <td>0.906837</td>\n","      <td>0.906837</td>\n","      <td>0.747573</td>\n","      <td>0.743274</td>\n","      <td>0.753461</td>\n","      <td>0.768277</td>\n","      <td>0.760225</td>\n","      <td>0.776501</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.6984351663792426, 'eval_macro_precision': 0.6796162942331835, 'eval_macro_recall': 0.7205181096364868, 'eval_micro_f1': 0.9066103866737016, 'eval_micro_precision': 0.9066103866737016, 'eval_micro_recall': 0.9066103866737016, 'eval_macro_f1_no_o': 0.7453815931799364, 'eval_macro_precision_no_o': 0.7384106835363337, 'eval_macro_recall_no_o': 0.7536233575031391, 'eval_micro_f1_no_o': 0.7670879546040753, 'eval_micro_precision_no_o': 0.7579001019367991, 'eval_micro_recall_no_o': 0.7765013054830288, 'eval_loss': 0.14211770010191446, 'eval_runtime': 8.943, 'eval_samples_per_second': 3.355, 'eval_steps_per_second': 0.224, 'epoch': 18.0}\n","Accuracy for fold  0 :  0.7670879546040753\n","--------------------------------\n","FOLD 1\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1929\n","  Num Epochs = 18\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2160\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2160' max='2160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2160/2160 26:34, Epoch 18/18]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.039600</td>\n","      <td>0.059256</td>\n","      <td>0.669576</td>\n","      <td>0.706570</td>\n","      <td>0.719175</td>\n","      <td>0.933898</td>\n","      <td>0.933898</td>\n","      <td>0.933898</td>\n","      <td>0.574711</td>\n","      <td>0.699124</td>\n","      <td>0.629912</td>\n","      <td>0.789916</td>\n","      <td>0.782898</td>\n","      <td>0.797060</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.008300</td>\n","      <td>0.033935</td>\n","      <td>0.776694</td>\n","      <td>0.758884</td>\n","      <td>0.795853</td>\n","      <td>0.963773</td>\n","      <td>0.963773</td>\n","      <td>0.963773</td>\n","      <td>0.773469</td>\n","      <td>0.755655</td>\n","      <td>0.792270</td>\n","      <td>0.920359</td>\n","      <td>0.913189</td>\n","      <td>0.927643</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.003700</td>\n","      <td>0.027173</td>\n","      <td>0.782499</td>\n","      <td>0.768307</td>\n","      <td>0.798307</td>\n","      <td>0.966722</td>\n","      <td>0.966722</td>\n","      <td>0.966722</td>\n","      <td>0.780761</td>\n","      <td>0.773100</td>\n","      <td>0.789012</td>\n","      <td>0.925212</td>\n","      <td>0.927314</td>\n","      <td>0.923120</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.002700</td>\n","      <td>0.025461</td>\n","      <td>0.780293</td>\n","      <td>0.767019</td>\n","      <td>0.795083</td>\n","      <td>0.966420</td>\n","      <td>0.966420</td>\n","      <td>0.966420</td>\n","      <td>0.777870</td>\n","      <td>0.772970</td>\n","      <td>0.783633</td>\n","      <td>0.926262</td>\n","      <td>0.929425</td>\n","      <td>0.923120</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.7791287504660611, 'eval_macro_precision': 0.7665910321420663, 'eval_macro_recall': 0.7932538741032167, 'eval_micro_f1': 0.9661927091211617, 'eval_micro_precision': 0.9661927091211617, 'eval_micro_recall': 0.9661927091211617, 'eval_macro_f1_no_o': 0.7755830238934118, 'eval_macro_precision_no_o': 0.7719390065248278, 'eval_macro_recall_no_o': 0.7803312352311597, 'eval_micro_f1_no_o': 0.9251276233692569, 'eval_micro_precision_no_o': 0.9282868525896414, 'eval_micro_recall_no_o': 0.9219898247597512, 'eval_loss': 0.025976481942443286, 'eval_runtime': 8.9278, 'eval_samples_per_second': 3.36, 'eval_steps_per_second': 0.224, 'epoch': 18.0}\n","Accuracy for fold  1 :  0.9251276233692569\n","--------------------------------\n","FOLD 2\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1930\n","  Num Epochs = 18\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2160\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2160' max='2160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2160/2160 26:37, Epoch 18/18]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.028700</td>\n","      <td>0.033000</td>\n","      <td>0.807383</td>\n","      <td>0.860289</td>\n","      <td>0.821420</td>\n","      <td>0.975489</td>\n","      <td>0.975489</td>\n","      <td>0.975489</td>\n","      <td>0.789336</td>\n","      <td>0.769741</td>\n","      <td>0.810427</td>\n","      <td>0.941176</td>\n","      <td>0.933884</td>\n","      <td>0.948583</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.007600</td>\n","      <td>0.018410</td>\n","      <td>0.816017</td>\n","      <td>0.859880</td>\n","      <td>0.829490</td>\n","      <td>0.975489</td>\n","      <td>0.975489</td>\n","      <td>0.975489</td>\n","      <td>0.802779</td>\n","      <td>0.786600</td>\n","      <td>0.819783</td>\n","      <td>0.952157</td>\n","      <td>0.948932</td>\n","      <td>0.955404</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.003900</td>\n","      <td>0.014832</td>\n","      <td>0.834088</td>\n","      <td>0.836097</td>\n","      <td>0.841544</td>\n","      <td>0.978253</td>\n","      <td>0.978253</td>\n","      <td>0.978253</td>\n","      <td>0.803097</td>\n","      <td>0.790934</td>\n","      <td>0.815883</td>\n","      <td>0.953158</td>\n","      <td>0.956177</td>\n","      <td>0.950157</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.002800</td>\n","      <td>0.015189</td>\n","      <td>0.853125</td>\n","      <td>0.871920</td>\n","      <td>0.853507</td>\n","      <td>0.978980</td>\n","      <td>0.978980</td>\n","      <td>0.978980</td>\n","      <td>0.803162</td>\n","      <td>0.791388</td>\n","      <td>0.815339</td>\n","      <td>0.954629</td>\n","      <td>0.954379</td>\n","      <td>0.954879</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.8534647786183442, 'eval_macro_precision': 0.8729949199507716, 'eval_macro_recall': 0.8529390383895712, 'eval_micro_f1': 0.9792712197250709, 'eval_micro_precision': 0.9792712197250709, 'eval_micro_recall': 0.9792712197250709, 'eval_macro_f1_no_o': 0.8033511735719333, 'eval_macro_precision_no_o': 0.791753998796001, 'eval_macro_recall_no_o': 0.8153388820121537, 'eval_micro_f1_no_o': 0.9548793284365162, 'eval_micro_precision_no_o': 0.9548793284365162, 'eval_micro_recall_no_o': 0.9548793284365162, 'eval_loss': 0.015209971030256498, 'eval_runtime': 9.1311, 'eval_samples_per_second': 3.285, 'eval_steps_per_second': 0.219, 'epoch': 18.0}\n","Accuracy for fold  2 :  0.9548793284365162\n","--------------------------------\n","FOLD 3\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1930\n","  Num Epochs = 18\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2160\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2160' max='2160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2160/2160 26:41, Epoch 18/18]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.025300</td>\n","      <td>0.031165</td>\n","      <td>0.844445</td>\n","      <td>0.843518</td>\n","      <td>0.855092</td>\n","      <td>0.976308</td>\n","      <td>0.976308</td>\n","      <td>0.976308</td>\n","      <td>0.789226</td>\n","      <td>0.767182</td>\n","      <td>0.813026</td>\n","      <td>0.936206</td>\n","      <td>0.934637</td>\n","      <td>0.937780</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.006400</td>\n","      <td>0.013751</td>\n","      <td>0.858906</td>\n","      <td>0.851246</td>\n","      <td>0.869104</td>\n","      <td>0.981076</td>\n","      <td>0.981076</td>\n","      <td>0.981076</td>\n","      <td>0.805641</td>\n","      <td>0.794373</td>\n","      <td>0.817382</td>\n","      <td>0.952489</td>\n","      <td>0.961187</td>\n","      <td>0.943946</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.003400</td>\n","      <td>0.011597</td>\n","      <td>0.866144</td>\n","      <td>0.858181</td>\n","      <td>0.875434</td>\n","      <td>0.982287</td>\n","      <td>0.982287</td>\n","      <td>0.982287</td>\n","      <td>0.805168</td>\n","      <td>0.794011</td>\n","      <td>0.816812</td>\n","      <td>0.952758</td>\n","      <td>0.961736</td>\n","      <td>0.943946</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.002800</td>\n","      <td>0.010573</td>\n","      <td>0.863368</td>\n","      <td>0.855530</td>\n","      <td>0.872436</td>\n","      <td>0.983423</td>\n","      <td>0.983423</td>\n","      <td>0.983423</td>\n","      <td>0.808294</td>\n","      <td>0.798098</td>\n","      <td>0.818948</td>\n","      <td>0.956620</td>\n","      <td>0.967871</td>\n","      <td>0.945628</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.8634040837316834, 'eval_macro_precision': 0.8554623641102906, 'eval_macro_recall': 0.8725726055828732, 'eval_micro_f1': 0.9834229051547952, 'eval_micro_precision': 0.9834229051547952, 'eval_micro_recall': 0.9834229051547952, 'eval_macro_f1_no_o': 0.8085170131757987, 'eval_macro_precision_no_o': 0.7985319903499842, 'eval_macro_recall_no_o': 0.818947965186343, 'eval_micro_f1_no_o': 0.9568916619398752, 'eval_micro_precision_no_o': 0.9684270952927669, 'eval_micro_recall_no_o': 0.945627802690583, 'eval_loss': 0.010509900678852092, 'eval_runtime': 8.9701, 'eval_samples_per_second': 3.344, 'eval_steps_per_second': 0.223, 'epoch': 18.0}\n","Accuracy for fold  3 :  0.9568916619398752\n","--------------------------------\n","FOLD 4\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1930\n","  Num Epochs = 18\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2160\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2160' max='2160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2160/2160 26:18, Epoch 18/18]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.024000</td>\n","      <td>0.037842</td>\n","      <td>0.860108</td>\n","      <td>0.853152</td>\n","      <td>0.870895</td>\n","      <td>0.979710</td>\n","      <td>0.979710</td>\n","      <td>0.979710</td>\n","      <td>0.801698</td>\n","      <td>0.793181</td>\n","      <td>0.810650</td>\n","      <td>0.947400</td>\n","      <td>0.957357</td>\n","      <td>0.937647</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.005900</td>\n","      <td>0.022491</td>\n","      <td>0.869318</td>\n","      <td>0.868281</td>\n","      <td>0.873165</td>\n","      <td>0.982753</td>\n","      <td>0.982753</td>\n","      <td>0.982753</td>\n","      <td>0.803576</td>\n","      <td>0.796829</td>\n","      <td>0.810702</td>\n","      <td>0.949153</td>\n","      <td>0.959711</td>\n","      <td>0.938824</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.003400</td>\n","      <td>0.016529</td>\n","      <td>0.867219</td>\n","      <td>0.863225</td>\n","      <td>0.872343</td>\n","      <td>0.983846</td>\n","      <td>0.983846</td>\n","      <td>0.983846</td>\n","      <td>0.808631</td>\n","      <td>0.802372</td>\n","      <td>0.815195</td>\n","      <td>0.955952</td>\n","      <td>0.967470</td>\n","      <td>0.944706</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.002500</td>\n","      <td>0.017348</td>\n","      <td>0.869039</td>\n","      <td>0.866719</td>\n","      <td>0.873211</td>\n","      <td>0.984002</td>\n","      <td>0.984002</td>\n","      <td>0.984002</td>\n","      <td>0.807257</td>\n","      <td>0.802166</td>\n","      <td>0.812659</td>\n","      <td>0.954112</td>\n","      <td>0.966787</td>\n","      <td>0.941765</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.8691467972511843, 'eval_macro_precision': 0.8669332848852356, 'eval_macro_recall': 0.8732106964516684, 'eval_micro_f1': 0.9840018729514594, 'eval_micro_precision': 0.9840018729514594, 'eval_micro_recall': 0.9840018729514594, 'eval_macro_f1_no_o': 0.8075004272522932, 'eval_macro_precision_no_o': 0.8026482898846007, 'eval_macro_recall_no_o': 0.8126586887118538, 'eval_micro_f1_no_o': 0.9543964232488823, 'eval_micro_precision_no_o': 0.9673716012084592, 'eval_micro_recall_no_o': 0.941764705882353, 'eval_loss': 0.017144847932348738, 'eval_runtime': 8.7833, 'eval_samples_per_second': 3.416, 'eval_steps_per_second': 0.228, 'epoch': 18.0}\n","Accuracy for fold  4 :  0.9543964232488823\n","--------------------------------\n"]}],"source":["for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    #train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    #test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    local_train = []\n","    #i = 0\n","    for idx in train_ids:\n","      #if i <= 1920:\n","        local_train.append(dataset[idx])\n","      #i += 1\n","    \n","    local_test = []\n","    #i = 0\n","    for idx in test_ids:\n","      #if i <= 480:\n","        local_test.append(dataset[idx])\n","      #i += 1\n","\n","    training_args = TrainingArguments(\"trained_scibert_ner_model\", # output dir\n","                                      learning_rate=7.312253480818096e-05, \n","                                      num_train_epochs=18, \n","                                      per_device_eval_batch_size=16, \n","                                      per_device_train_batch_size=16,\n","                                      logging_steps=50,\n","                                      save_steps=len(train) // batch_size,\n","                                      lr_scheduler_type='cosine',\n","                                      evaluation_strategy='steps',\n","                                      weight_decay=0.10007182333796912,\n","                                      dataloader_drop_last=True,\n","                                      eval_steps=len(train) // batch_size\n","                                      )\n","\n","    #objective=9.177820413486334, hyperparameters={'learning_rate': 7.312253480818096e-05, 'num_train_epochs': 18, 'weight_decay': 0.10007182333796912, 'per_device_train_batch_size': 16}\n","\n","    # Init the neural network\n","    ner_model = NerModel(BertEmbModel).to('cuda')  # make sure we move the model to the GPU for training\n","    \n","    trainer = MultilabelTrainer(model=ner_model,\n","                                args=training_args,\n","                                train_dataset=local_train,\n","                                eval_dataset=local_test,\n","                                data_collator=collator  # defines how to merge data into batches, using the collator function above\n","                                )\n","\n","    ##Loading Best parameters\n","    #load_param()\n","\n","    #Training\n","    trainer.train()\n","          \n","    # Process is complete.\n","    print('Training process has finished. Saving trained model.')\n","\n","    # Print about testing\n","    print('Starting testing')\n","    \n","    # Saving the model\n","    save_path = f'./model-fold-{fold}.pth'\n","    torch.save(ner_model.state_dict(), save_path)\n","\n","    # Evaluationfor this fold\n","    #correct, total = 0, 0\n","    with torch.no_grad():\n","      result = trainer.evaluate(local_test)\n","      print(result)\n","\n","      # Print accuracy\n","      print('Accuracy for fold ', fold, ': ', result['eval_micro_f1_no_o'])\n","      print('--------------------------------')\n","      results[fold] = result['eval_micro_f1_no_o']\n","      resultss[fold] = result['eval_micro_f1']\n","      del result\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"BBA4owXH8oS1"},"source":["# Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dhusoblW-oCA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646900226749,"user_tz":360,"elapsed":10,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"3ad4fe65-e6f5-47e8-9e0a-423da3a00d11"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.76708795, 0.92512762, 0.95487933, 0.95689166, 0.95439642])"]},"metadata":{},"execution_count":22}],"source":["results"]},{"cell_type":"code","source":["resultss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L8lNxCB8Kkis","executionInfo":{"status":"ok","timestamp":1646900226750,"user_tz":360,"elapsed":9,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"34b1432c-c811-4b76-eedc-cc5284686c54"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.90661039, 0.96619271, 0.97927122, 0.98342291, 0.98400187])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yPIH-gt_-foF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646900226750,"user_tz":360,"elapsed":7,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"a1606ed7-3864-4075-c921-2925e774c6ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n","--------------------------------\n","Fold 0: 0.7670879546040753 %\n","Fold 1: 0.9251276233692569 %\n","Fold 2: 0.9548793284365162 %\n","Fold 3: 0.9568916619398752 %\n","Fold 4: 0.9543964232488823 %\n","Average: 0.9116765983197211 %\n"]}],"source":["# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","key = 0\n","for value in results:\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","  key += 1\n","print(f'Average: {sum/len(results)} %')"]},{"cell_type":"markdown","metadata":{"id":"1DkDHptAhniL"},"source":["# Pytorch Training - Loop UPDT"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"rirS-e83GVn0","executionInfo":{"status":"ok","timestamp":1647112702964,"user_tz":360,"elapsed":6,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"outputs":[],"source":["device = 'cuda'"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"KSDdzo_so0vk","executionInfo":{"status":"ok","timestamp":1647112702964,"user_tz":360,"elapsed":5,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"outputs":[],"source":["training_args = TrainingArguments(\"trained_scibert_ner_model\", # output dir\n","                                      learning_rate=7.312253480818096e-05, \n","                                      weight_decay=0.10007182333796912,\n","                                      num_train_epochs=18, \n","                                      per_device_eval_batch_size=16,\n","                                      per_device_train_batch_size=16,\n","                                      logging_steps=50,\n","                                      dataloader_drop_last=True,\n","                                      save_steps=len(train) // batch_size,\n","                                      eval_steps=len(train) // batch_size,\n","                                      lr_scheduler_type='cosine',\n","                                      evaluation_strategy='steps',\n","                                      report_to='all'#,\n","                                      #warmup_ratio=0.2\n","                                      )\n","\n","#objective=9.177820413486334, hyperparameters={'learning_rate': 7.312253480818096e-05, 'num_train_epochs': 18, 'weight_decay': 0.10007182333796912, 'per_device_train_batch_size': 16}\n","\n","#load_param()"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"12dfb79c-7ebf-471b-de13-4250669bc9ed","id":"nZR3aDuKyUqy","executionInfo":{"status":"ok","timestamp":1647128111231,"user_tz":360,"elapsed":15408272,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"source":["loop_val = 10\n","loop_results = np.zeros(loop_val)\n","loop_resultss = np.zeros(loop_val)\n","for r in range(loop_val):\n","\n","  ner_model = NerModel(BertEmbModel).to('cuda')  # make sure we move the model to the GPU for training\n","\n","  trainer = MultilabelTrainer(\n","      model=ner_model, \n","      args=training_args, \n","      train_dataset=train, \n","      eval_dataset=test,\n","      data_collator=collator  # defines how to merge data into batches, using the collator function above\n","  )\n","\n","  # Print\n","  print(f'Train run #{r}')\n","  print('--------------------------------')\n","\n","  trainer.train()\n","\n","  # Process is complete.\n","  print('Training process has finished.')\n","\n","  # Print about testing\n","  print('Starting testing')\n","\n","  with torch.no_grad():\n","    result = trainer.evaluate(test)\n","    print(result)\n","\n","    # Print accuracy\n","    print('Accuracy for fold ', r, ': ', result['eval_micro_f1_no_o'], ' -- ', result['eval_micro_f1'])\n","    print('--------------------------------')\n","    loop_results[r] = result['eval_micro_f1_no_o']\n","    loop_resultss[r] = result['eval_micro_f1']\n","    del result\n","\n","  if r > 0:\n","    if loop_results[r] < loop_results[r-1]:\n","      save_path = f'./model-fold-{r}.pth'\n","      torch.save(ner_model.state_dict(), save_path)\n","\n","  print('Testing process has finished.')"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 18\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2088\n"]},{"output_type":"stream","name":"stdout","text":["Train run #0\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2088' max='2088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2088/2088 32:56, Epoch 18/18]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.197500</td>\n","      <td>0.256987</td>\n","      <td>0.549061</td>\n","      <td>0.525094</td>\n","      <td>0.604708</td>\n","      <td>0.862315</td>\n","      <td>0.862315</td>\n","      <td>0.862315</td>\n","      <td>0.518161</td>\n","      <td>0.492385</td>\n","      <td>0.585836</td>\n","      <td>0.656703</td>\n","      <td>0.620870</td>\n","      <td>0.696925</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.021600</td>\n","      <td>0.144408</td>\n","      <td>0.602523</td>\n","      <td>0.590810</td>\n","      <td>0.636505</td>\n","      <td>0.886165</td>\n","      <td>0.886165</td>\n","      <td>0.886165</td>\n","      <td>0.591480</td>\n","      <td>0.634875</td>\n","      <td>0.570047</td>\n","      <td>0.734622</td>\n","      <td>0.756463</td>\n","      <td>0.714007</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.007500</td>\n","      <td>0.137608</td>\n","      <td>0.627181</td>\n","      <td>0.619105</td>\n","      <td>0.651614</td>\n","      <td>0.896185</td>\n","      <td>0.896185</td>\n","      <td>0.896185</td>\n","      <td>0.612155</td>\n","      <td>0.636840</td>\n","      <td>0.613104</td>\n","      <td>0.737208</td>\n","      <td>0.750632</td>\n","      <td>0.724256</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.005700</td>\n","      <td>0.145457</td>\n","      <td>0.624546</td>\n","      <td>0.610085</td>\n","      <td>0.648891</td>\n","      <td>0.896252</td>\n","      <td>0.896252</td>\n","      <td>0.896252</td>\n","      <td>0.607324</td>\n","      <td>0.615386</td>\n","      <td>0.612899</td>\n","      <td>0.732506</td>\n","      <td>0.745078</td>\n","      <td>0.720351</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 18\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2088\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_macro_f1': 0.6236314562541356, 'eval_macro_precision': 0.6096271766769739, 'eval_macro_recall': 0.6487817971512484, 'eval_micro_f1': 0.8958514262809807, 'eval_micro_precision': 0.8958514262809807, 'eval_micro_recall': 0.8958514262809807, 'eval_macro_f1_no_o': 0.605362454899944, 'eval_macro_precision_no_o': 0.6145997396581445, 'eval_macro_recall_no_o': 0.6121891666990802, 'eval_micro_f1_no_o': 0.7311507936507935, 'eval_micro_precision_no_o': 0.7433182047402925, 'eval_micro_recall_no_o': 0.7193753050268423, 'eval_loss': 0.14497827433762886, 'eval_runtime': 17.473, 'eval_samples_per_second': 1.946, 'eval_steps_per_second': 0.172, 'epoch': 18.0}\n","Accuracy for fold  0 :  0.7311507936507935  --  0.8958514262809807\n","--------------------------------\n","Testing process has finished.\n","Train run #1\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2088' max='2088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2088/2088 27:33, Epoch 18/18]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.031000</td>\n","      <td>0.208726</td>\n","      <td>0.541660</td>\n","      <td>0.553270</td>\n","      <td>0.585414</td>\n","      <td>0.873539</td>\n","      <td>0.873539</td>\n","      <td>0.873539</td>\n","      <td>0.446314</td>\n","      <td>0.497635</td>\n","      <td>0.510974</td>\n","      <td>0.633640</td>\n","      <td>0.613242</td>\n","      <td>0.655442</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.006800</td>\n","      <td>0.178377</td>\n","      <td>0.611572</td>\n","      <td>0.582396</td>\n","      <td>0.649786</td>\n","      <td>0.889104</td>\n","      <td>0.889104</td>\n","      <td>0.889104</td>\n","      <td>0.596919</td>\n","      <td>0.580688</td>\n","      <td>0.618913</td>\n","      <td>0.727900</td>\n","      <td>0.734592</td>\n","      <td>0.721327</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.003500</td>\n","      <td>0.175790</td>\n","      <td>0.621945</td>\n","      <td>0.600247</td>\n","      <td>0.647175</td>\n","      <td>0.891643</td>\n","      <td>0.891643</td>\n","      <td>0.891643</td>\n","      <td>0.597308</td>\n","      <td>0.582444</td>\n","      <td>0.613927</td>\n","      <td>0.721271</td>\n","      <td>0.722685</td>\n","      <td>0.719863</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.002800</td>\n","      <td>0.176204</td>\n","      <td>0.619732</td>\n","      <td>0.597640</td>\n","      <td>0.646486</td>\n","      <td>0.891509</td>\n","      <td>0.891509</td>\n","      <td>0.891509</td>\n","      <td>0.594249</td>\n","      <td>0.584966</td>\n","      <td>0.606846</td>\n","      <td>0.718012</td>\n","      <td>0.731275</td>\n","      <td>0.705222</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.6202406266089937, 'eval_macro_precision': 0.5981139902378512, 'eval_macro_recall': 0.6469948828093967, 'eval_micro_f1': 0.891642728305164, 'eval_micro_precision': 0.891642728305164, 'eval_micro_recall': 0.891642728305164, 'eval_macro_f1_no_o': 0.595077305398875, 'eval_macro_precision_no_o': 0.5859758271947498, 'eval_macro_recall_no_o': 0.6072391662186483, 'eval_micro_f1_no_o': 0.7183308494783904, 'eval_micro_precision_no_o': 0.7314112291350531, 'eval_micro_recall_no_o': 0.705710102489019, 'eval_loss': 0.17629705333303286, 'eval_runtime': 18.3261, 'eval_samples_per_second': 1.855, 'eval_steps_per_second': 0.164, 'epoch': 18.0}\n","Accuracy for fold  1 :  0.7183308494783904  --  0.891642728305164\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 18\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2088\n"]},{"output_type":"stream","name":"stdout","text":["Testing process has finished.\n","Train run #2\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2088' max='2088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2088/2088 24:51, Epoch 18/18]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.026000</td>\n","      <td>0.230619</td>\n","      <td>0.601984</td>\n","      <td>0.585470</td>\n","      <td>0.622117</td>\n","      <td>0.881889</td>\n","      <td>0.881889</td>\n","      <td>0.881889</td>\n","      <td>0.578336</td>\n","      <td>0.565583</td>\n","      <td>0.594549</td>\n","      <td>0.688835</td>\n","      <td>0.685176</td>\n","      <td>0.692533</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.005900</td>\n","      <td>0.189256</td>\n","      <td>0.598077</td>\n","      <td>0.584957</td>\n","      <td>0.617790</td>\n","      <td>0.880353</td>\n","      <td>0.880353</td>\n","      <td>0.880353</td>\n","      <td>0.574203</td>\n","      <td>0.583037</td>\n","      <td>0.571022</td>\n","      <td>0.690990</td>\n","      <td>0.703030</td>\n","      <td>0.679356</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.003300</td>\n","      <td>0.199106</td>\n","      <td>0.607154</td>\n","      <td>0.589020</td>\n","      <td>0.629236</td>\n","      <td>0.890240</td>\n","      <td>0.890240</td>\n","      <td>0.890240</td>\n","      <td>0.588152</td>\n","      <td>0.574714</td>\n","      <td>0.606076</td>\n","      <td>0.709136</td>\n","      <td>0.717641</td>\n","      <td>0.700830</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.002700</td>\n","      <td>0.189447</td>\n","      <td>0.618947</td>\n","      <td>0.605193</td>\n","      <td>0.637508</td>\n","      <td>0.888837</td>\n","      <td>0.888837</td>\n","      <td>0.888837</td>\n","      <td>0.593232</td>\n","      <td>0.579429</td>\n","      <td>0.609671</td>\n","      <td>0.711840</td>\n","      <td>0.713585</td>\n","      <td>0.710102</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.6189272656183084, 'eval_macro_precision': 0.6050576313086086, 'eval_macro_recall': 0.6376049620955514, 'eval_micro_f1': 0.8888369296546196, 'eval_micro_precision': 0.8888369296546196, 'eval_micro_recall': 0.8888369296546196, 'eval_macro_f1_no_o': 0.5933717550680305, 'eval_macro_precision_no_o': 0.5794761853246603, 'eval_macro_recall_no_o': 0.6098967492786549, 'eval_micro_f1_no_o': 0.7121545610173636, 'eval_micro_precision_no_o': 0.7137254901960784, 'eval_micro_recall_no_o': 0.7105905319668131, 'eval_loss': 0.18967018949438974, 'eval_runtime': 8.4418, 'eval_samples_per_second': 4.028, 'eval_steps_per_second': 0.355, 'epoch': 18.0}\n","Accuracy for fold  2 :  0.7121545610173636  --  0.8888369296546196\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 18\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2088\n"]},{"output_type":"stream","name":"stdout","text":["Testing process has finished.\n","Train run #3\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2088' max='2088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2088/2088 17:04, Epoch 18/18]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.022500</td>\n","      <td>0.223447</td>\n","      <td>0.598871</td>\n","      <td>0.572003</td>\n","      <td>0.642363</td>\n","      <td>0.871601</td>\n","      <td>0.871601</td>\n","      <td>0.871601</td>\n","      <td>0.576509</td>\n","      <td>0.581716</td>\n","      <td>0.580374</td>\n","      <td>0.691772</td>\n","      <td>0.733589</td>\n","      <td>0.654466</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.005700</td>\n","      <td>0.195170</td>\n","      <td>0.627640</td>\n","      <td>0.603329</td>\n","      <td>0.658847</td>\n","      <td>0.883893</td>\n","      <td>0.883893</td>\n","      <td>0.883893</td>\n","      <td>0.604543</td>\n","      <td>0.602315</td>\n","      <td>0.608341</td>\n","      <td>0.721491</td>\n","      <td>0.734818</td>\n","      <td>0.708638</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.003100</td>\n","      <td>0.188047</td>\n","      <td>0.619685</td>\n","      <td>0.589141</td>\n","      <td>0.671226</td>\n","      <td>0.884294</td>\n","      <td>0.884294</td>\n","      <td>0.884294</td>\n","      <td>0.580022</td>\n","      <td>0.565117</td>\n","      <td>0.604414</td>\n","      <td>0.705134</td>\n","      <td>0.706516</td>\n","      <td>0.703758</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.002700</td>\n","      <td>0.198359</td>\n","      <td>0.627778</td>\n","      <td>0.606438</td>\n","      <td>0.654213</td>\n","      <td>0.889639</td>\n","      <td>0.889639</td>\n","      <td>0.889639</td>\n","      <td>0.589479</td>\n","      <td>0.579251</td>\n","      <td>0.602558</td>\n","      <td>0.708642</td>\n","      <td>0.717141</td>\n","      <td>0.700342</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.626293836342925, 'eval_macro_precision': 0.6042731693315768, 'eval_macro_recall': 0.6537688081642284, 'eval_micro_f1': 0.8894381722225934, 'eval_micro_precision': 0.8894381722225934, 'eval_micro_recall': 0.8894381722225934, 'eval_macro_f1_no_o': 0.5865709891319316, 'eval_macro_precision_no_o': 0.574807416470776, 'eval_macro_recall_no_o': 0.6019967503329859, 'eval_micro_f1_no_o': 0.707305034550839, 'eval_micro_precision_no_o': 0.7154268597104343, 'eval_micro_recall_no_o': 0.6993655441678868, 'eval_loss': 0.1981472290992452, 'eval_runtime': 8.5128, 'eval_samples_per_second': 3.994, 'eval_steps_per_second': 0.352, 'epoch': 18.0}\n","Accuracy for fold  3 :  0.707305034550839  --  0.8894381722225934\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 18\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2088\n"]},{"output_type":"stream","name":"stdout","text":["Testing process has finished.\n","Train run #4\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2088' max='2088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2088/2088 17:35, Epoch 18/18]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.020900</td>\n","      <td>0.228018</td>\n","      <td>0.612021</td>\n","      <td>0.586428</td>\n","      <td>0.654525</td>\n","      <td>0.882691</td>\n","      <td>0.882691</td>\n","      <td>0.882691</td>\n","      <td>0.586926</td>\n","      <td>0.592378</td>\n","      <td>0.581628</td>\n","      <td>0.708062</td>\n","      <td>0.726992</td>\n","      <td>0.690093</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.005800</td>\n","      <td>0.209724</td>\n","      <td>0.616777</td>\n","      <td>0.598359</td>\n","      <td>0.648581</td>\n","      <td>0.886432</td>\n","      <td>0.886432</td>\n","      <td>0.886432</td>\n","      <td>0.589384</td>\n","      <td>0.586386</td>\n","      <td>0.593170</td>\n","      <td>0.712559</td>\n","      <td>0.720559</td>\n","      <td>0.704734</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.003300</td>\n","      <td>0.203363</td>\n","      <td>0.624866</td>\n","      <td>0.600350</td>\n","      <td>0.658289</td>\n","      <td>0.886365</td>\n","      <td>0.886365</td>\n","      <td>0.886365</td>\n","      <td>0.591928</td>\n","      <td>0.581356</td>\n","      <td>0.609687</td>\n","      <td>0.715070</td>\n","      <td>0.731496</td>\n","      <td>0.699366</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.002500</td>\n","      <td>0.203192</td>\n","      <td>0.627152</td>\n","      <td>0.603897</td>\n","      <td>0.656063</td>\n","      <td>0.886566</td>\n","      <td>0.886566</td>\n","      <td>0.886566</td>\n","      <td>0.592816</td>\n","      <td>0.583322</td>\n","      <td>0.606745</td>\n","      <td>0.718727</td>\n","      <td>0.732759</td>\n","      <td>0.705222</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 18\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2088\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_macro_f1': 0.6262540768209793, 'eval_macro_precision': 0.6033066710868323, 'eval_macro_recall': 0.6551521457459147, 'eval_micro_f1': 0.8869663972209232, 'eval_micro_precision': 0.8869663972209232, 'eval_micro_recall': 0.8869663972209232, 'eval_macro_f1_no_o': 0.5936366375766432, 'eval_macro_precision_no_o': 0.5846319089759197, 'eval_macro_recall_no_o': 0.6068572761943247, 'eval_micro_f1_no_o': 0.719084349340632, 'eval_micro_precision_no_o': 0.733502538071066, 'eval_micro_recall_no_o': 0.7052220595412396, 'eval_loss': 0.20376568511655999, 'eval_runtime': 11.0042, 'eval_samples_per_second': 3.09, 'eval_steps_per_second': 0.273, 'epoch': 18.0}\n","Accuracy for fold  4 :  0.719084349340632  --  0.8869663972209232\n","--------------------------------\n","Testing process has finished.\n","Train run #5\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2088' max='2088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2088/2088 25:51, Epoch 18/18]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.020300</td>\n","      <td>0.233255</td>\n","      <td>0.612345</td>\n","      <td>0.582042</td>\n","      <td>0.654671</td>\n","      <td>0.882424</td>\n","      <td>0.882424</td>\n","      <td>0.882424</td>\n","      <td>0.583041</td>\n","      <td>0.569873</td>\n","      <td>0.606351</td>\n","      <td>0.706527</td>\n","      <td>0.721628</td>\n","      <td>0.692045</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.005800</td>\n","      <td>0.221045</td>\n","      <td>0.621062</td>\n","      <td>0.602289</td>\n","      <td>0.651858</td>\n","      <td>0.881889</td>\n","      <td>0.881889</td>\n","      <td>0.881889</td>\n","      <td>0.595850</td>\n","      <td>0.616426</td>\n","      <td>0.580754</td>\n","      <td>0.708583</td>\n","      <td>0.761211</td>\n","      <td>0.662762</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.003000</td>\n","      <td>0.204446</td>\n","      <td>0.623855</td>\n","      <td>0.600352</td>\n","      <td>0.658451</td>\n","      <td>0.885296</td>\n","      <td>0.885296</td>\n","      <td>0.885296</td>\n","      <td>0.591343</td>\n","      <td>0.592645</td>\n","      <td>0.598254</td>\n","      <td>0.702053</td>\n","      <td>0.720823</td>\n","      <td>0.684236</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.002500</td>\n","      <td>0.202427</td>\n","      <td>0.635837</td>\n","      <td>0.618034</td>\n","      <td>0.661367</td>\n","      <td>0.886900</td>\n","      <td>0.886900</td>\n","      <td>0.886900</td>\n","      <td>0.600588</td>\n","      <td>0.604242</td>\n","      <td>0.601715</td>\n","      <td>0.713998</td>\n","      <td>0.737389</td>\n","      <td>0.692045</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.6357770462258489, 'eval_macro_precision': 0.6185249734790124, 'eval_macro_recall': 0.6603389859516633, 'eval_micro_f1': 0.8871668114102479, 'eval_micro_precision': 0.8871668114102479, 'eval_micro_recall': 0.8871668114102479, 'eval_macro_f1_no_o': 0.5992531005381695, 'eval_macro_precision_no_o': 0.6033519465984004, 'eval_macro_recall_no_o': 0.5994270554507405, 'eval_micro_f1_no_o': 0.7131003268795574, 'eval_micro_precision_no_o': 0.7354771784232366, 'eval_micro_recall_no_o': 0.6920448999511957, 'eval_loss': 0.202151770692925, 'eval_runtime': 21.1441, 'eval_samples_per_second': 1.608, 'eval_steps_per_second': 0.142, 'epoch': 18.0}\n","Accuracy for fold  5 :  0.7131003268795574  --  0.8871668114102479\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 18\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2088\n"]},{"output_type":"stream","name":"stdout","text":["Testing process has finished.\n","Train run #6\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2088' max='2088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2088/2088 28:21, Epoch 18/18]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.020500</td>\n","      <td>0.246665</td>\n","      <td>0.614451</td>\n","      <td>0.618294</td>\n","      <td>0.623217</td>\n","      <td>0.876879</td>\n","      <td>0.876879</td>\n","      <td>0.876879</td>\n","      <td>0.568581</td>\n","      <td>0.589915</td>\n","      <td>0.560230</td>\n","      <td>0.697698</td>\n","      <td>0.724265</td>\n","      <td>0.673011</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.005600</td>\n","      <td>0.201600</td>\n","      <td>0.624475</td>\n","      <td>0.602194</td>\n","      <td>0.652029</td>\n","      <td>0.881956</td>\n","      <td>0.881956</td>\n","      <td>0.881956</td>\n","      <td>0.601353</td>\n","      <td>0.588951</td>\n","      <td>0.618434</td>\n","      <td>0.711766</td>\n","      <td>0.704785</td>\n","      <td>0.718887</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.003000</td>\n","      <td>0.219289</td>\n","      <td>0.625991</td>\n","      <td>0.617778</td>\n","      <td>0.641449</td>\n","      <td>0.882958</td>\n","      <td>0.882958</td>\n","      <td>0.882958</td>\n","      <td>0.596004</td>\n","      <td>0.596671</td>\n","      <td>0.596100</td>\n","      <td>0.708480</td>\n","      <td>0.728962</td>\n","      <td>0.689117</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.002600</td>\n","      <td>0.210505</td>\n","      <td>0.625620</td>\n","      <td>0.612031</td>\n","      <td>0.647225</td>\n","      <td>0.881889</td>\n","      <td>0.881889</td>\n","      <td>0.881889</td>\n","      <td>0.596438</td>\n","      <td>0.599361</td>\n","      <td>0.595270</td>\n","      <td>0.707040</td>\n","      <td>0.731975</td>\n","      <td>0.683748</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.6265569187403321, 'eval_macro_precision': 0.6128499619554625, 'eval_macro_recall': 0.6477962679771095, 'eval_micro_f1': 0.8825572850557819, 'eval_micro_precision': 0.8825572850557819, 'eval_micro_recall': 0.8825572850557819, 'eval_macro_f1_no_o': 0.5979900880469745, 'eval_macro_precision_no_o': 0.5983116803907241, 'eval_macro_recall_no_o': 0.5993330527112974, 'eval_micro_f1_no_o': 0.7083019814396789, 'eval_micro_precision_no_o': 0.7285861713106295, 'eval_micro_recall_no_o': 0.6891166422645193, 'eval_loss': 0.20955406778328806, 'eval_runtime': 20.8066, 'eval_samples_per_second': 1.634, 'eval_steps_per_second': 0.144, 'epoch': 18.0}\n","Accuracy for fold  6 :  0.7083019814396789  --  0.8825572850557819\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 18\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2088\n"]},{"output_type":"stream","name":"stdout","text":["Testing process has finished.\n","Train run #7\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2088' max='2088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2088/2088 20:44, Epoch 18/18]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.021000</td>\n","      <td>0.233846</td>\n","      <td>0.601199</td>\n","      <td>0.581911</td>\n","      <td>0.633660</td>\n","      <td>0.879217</td>\n","      <td>0.879217</td>\n","      <td>0.879217</td>\n","      <td>0.561728</td>\n","      <td>0.566555</td>\n","      <td>0.572416</td>\n","      <td>0.690206</td>\n","      <td>0.731294</td>\n","      <td>0.653490</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.005300</td>\n","      <td>0.228877</td>\n","      <td>0.607768</td>\n","      <td>0.587925</td>\n","      <td>0.634219</td>\n","      <td>0.882624</td>\n","      <td>0.882624</td>\n","      <td>0.882624</td>\n","      <td>0.572833</td>\n","      <td>0.565498</td>\n","      <td>0.582940</td>\n","      <td>0.691231</td>\n","      <td>0.695846</td>\n","      <td>0.686676</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.003100</td>\n","      <td>0.207979</td>\n","      <td>0.611408</td>\n","      <td>0.588340</td>\n","      <td>0.641539</td>\n","      <td>0.881488</td>\n","      <td>0.881488</td>\n","      <td>0.881488</td>\n","      <td>0.570883</td>\n","      <td>0.555538</td>\n","      <td>0.593221</td>\n","      <td>0.691311</td>\n","      <td>0.680208</td>\n","      <td>0.702782</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.002600</td>\n","      <td>0.209124</td>\n","      <td>0.622653</td>\n","      <td>0.603307</td>\n","      <td>0.646135</td>\n","      <td>0.885497</td>\n","      <td>0.885497</td>\n","      <td>0.885497</td>\n","      <td>0.583989</td>\n","      <td>0.573485</td>\n","      <td>0.596884</td>\n","      <td>0.703758</td>\n","      <td>0.703758</td>\n","      <td>0.703758</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.6232660246700608, 'eval_macro_precision': 0.6032903059593534, 'eval_macro_recall': 0.6474978317405818, 'eval_micro_f1': 0.8856971073552008, 'eval_micro_precision': 0.8856971073552008, 'eval_micro_recall': 0.8856971073552008, 'eval_macro_f1_no_o': 0.5844156527968295, 'eval_macro_precision_no_o': 0.5737487471665035, 'eval_macro_recall_no_o': 0.5973904598860296, 'eval_micro_f1_no_o': 0.704562088314223, 'eval_micro_precision_no_o': 0.704390243902439, 'eval_micro_recall_no_o': 0.7047340165934602, 'eval_loss': 0.20870814300755736, 'eval_runtime': 11.0486, 'eval_samples_per_second': 3.077, 'eval_steps_per_second': 0.272, 'epoch': 18.0}\n","Accuracy for fold  7 :  0.704562088314223  --  0.8856971073552008\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 18\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2088\n"]},{"output_type":"stream","name":"stdout","text":["Testing process has finished.\n","Train run #8\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2088' max='2088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2088/2088 29:21, Epoch 18/18]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.019000</td>\n","      <td>0.221740</td>\n","      <td>0.623104</td>\n","      <td>0.595900</td>\n","      <td>0.659844</td>\n","      <td>0.878081</td>\n","      <td>0.878081</td>\n","      <td>0.878081</td>\n","      <td>0.586911</td>\n","      <td>0.587928</td>\n","      <td>0.586894</td>\n","      <td>0.711301</td>\n","      <td>0.734407</td>\n","      <td>0.689605</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.005100</td>\n","      <td>0.209570</td>\n","      <td>0.619125</td>\n","      <td>0.592982</td>\n","      <td>0.650965</td>\n","      <td>0.876344</td>\n","      <td>0.876344</td>\n","      <td>0.876344</td>\n","      <td>0.574471</td>\n","      <td>0.564311</td>\n","      <td>0.585924</td>\n","      <td>0.690096</td>\n","      <td>0.695050</td>\n","      <td>0.685212</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.003000</td>\n","      <td>0.209750</td>\n","      <td>0.629224</td>\n","      <td>0.614651</td>\n","      <td>0.648799</td>\n","      <td>0.881689</td>\n","      <td>0.881689</td>\n","      <td>0.881689</td>\n","      <td>0.588866</td>\n","      <td>0.588471</td>\n","      <td>0.593960</td>\n","      <td>0.699647</td>\n","      <td>0.724516</td>\n","      <td>0.676428</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.002600</td>\n","      <td>0.205319</td>\n","      <td>0.630405</td>\n","      <td>0.609352</td>\n","      <td>0.657116</td>\n","      <td>0.881355</td>\n","      <td>0.881355</td>\n","      <td>0.881355</td>\n","      <td>0.591421</td>\n","      <td>0.583893</td>\n","      <td>0.603638</td>\n","      <td>0.700995</td>\n","      <td>0.714866</td>\n","      <td>0.687653</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.6303027791108072, 'eval_macro_precision': 0.6092825178858684, 'eval_macro_recall': 0.6569619697722812, 'eval_micro_f1': 0.8815552141091589, 'eval_micro_precision': 0.8815552141091589, 'eval_micro_recall': 0.8815552141091589, 'eval_macro_f1_no_o': 0.5912689596722945, 'eval_macro_precision_no_o': 0.5839850408944831, 'eval_macro_recall_no_o': 0.6032444926124867, 'eval_micro_f1_no_o': 0.7008461921353907, 'eval_micro_precision_no_o': 0.7150837988826816, 'eval_micro_recall_no_o': 0.6871644704734017, 'eval_loss': 0.20565300843137427, 'eval_runtime': 22.2299, 'eval_samples_per_second': 1.529, 'eval_steps_per_second': 0.135, 'epoch': 18.0}\n","Accuracy for fold  8 :  0.7008461921353907  --  0.8815552141091589\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1861\n","  Num Epochs = 18\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2088\n"]},{"output_type":"stream","name":"stdout","text":["Testing process has finished.\n","Train run #9\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2088' max='2088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2088/2088 29:18, Epoch 18/18]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>465</td>\n","      <td>0.018800</td>\n","      <td>0.257365</td>\n","      <td>0.615533</td>\n","      <td>0.612316</td>\n","      <td>0.621629</td>\n","      <td>0.882825</td>\n","      <td>0.882825</td>\n","      <td>0.882825</td>\n","      <td>0.581714</td>\n","      <td>0.596209</td>\n","      <td>0.570543</td>\n","      <td>0.704189</td>\n","      <td>0.743757</td>\n","      <td>0.668619</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.005000</td>\n","      <td>0.225878</td>\n","      <td>0.613002</td>\n","      <td>0.586731</td>\n","      <td>0.646261</td>\n","      <td>0.877480</td>\n","      <td>0.877480</td>\n","      <td>0.877480</td>\n","      <td>0.577428</td>\n","      <td>0.571393</td>\n","      <td>0.584027</td>\n","      <td>0.699432</td>\n","      <td>0.708000</td>\n","      <td>0.691069</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.002900</td>\n","      <td>0.217064</td>\n","      <td>0.614541</td>\n","      <td>0.586560</td>\n","      <td>0.654304</td>\n","      <td>0.876478</td>\n","      <td>0.876478</td>\n","      <td>0.876478</td>\n","      <td>0.581557</td>\n","      <td>0.577635</td>\n","      <td>0.591438</td>\n","      <td>0.699597</td>\n","      <td>0.723293</td>\n","      <td>0.677404</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.002500</td>\n","      <td>0.222749</td>\n","      <td>0.617173</td>\n","      <td>0.595263</td>\n","      <td>0.647007</td>\n","      <td>0.880887</td>\n","      <td>0.880887</td>\n","      <td>0.880887</td>\n","      <td>0.580760</td>\n","      <td>0.577428</td>\n","      <td>0.590064</td>\n","      <td>0.696091</td>\n","      <td>0.720251</td>\n","      <td>0.673499</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-465\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-930\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1395\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-1860\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.6170570366609802, 'eval_macro_precision': 0.5951498257001102, 'eval_macro_recall': 0.6468058046197442, 'eval_micro_f1': 0.8809539715411852, 'eval_micro_precision': 0.8809539715411852, 'eval_micro_recall': 0.8809539715411852, 'eval_macro_f1_no_o': 0.5806954884868718, 'eval_macro_precision_no_o': 0.5772098963900101, 'eval_macro_recall_no_o': 0.5900644629793671, 'eval_micro_f1_no_o': 0.6959152798789712, 'eval_micro_precision_no_o': 0.7198748043818466, 'eval_micro_recall_no_o': 0.6734992679355783, 'eval_loss': 0.2227173379114601, 'eval_runtime': 21.8243, 'eval_samples_per_second': 1.558, 'eval_steps_per_second': 0.137, 'epoch': 18.0}\n","Accuracy for fold  9 :  0.6959152798789712  --  0.8809539715411852\n","--------------------------------\n","Testing process has finished.\n"]}]},{"cell_type":"code","source":["loop_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"idsauF6I7iVt","executionInfo":{"status":"ok","timestamp":1647128111231,"user_tz":360,"elapsed":14,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"1aac8954-85ac-497e-f205-ea73b9aaa336"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.73115079, 0.71833085, 0.71215456, 0.70730503, 0.71908435,\n","       0.71310033, 0.70830198, 0.70456209, 0.70084619, 0.69591528])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["loop_resultss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q2RgMCQi7iN_","executionInfo":{"status":"ok","timestamp":1647128111231,"user_tz":360,"elapsed":5,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"805aab8b-f085-45f2-d252-dd23824ccf13"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.89585143, 0.89164273, 0.88883693, 0.88943817, 0.8869664 ,\n","       0.88716681, 0.88255729, 0.88569711, 0.88155521, 0.88095397])"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["sum = 0.0\n","for value in loop_results:\n","  sum += value\n","print(f'Average micro_f1_no_o: {sum/len(loop_results)} %')\n","\n","sum = 0.0\n","for value in loop_resultss:\n","  sum += value\n","print(f'Average micro_f1: {sum/len(loop_results)} %')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QrlB7EQ17iKb","executionInfo":{"status":"ok","timestamp":1647128111232,"user_tz":360,"elapsed":5,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"55fbb03f-f815-4823-c04c-d6494dd5d019"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Average micro_f1_no_o: 0.7110751456685838 %\n","Average micro_f1: 0.8870666043155856 %\n"]}]},{"cell_type":"code","source":["ner_model = NerModel(BertEmbModel).to('cuda')  # make sure we move the model to the GPU for training\n","ner_model.load_state_dict(torch.load(save_path))\n","ner_model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q0v_Fe207iHX","executionInfo":{"status":"ok","timestamp":1647128111657,"user_tz":360,"elapsed":430,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"01e9fadb-a94e-48cc-a6c9-6b42044b2862"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NerModel(\n","  (sci_embeddings): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (embd_dropout): Dropout(p=0.1, inplace=False)\n","  (ff_dropout): Dropout(p=0.1, inplace=False)\n","  (ff): Linear(in_features=200, out_features=14, bias=True)\n","  (tanh): Tanh()\n","  (lstm): LSTM(768, 100, bidirectional=True)\n","  (lstm_drop): Dropout(p=0.4, inplace=False)\n","  (ff_act): ReLU()\n","  (classifier): Linear(in_features=14, out_features=13, bias=True)\n",")"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"dcdDIwq0kXy2"},"source":["# Get Values of Thruth"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"uCnsc2rplFzW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647128111658,"user_tz":360,"elapsed":4,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"1c0585b6-dd0f-4ecd-ad64-514566ac9d81"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["NerModel(\n","  (sci_embeddings): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (embd_dropout): Dropout(p=0.1, inplace=False)\n","  (ff_dropout): Dropout(p=0.1, inplace=False)\n","  (ff): Linear(in_features=200, out_features=14, bias=True)\n","  (tanh): Tanh()\n","  (lstm): LSTM(768, 100, bidirectional=True)\n","  (lstm_drop): Dropout(p=0.4, inplace=False)\n","  (ff_act): ReLU()\n","  (classifier): Linear(in_features=14, out_features=13, bias=True)\n",")"]},"metadata":{},"execution_count":27}],"source":["# Pytorch thing (if we aren't training, do this)\n","ner_model.eval()\n","ner_model.to('cuda')"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"FVfjoHmcI0pL","executionInfo":{"status":"ok","timestamp":1647128165390,"user_tz":360,"elapsed":53734,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"outputs":[],"source":["output_preds = []\n","output_real = []\n","for x in range(len(test)):\n","  inputs1 = test[x]['input_ids'][0].clone().detach().to(torch.long).unsqueeze(0).to('cuda')\n","  inputs2 = test[x]['attention_mask'][0].clone().detach().to(torch.long).unsqueeze(0).to('cuda')\n","  inputs = {'input_ids': inputs1,  'attention_mask': inputs2}\n","  #print(inputs)\n","\n","  temp_test = test[x]\n","  temp_out = temp_test.pop(\"labels\")\n","  output_real.append(np.array(temp_out[temp_out != -100])) \n","\n","  gen_preds = ner_model(**inputs)\n","  label_preds = np.argmax(gen_preds.cpu().detach().numpy(), axis=-1)[0]\n","  output_preds.append(label_preds[temp_out != -100])\n"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"mXBvXjpP-VGh","executionInfo":{"status":"ok","timestamp":1647128165391,"user_tz":360,"elapsed":5,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"outputs":[],"source":["for x in range(len(output_real)):\n","  output_real[x] = [ID2Entity(y) for y in output_real[x]]\n","  output_preds[x] = [ID2Entity(z) for z in output_preds[x]]"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"Pd1Xl1giQ7z7","executionInfo":{"status":"ok","timestamp":1647128165391,"user_tz":360,"elapsed":4,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"outputs":[],"source":["#output_real[28]"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"5rslGT68vvC8","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1647128166961,"user_tz":360,"elapsed":1573,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"2552b378-56dc-4e3a-d707-ba8691e725ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[10647    34    48    14    22    12     0    32    52   133   162    58\n","      3]\n"," [   21   184    12    15     4     4     0     5     0    15     2     0\n","      0]\n"," [   43    11   320     2    56     0     0     5    12    10    46     0\n","      0]\n"," [   28    38     1   296     3     3     0     2     0    52     1     6\n","      0]\n"," [   40     4    56    12   537     2     0     1     2     7    78     4\n","      4]\n"," [    7     1     0     2     0    55     0     0     0     4     1     1\n","      0]\n"," [   53     0     2     0     2     2     0     0     0     2     8     0\n","      0]\n"," [   17     3     3     0     0     0     0   117     7     9     1     1\n","      0]\n"," [   14     0     6     0     0     0     0     9   174     1    12     1\n","      0]\n"," [   49    22    12    29     0     7     0    22     1   353    20     5\n","      0]\n"," [   71     3    46     2    40     1     0     6    50    14   463     0\n","      2]\n"," [   42     2     1     4     1     2     0     1     0     2     0   184\n","      2]\n"," [    5     0     1     0     2     0     0     0     0     0     0     3\n","      5]]\n"]},{"output_type":"execute_result","data":{"text/plain":["<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7eff214d0390>"]},"metadata":{},"execution_count":31},{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x864 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["from sklearn.metrics import mean_squared_error, multilabel_confusion_matrix, confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support\n","import matplotlib.pyplot as plt\n","\n","plt.rcParams['figure.figsize'] = [15, 12]\n","plt.rcParams[\"figure.autolayout\"] = True\n","plt.rcParams.update({'font.size': 13})\n","\n","labels = [\"O\", \"B-Task\", \"I-Task\", \"B-Method\", \"I-Method\", \"B-Metric\", \"I-Metric\", \"B-Material\", \"I-Material\", \"B-OtherScientificTerm\", \"I-OtherScientificTerm\", \"B-Generic\", \"I-Generic\"]\n","cm = confusion_matrix(output_real[0], output_preds[0], labels=labels)\n","for x in range(len(output_real)-1):\n","  cm += confusion_matrix(output_real[x+1], output_preds[x+1], labels=labels)\n","print(cm)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n","disp.plot(cmap=plt.cm.Blues)"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"m10aBi5x5Hdb","executionInfo":{"status":"ok","timestamp":1647128166961,"user_tz":360,"elapsed":16,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"outputs":[],"source":["del cm"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"fgGd1XfheERK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647128166962,"user_tz":360,"elapsed":16,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"1cf0d613-54f1-436d-c751-b02211aa0326"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["551"]},"metadata":{},"execution_count":33}],"source":["len(output_real)"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"fHlg1QV3eZCa","executionInfo":{"status":"ok","timestamp":1647128166963,"user_tz":360,"elapsed":17,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}}},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"k0w9Lc0d3iOT"},"source":["# Test over Text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mgNM3p1q3hrf"},"outputs":[],"source":["def prepare_input(txt):\n","  inputs = BertTokenizer(txt, return_tensors='pt', padding='max_length', truncation=True, max_length=150).to('cuda')\n","  return inputs\n","\n","input_text = [\"English is shown to be trans-context-free on the basis of coordinations of the respectively type that involve strictly syntactic cross-serial agreement.\"]\n","##input_text = [\"The transient analysis of gyro-elastic structured media, composed of periodically placed masses interconnected by elastic rods and attached to gyroscopic spinners, is presented.\"] \n","##input_text = [\"The results indicated that thermal curing promoted the early strength of mortars, while decreased the late strength of mortars.\"] \n","##input_text = [\"A wide variety of processes are attested in the literature, and we find different forms of clippings in our data, including mixtures of different clippings, homophone respellings, phonetic respellings in-cluding informal oral forms, initialisms (but no acronyms), and mixtures of clipping together with homo-phone and phonetic respellings.\"] \n","\n","input_text = [\"The goal is to accurately predict the running time of applications for task scheduling and job migration.\"] \n","input_text = [\"This paper reports on the development of a cross-domain framework for describing complex design practices.\"] \n","input_text = [\"Studies of inequality in China typically ignore cost of liv-ing differences between areas.\"] \n","input_text = [\"The present study was designed to explore the long-term differences be-tween three mouse models for depression.\"]\n","input_text = [\"Finally, regarding professional competencies, teachers appeared to be largely unprepared to conduct language assessments consistent with the LAR demands.\"] \n","\n","##input_text = [\"propose a fast and reliable restoration method of virtual resources on OpenStack when physical servers or virtual machines are down.\"] \n","##input_text = [\"The results from our simulations reveal that the network assisted adaptation clearly outperforms the purely client-based DASH heuristics in some of the metrics, not all of them, particularly, in situations when the achievable throughput is moderately high or the link quality of the mobile clients does not differ from each other substantially.\"] \n","##input_text = [\"For hard rock drilling in coal mine, the drilling efficiency and service life of polycrystalline diamond compact bit are very low.\"] \n","##input_text = [\"Capturing changes in foreign reserves and exchange rates through the exchange market pressure, this article investigates whether economic policy uncertainty plays any role in exchange market pressure movements while controlling for the effects of domestic and external factors.\"] \n","##input_text = [\"This paper presents design of an self contained actuators unit in wide area damping control of power system in stabilizing system response for both nominal system condition and during actuator faults.\"] \n","\n","##input_text = [\"Ultrasound-based brain stimulation techniques may become a powerful new technique to modulate the human brain in a focal and targeted manner.\"] \n","input_text = [\"Recent work pre-training Transformers with self-supervised objectives on large text corpora has shown great success when fine-tuned on downstream NLP tasks including text summarization.\"]\n","\n","# Tokenize + pad\n","inputs = prepare_input(input_text)\n","\n","#inputs\n","#print(inputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1646696584344,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"jaG1vUq58BFI","outputId":"300ddd0a-c157-429b-ba97-7ec4c5fde292"},"outputs":[{"output_type":"stream","name":"stdout","text":["recent -> O\n","work -> O\n","pre -> B-Method\n","- -> O\n","training -> O\n","transformers -> B-Method\n","with -> O\n","self -> B-OtherScientificTerm\n","- -> O\n","supervised -> I-OtherScientificTerm\n","objectives -> I-OtherScientificTerm\n","on -> O\n","large -> B-Material\n","text -> I-Material\n","corpora -> I-Material\n","has -> O\n","shown -> O\n","great -> O\n","success -> O\n","when -> O\n","fine -> O\n","- -> O\n","tuned -> O\n","on -> O\n","downstream -> B-Task\n","nl -> I-Task\n","##p -> O\n","tasks -> I-Task\n","including -> O\n","text -> B-Task\n","summar -> I-Task\n","##ization -> I-Task\n",". -> O\n"]}],"source":["# Pytorch thing (if we aren't training, do this)\n","ner_model.eval()\n","\n","# Get predictions\n","preds = ner_model(**inputs).cpu().detach().numpy()\n","preds = np.argmax(preds, axis=-1)[0]\n","pred_labels = [ID2Entity(x) for x in preds]\n","\n","# Convert token ids to text\n","tokens = BertTokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n","\n","# Display result\n","for token, label in zip(tokens, pred_labels):\n","  if token == '[SEP]':\n","    break\n","  if token == '[CLS]':\n","    continue\n","  print('{} -> {}'.format(token, label))"]},{"cell_type":"markdown","metadata":{"id":"hC35X0v72kXB"},"source":["# Model Save and Load"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":158,"status":"ok","timestamp":1637844465024,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"AnK4H5vP2kJU","outputId":"73e317f0-1cc0-4962-a048-cc7352855f38"},"outputs":[{"name":"stdout","output_type":"stream","text":["Our model: \n","\n"," NerModel(\n","  (sci_embeddings): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (embd_dropout): Dropout(p=0.1, inplace=False)\n","  (ff_dropout): Dropout(p=0.1, inplace=False)\n","  (ff): Linear(in_features=200, out_features=14, bias=True)\n","  (tanh): Tanh()\n","  (lstm): LSTM(768, 100, bidirectional=True)\n","  (lstm_drop): Dropout(p=0.4, inplace=False)\n","  (ff_act): ReLU()\n","  (classifier): Linear(in_features=14, out_features=7, bias=True)\n",") \n","\n","The state dict keys: \n","\n"," odict_keys(['sci_embeddings.embeddings.position_ids', 'sci_embeddings.embeddings.word_embeddings.weight', 'sci_embeddings.embeddings.position_embeddings.weight', 'sci_embeddings.embeddings.token_type_embeddings.weight', 'sci_embeddings.embeddings.LayerNorm.weight', 'sci_embeddings.embeddings.LayerNorm.bias', 'sci_embeddings.encoder.layer.0.attention.self.query.weight', 'sci_embeddings.encoder.layer.0.attention.self.query.bias', 'sci_embeddings.encoder.layer.0.attention.self.key.weight', 'sci_embeddings.encoder.layer.0.attention.self.key.bias', 'sci_embeddings.encoder.layer.0.attention.self.value.weight', 'sci_embeddings.encoder.layer.0.attention.self.value.bias', 'sci_embeddings.encoder.layer.0.attention.output.dense.weight', 'sci_embeddings.encoder.layer.0.attention.output.dense.bias', 'sci_embeddings.encoder.layer.0.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.0.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.0.intermediate.dense.weight', 'sci_embeddings.encoder.layer.0.intermediate.dense.bias', 'sci_embeddings.encoder.layer.0.output.dense.weight', 'sci_embeddings.encoder.layer.0.output.dense.bias', 'sci_embeddings.encoder.layer.0.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.0.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.1.attention.self.query.weight', 'sci_embeddings.encoder.layer.1.attention.self.query.bias', 'sci_embeddings.encoder.layer.1.attention.self.key.weight', 'sci_embeddings.encoder.layer.1.attention.self.key.bias', 'sci_embeddings.encoder.layer.1.attention.self.value.weight', 'sci_embeddings.encoder.layer.1.attention.self.value.bias', 'sci_embeddings.encoder.layer.1.attention.output.dense.weight', 'sci_embeddings.encoder.layer.1.attention.output.dense.bias', 'sci_embeddings.encoder.layer.1.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.1.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.1.intermediate.dense.weight', 'sci_embeddings.encoder.layer.1.intermediate.dense.bias', 'sci_embeddings.encoder.layer.1.output.dense.weight', 'sci_embeddings.encoder.layer.1.output.dense.bias', 'sci_embeddings.encoder.layer.1.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.1.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.2.attention.self.query.weight', 'sci_embeddings.encoder.layer.2.attention.self.query.bias', 'sci_embeddings.encoder.layer.2.attention.self.key.weight', 'sci_embeddings.encoder.layer.2.attention.self.key.bias', 'sci_embeddings.encoder.layer.2.attention.self.value.weight', 'sci_embeddings.encoder.layer.2.attention.self.value.bias', 'sci_embeddings.encoder.layer.2.attention.output.dense.weight', 'sci_embeddings.encoder.layer.2.attention.output.dense.bias', 'sci_embeddings.encoder.layer.2.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.2.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.2.intermediate.dense.weight', 'sci_embeddings.encoder.layer.2.intermediate.dense.bias', 'sci_embeddings.encoder.layer.2.output.dense.weight', 'sci_embeddings.encoder.layer.2.output.dense.bias', 'sci_embeddings.encoder.layer.2.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.2.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.3.attention.self.query.weight', 'sci_embeddings.encoder.layer.3.attention.self.query.bias', 'sci_embeddings.encoder.layer.3.attention.self.key.weight', 'sci_embeddings.encoder.layer.3.attention.self.key.bias', 'sci_embeddings.encoder.layer.3.attention.self.value.weight', 'sci_embeddings.encoder.layer.3.attention.self.value.bias', 'sci_embeddings.encoder.layer.3.attention.output.dense.weight', 'sci_embeddings.encoder.layer.3.attention.output.dense.bias', 'sci_embeddings.encoder.layer.3.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.3.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.3.intermediate.dense.weight', 'sci_embeddings.encoder.layer.3.intermediate.dense.bias', 'sci_embeddings.encoder.layer.3.output.dense.weight', 'sci_embeddings.encoder.layer.3.output.dense.bias', 'sci_embeddings.encoder.layer.3.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.3.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.4.attention.self.query.weight', 'sci_embeddings.encoder.layer.4.attention.self.query.bias', 'sci_embeddings.encoder.layer.4.attention.self.key.weight', 'sci_embeddings.encoder.layer.4.attention.self.key.bias', 'sci_embeddings.encoder.layer.4.attention.self.value.weight', 'sci_embeddings.encoder.layer.4.attention.self.value.bias', 'sci_embeddings.encoder.layer.4.attention.output.dense.weight', 'sci_embeddings.encoder.layer.4.attention.output.dense.bias', 'sci_embeddings.encoder.layer.4.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.4.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.4.intermediate.dense.weight', 'sci_embeddings.encoder.layer.4.intermediate.dense.bias', 'sci_embeddings.encoder.layer.4.output.dense.weight', 'sci_embeddings.encoder.layer.4.output.dense.bias', 'sci_embeddings.encoder.layer.4.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.4.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.5.attention.self.query.weight', 'sci_embeddings.encoder.layer.5.attention.self.query.bias', 'sci_embeddings.encoder.layer.5.attention.self.key.weight', 'sci_embeddings.encoder.layer.5.attention.self.key.bias', 'sci_embeddings.encoder.layer.5.attention.self.value.weight', 'sci_embeddings.encoder.layer.5.attention.self.value.bias', 'sci_embeddings.encoder.layer.5.attention.output.dense.weight', 'sci_embeddings.encoder.layer.5.attention.output.dense.bias', 'sci_embeddings.encoder.layer.5.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.5.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.5.intermediate.dense.weight', 'sci_embeddings.encoder.layer.5.intermediate.dense.bias', 'sci_embeddings.encoder.layer.5.output.dense.weight', 'sci_embeddings.encoder.layer.5.output.dense.bias', 'sci_embeddings.encoder.layer.5.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.5.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.6.attention.self.query.weight', 'sci_embeddings.encoder.layer.6.attention.self.query.bias', 'sci_embeddings.encoder.layer.6.attention.self.key.weight', 'sci_embeddings.encoder.layer.6.attention.self.key.bias', 'sci_embeddings.encoder.layer.6.attention.self.value.weight', 'sci_embeddings.encoder.layer.6.attention.self.value.bias', 'sci_embeddings.encoder.layer.6.attention.output.dense.weight', 'sci_embeddings.encoder.layer.6.attention.output.dense.bias', 'sci_embeddings.encoder.layer.6.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.6.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.6.intermediate.dense.weight', 'sci_embeddings.encoder.layer.6.intermediate.dense.bias', 'sci_embeddings.encoder.layer.6.output.dense.weight', 'sci_embeddings.encoder.layer.6.output.dense.bias', 'sci_embeddings.encoder.layer.6.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.6.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.7.attention.self.query.weight', 'sci_embeddings.encoder.layer.7.attention.self.query.bias', 'sci_embeddings.encoder.layer.7.attention.self.key.weight', 'sci_embeddings.encoder.layer.7.attention.self.key.bias', 'sci_embeddings.encoder.layer.7.attention.self.value.weight', 'sci_embeddings.encoder.layer.7.attention.self.value.bias', 'sci_embeddings.encoder.layer.7.attention.output.dense.weight', 'sci_embeddings.encoder.layer.7.attention.output.dense.bias', 'sci_embeddings.encoder.layer.7.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.7.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.7.intermediate.dense.weight', 'sci_embeddings.encoder.layer.7.intermediate.dense.bias', 'sci_embeddings.encoder.layer.7.output.dense.weight', 'sci_embeddings.encoder.layer.7.output.dense.bias', 'sci_embeddings.encoder.layer.7.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.7.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.8.attention.self.query.weight', 'sci_embeddings.encoder.layer.8.attention.self.query.bias', 'sci_embeddings.encoder.layer.8.attention.self.key.weight', 'sci_embeddings.encoder.layer.8.attention.self.key.bias', 'sci_embeddings.encoder.layer.8.attention.self.value.weight', 'sci_embeddings.encoder.layer.8.attention.self.value.bias', 'sci_embeddings.encoder.layer.8.attention.output.dense.weight', 'sci_embeddings.encoder.layer.8.attention.output.dense.bias', 'sci_embeddings.encoder.layer.8.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.8.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.8.intermediate.dense.weight', 'sci_embeddings.encoder.layer.8.intermediate.dense.bias', 'sci_embeddings.encoder.layer.8.output.dense.weight', 'sci_embeddings.encoder.layer.8.output.dense.bias', 'sci_embeddings.encoder.layer.8.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.8.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.9.attention.self.query.weight', 'sci_embeddings.encoder.layer.9.attention.self.query.bias', 'sci_embeddings.encoder.layer.9.attention.self.key.weight', 'sci_embeddings.encoder.layer.9.attention.self.key.bias', 'sci_embeddings.encoder.layer.9.attention.self.value.weight', 'sci_embeddings.encoder.layer.9.attention.self.value.bias', 'sci_embeddings.encoder.layer.9.attention.output.dense.weight', 'sci_embeddings.encoder.layer.9.attention.output.dense.bias', 'sci_embeddings.encoder.layer.9.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.9.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.9.intermediate.dense.weight', 'sci_embeddings.encoder.layer.9.intermediate.dense.bias', 'sci_embeddings.encoder.layer.9.output.dense.weight', 'sci_embeddings.encoder.layer.9.output.dense.bias', 'sci_embeddings.encoder.layer.9.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.9.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.10.attention.self.query.weight', 'sci_embeddings.encoder.layer.10.attention.self.query.bias', 'sci_embeddings.encoder.layer.10.attention.self.key.weight', 'sci_embeddings.encoder.layer.10.attention.self.key.bias', 'sci_embeddings.encoder.layer.10.attention.self.value.weight', 'sci_embeddings.encoder.layer.10.attention.self.value.bias', 'sci_embeddings.encoder.layer.10.attention.output.dense.weight', 'sci_embeddings.encoder.layer.10.attention.output.dense.bias', 'sci_embeddings.encoder.layer.10.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.10.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.10.intermediate.dense.weight', 'sci_embeddings.encoder.layer.10.intermediate.dense.bias', 'sci_embeddings.encoder.layer.10.output.dense.weight', 'sci_embeddings.encoder.layer.10.output.dense.bias', 'sci_embeddings.encoder.layer.10.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.10.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.11.attention.self.query.weight', 'sci_embeddings.encoder.layer.11.attention.self.query.bias', 'sci_embeddings.encoder.layer.11.attention.self.key.weight', 'sci_embeddings.encoder.layer.11.attention.self.key.bias', 'sci_embeddings.encoder.layer.11.attention.self.value.weight', 'sci_embeddings.encoder.layer.11.attention.self.value.bias', 'sci_embeddings.encoder.layer.11.attention.output.dense.weight', 'sci_embeddings.encoder.layer.11.attention.output.dense.bias', 'sci_embeddings.encoder.layer.11.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.11.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.11.intermediate.dense.weight', 'sci_embeddings.encoder.layer.11.intermediate.dense.bias', 'sci_embeddings.encoder.layer.11.output.dense.weight', 'sci_embeddings.encoder.layer.11.output.dense.bias', 'sci_embeddings.encoder.layer.11.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.11.output.LayerNorm.bias', 'sci_embeddings.pooler.dense.weight', 'sci_embeddings.pooler.dense.bias', 'ff.weight', 'ff.bias', 'lstm.weight_ih_l0', 'lstm.weight_hh_l0', 'lstm.bias_ih_l0', 'lstm.bias_hh_l0', 'lstm.weight_ih_l0_reverse', 'lstm.weight_hh_l0_reverse', 'lstm.bias_ih_l0_reverse', 'lstm.bias_hh_l0_reverse', 'classifier.weight', 'classifier.bias'])\n"]}],"source":["print(\"Our model: \\n\\n\", ner_model, '\\n')\n","print(\"The state dict keys: \\n\\n\", ner_model.state_dict().keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KftdO6GD2rWF"},"outputs":[],"source":["torch.save(ner_model.state_dict(), 'trained_model_dic.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1637655583613,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"kd4NJxK14P14","outputId":"8a1acc1b-ac77-4f86-f888-de233967043d"},"outputs":[{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_c004abdd-a72a-4d8d-94ca-c82c3c4c2640\", \"trained_model_dic.pth\", 442559655)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["# download checkpoint file\n","files.download('trained_model_dic.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1637655465909,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"l1hvL5Nb3kmo","outputId":"a2910628-2592-4edd-b135-c329d0352c5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["checkpoint.pth\t  model-fold-1.pth  model-fold-4.pth  trained_model_dic.pth\n","dev.json\t  model-fold-2.pth  sample_data       trained_scibert_ner_model\n","model-fold-0.pth  model-fold-3.pth  test.json\t      train.json\n"]}],"source":["!ls"]},{"cell_type":"markdown","metadata":{"id":"hQL7fqSY2x9e"},"source":["Loading the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":374,"status":"ok","timestamp":1638229478125,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"2ufmrdfeT6Qz","outputId":"a0fce754-147a-4881-e006-0e812e6bbdeb"},"outputs":[{"name":"stdout","output_type":"stream","text":["dev.json  sample_data  test.json  trained_model_dic.pth  train.json\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10317,"status":"ok","timestamp":1638229490872,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"a4Eus2gmJ-bS","outputId":"a7212f4c-979a-40fe-afc6-937b5651e87b"},"outputs":[{"name":"stdout","output_type":"stream","text":["odict_keys(['sci_embeddings.embeddings.position_ids', 'sci_embeddings.embeddings.word_embeddings.weight', 'sci_embeddings.embeddings.position_embeddings.weight', 'sci_embeddings.embeddings.token_type_embeddings.weight', 'sci_embeddings.embeddings.LayerNorm.weight', 'sci_embeddings.embeddings.LayerNorm.bias', 'sci_embeddings.encoder.layer.0.attention.self.query.weight', 'sci_embeddings.encoder.layer.0.attention.self.query.bias', 'sci_embeddings.encoder.layer.0.attention.self.key.weight', 'sci_embeddings.encoder.layer.0.attention.self.key.bias', 'sci_embeddings.encoder.layer.0.attention.self.value.weight', 'sci_embeddings.encoder.layer.0.attention.self.value.bias', 'sci_embeddings.encoder.layer.0.attention.output.dense.weight', 'sci_embeddings.encoder.layer.0.attention.output.dense.bias', 'sci_embeddings.encoder.layer.0.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.0.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.0.intermediate.dense.weight', 'sci_embeddings.encoder.layer.0.intermediate.dense.bias', 'sci_embeddings.encoder.layer.0.output.dense.weight', 'sci_embeddings.encoder.layer.0.output.dense.bias', 'sci_embeddings.encoder.layer.0.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.0.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.1.attention.self.query.weight', 'sci_embeddings.encoder.layer.1.attention.self.query.bias', 'sci_embeddings.encoder.layer.1.attention.self.key.weight', 'sci_embeddings.encoder.layer.1.attention.self.key.bias', 'sci_embeddings.encoder.layer.1.attention.self.value.weight', 'sci_embeddings.encoder.layer.1.attention.self.value.bias', 'sci_embeddings.encoder.layer.1.attention.output.dense.weight', 'sci_embeddings.encoder.layer.1.attention.output.dense.bias', 'sci_embeddings.encoder.layer.1.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.1.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.1.intermediate.dense.weight', 'sci_embeddings.encoder.layer.1.intermediate.dense.bias', 'sci_embeddings.encoder.layer.1.output.dense.weight', 'sci_embeddings.encoder.layer.1.output.dense.bias', 'sci_embeddings.encoder.layer.1.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.1.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.2.attention.self.query.weight', 'sci_embeddings.encoder.layer.2.attention.self.query.bias', 'sci_embeddings.encoder.layer.2.attention.self.key.weight', 'sci_embeddings.encoder.layer.2.attention.self.key.bias', 'sci_embeddings.encoder.layer.2.attention.self.value.weight', 'sci_embeddings.encoder.layer.2.attention.self.value.bias', 'sci_embeddings.encoder.layer.2.attention.output.dense.weight', 'sci_embeddings.encoder.layer.2.attention.output.dense.bias', 'sci_embeddings.encoder.layer.2.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.2.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.2.intermediate.dense.weight', 'sci_embeddings.encoder.layer.2.intermediate.dense.bias', 'sci_embeddings.encoder.layer.2.output.dense.weight', 'sci_embeddings.encoder.layer.2.output.dense.bias', 'sci_embeddings.encoder.layer.2.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.2.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.3.attention.self.query.weight', 'sci_embeddings.encoder.layer.3.attention.self.query.bias', 'sci_embeddings.encoder.layer.3.attention.self.key.weight', 'sci_embeddings.encoder.layer.3.attention.self.key.bias', 'sci_embeddings.encoder.layer.3.attention.self.value.weight', 'sci_embeddings.encoder.layer.3.attention.self.value.bias', 'sci_embeddings.encoder.layer.3.attention.output.dense.weight', 'sci_embeddings.encoder.layer.3.attention.output.dense.bias', 'sci_embeddings.encoder.layer.3.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.3.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.3.intermediate.dense.weight', 'sci_embeddings.encoder.layer.3.intermediate.dense.bias', 'sci_embeddings.encoder.layer.3.output.dense.weight', 'sci_embeddings.encoder.layer.3.output.dense.bias', 'sci_embeddings.encoder.layer.3.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.3.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.4.attention.self.query.weight', 'sci_embeddings.encoder.layer.4.attention.self.query.bias', 'sci_embeddings.encoder.layer.4.attention.self.key.weight', 'sci_embeddings.encoder.layer.4.attention.self.key.bias', 'sci_embeddings.encoder.layer.4.attention.self.value.weight', 'sci_embeddings.encoder.layer.4.attention.self.value.bias', 'sci_embeddings.encoder.layer.4.attention.output.dense.weight', 'sci_embeddings.encoder.layer.4.attention.output.dense.bias', 'sci_embeddings.encoder.layer.4.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.4.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.4.intermediate.dense.weight', 'sci_embeddings.encoder.layer.4.intermediate.dense.bias', 'sci_embeddings.encoder.layer.4.output.dense.weight', 'sci_embeddings.encoder.layer.4.output.dense.bias', 'sci_embeddings.encoder.layer.4.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.4.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.5.attention.self.query.weight', 'sci_embeddings.encoder.layer.5.attention.self.query.bias', 'sci_embeddings.encoder.layer.5.attention.self.key.weight', 'sci_embeddings.encoder.layer.5.attention.self.key.bias', 'sci_embeddings.encoder.layer.5.attention.self.value.weight', 'sci_embeddings.encoder.layer.5.attention.self.value.bias', 'sci_embeddings.encoder.layer.5.attention.output.dense.weight', 'sci_embeddings.encoder.layer.5.attention.output.dense.bias', 'sci_embeddings.encoder.layer.5.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.5.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.5.intermediate.dense.weight', 'sci_embeddings.encoder.layer.5.intermediate.dense.bias', 'sci_embeddings.encoder.layer.5.output.dense.weight', 'sci_embeddings.encoder.layer.5.output.dense.bias', 'sci_embeddings.encoder.layer.5.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.5.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.6.attention.self.query.weight', 'sci_embeddings.encoder.layer.6.attention.self.query.bias', 'sci_embeddings.encoder.layer.6.attention.self.key.weight', 'sci_embeddings.encoder.layer.6.attention.self.key.bias', 'sci_embeddings.encoder.layer.6.attention.self.value.weight', 'sci_embeddings.encoder.layer.6.attention.self.value.bias', 'sci_embeddings.encoder.layer.6.attention.output.dense.weight', 'sci_embeddings.encoder.layer.6.attention.output.dense.bias', 'sci_embeddings.encoder.layer.6.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.6.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.6.intermediate.dense.weight', 'sci_embeddings.encoder.layer.6.intermediate.dense.bias', 'sci_embeddings.encoder.layer.6.output.dense.weight', 'sci_embeddings.encoder.layer.6.output.dense.bias', 'sci_embeddings.encoder.layer.6.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.6.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.7.attention.self.query.weight', 'sci_embeddings.encoder.layer.7.attention.self.query.bias', 'sci_embeddings.encoder.layer.7.attention.self.key.weight', 'sci_embeddings.encoder.layer.7.attention.self.key.bias', 'sci_embeddings.encoder.layer.7.attention.self.value.weight', 'sci_embeddings.encoder.layer.7.attention.self.value.bias', 'sci_embeddings.encoder.layer.7.attention.output.dense.weight', 'sci_embeddings.encoder.layer.7.attention.output.dense.bias', 'sci_embeddings.encoder.layer.7.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.7.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.7.intermediate.dense.weight', 'sci_embeddings.encoder.layer.7.intermediate.dense.bias', 'sci_embeddings.encoder.layer.7.output.dense.weight', 'sci_embeddings.encoder.layer.7.output.dense.bias', 'sci_embeddings.encoder.layer.7.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.7.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.8.attention.self.query.weight', 'sci_embeddings.encoder.layer.8.attention.self.query.bias', 'sci_embeddings.encoder.layer.8.attention.self.key.weight', 'sci_embeddings.encoder.layer.8.attention.self.key.bias', 'sci_embeddings.encoder.layer.8.attention.self.value.weight', 'sci_embeddings.encoder.layer.8.attention.self.value.bias', 'sci_embeddings.encoder.layer.8.attention.output.dense.weight', 'sci_embeddings.encoder.layer.8.attention.output.dense.bias', 'sci_embeddings.encoder.layer.8.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.8.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.8.intermediate.dense.weight', 'sci_embeddings.encoder.layer.8.intermediate.dense.bias', 'sci_embeddings.encoder.layer.8.output.dense.weight', 'sci_embeddings.encoder.layer.8.output.dense.bias', 'sci_embeddings.encoder.layer.8.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.8.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.9.attention.self.query.weight', 'sci_embeddings.encoder.layer.9.attention.self.query.bias', 'sci_embeddings.encoder.layer.9.attention.self.key.weight', 'sci_embeddings.encoder.layer.9.attention.self.key.bias', 'sci_embeddings.encoder.layer.9.attention.self.value.weight', 'sci_embeddings.encoder.layer.9.attention.self.value.bias', 'sci_embeddings.encoder.layer.9.attention.output.dense.weight', 'sci_embeddings.encoder.layer.9.attention.output.dense.bias', 'sci_embeddings.encoder.layer.9.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.9.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.9.intermediate.dense.weight', 'sci_embeddings.encoder.layer.9.intermediate.dense.bias', 'sci_embeddings.encoder.layer.9.output.dense.weight', 'sci_embeddings.encoder.layer.9.output.dense.bias', 'sci_embeddings.encoder.layer.9.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.9.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.10.attention.self.query.weight', 'sci_embeddings.encoder.layer.10.attention.self.query.bias', 'sci_embeddings.encoder.layer.10.attention.self.key.weight', 'sci_embeddings.encoder.layer.10.attention.self.key.bias', 'sci_embeddings.encoder.layer.10.attention.self.value.weight', 'sci_embeddings.encoder.layer.10.attention.self.value.bias', 'sci_embeddings.encoder.layer.10.attention.output.dense.weight', 'sci_embeddings.encoder.layer.10.attention.output.dense.bias', 'sci_embeddings.encoder.layer.10.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.10.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.10.intermediate.dense.weight', 'sci_embeddings.encoder.layer.10.intermediate.dense.bias', 'sci_embeddings.encoder.layer.10.output.dense.weight', 'sci_embeddings.encoder.layer.10.output.dense.bias', 'sci_embeddings.encoder.layer.10.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.10.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.11.attention.self.query.weight', 'sci_embeddings.encoder.layer.11.attention.self.query.bias', 'sci_embeddings.encoder.layer.11.attention.self.key.weight', 'sci_embeddings.encoder.layer.11.attention.self.key.bias', 'sci_embeddings.encoder.layer.11.attention.self.value.weight', 'sci_embeddings.encoder.layer.11.attention.self.value.bias', 'sci_embeddings.encoder.layer.11.attention.output.dense.weight', 'sci_embeddings.encoder.layer.11.attention.output.dense.bias', 'sci_embeddings.encoder.layer.11.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.11.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.11.intermediate.dense.weight', 'sci_embeddings.encoder.layer.11.intermediate.dense.bias', 'sci_embeddings.encoder.layer.11.output.dense.weight', 'sci_embeddings.encoder.layer.11.output.dense.bias', 'sci_embeddings.encoder.layer.11.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.11.output.LayerNorm.bias', 'sci_embeddings.pooler.dense.weight', 'sci_embeddings.pooler.dense.bias', 'ff.weight', 'ff.bias', 'lstm.weight_ih_l0', 'lstm.weight_hh_l0', 'lstm.bias_ih_l0', 'lstm.bias_hh_l0', 'lstm.weight_ih_l0_reverse', 'lstm.weight_hh_l0_reverse', 'lstm.bias_ih_l0_reverse', 'lstm.bias_hh_l0_reverse', 'classifier.weight', 'classifier.bias'])\n"]}],"source":["state_dict = torch.load('trained_model_dic.pth')\n","print(state_dict.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":188,"status":"ok","timestamp":1638229491048,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"TCFtuyBv3ADq","outputId":"926a21bc-7488-4417-d42b-29f9fa5a07ae"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["ner_model = NerModel(BertEmbModel).to('cuda')\n","ner_model.load_state_dict(state_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VSkY_QSCz3tC"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"ymiejDO5srYE"},"source":["# Obtain datasets' weights values (Do not run - fixed values)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17383729,"status":"ok","timestamp":1645970121321,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"GsRs55zcsxhk","outputId":"57de09ef-6f18-4c67-c5e9-0df872fc0ad6"},"outputs":[{"output_type":"stream","name":"stdout","text":["0:  38412 1:  891 2:  1767 3:  1444 4:  2461 5:  231 6:  254 7:  541 8:  815 9:  1533 10:  2034 11:  950 12:  79\n"]}],"source":["zero = 0\n","one=0\n","two=0 \n","three=0\n","four=0\n","five=0\n","six=0\n","seven=0\n","eight=0\n","nine=0\n","ten=0\n","eleven=0\n","tw=0\n","\n","local_set = train\n","for i in range(len(local_set)):\n","  for j in range(len(local_set[i]['labels'])):\n","    if local_set[i]['labels'][j] == 0:\n","      zero += 1\n","    elif local_set[i]['labels'][j] == 1:\n","      one += 1\n","    elif local_set[i]['labels'][j] == 2:\n","      two += 1\n","    elif local_set[i]['labels'][j] == 3:\n","      three += 1\n","    elif local_set[i]['labels'][j] == 4:\n","      four += 1\n","    elif local_set[i]['labels'][j] == 5:\n","      five += 1\n","    elif local_set[i]['labels'][j] == 6:\n","      six += 1\n","    elif local_set[i]['labels'][j] == 7:\n","      seven += 1\n","    elif local_set[i]['labels'][j] == 8:\n","      eight += 1\n","    elif local_set[i]['labels'][j] == 9:\n","      nine += 1\n","    elif local_set[i]['labels'][j] == 10:\n","      ten += 1\n","    elif local_set[i]['labels'][j] == 11:\n","      eleven += 1\n","    elif local_set[i]['labels'][j] == 12:\n","      tw += 1\n","    \n","print('0: ', zero, '1: ', one, '2: ', two, '3: ', three, '4: ', four, '5: ', five, '6: ', six, '7: ', seven, '8: ', eight, '9: ', nine, '10: ', ten, '11: ', eleven, '12: ', tw)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YzN52yRfsym4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645952737594,"user_tz":360,"elapsed":4852863,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"ad64567b-8e2f-4b1e-e5aa-96424f48e711"},"outputs":[{"output_type":"stream","name":"stdout","text":["0:  11217 1:  262 2:  505 3:  430 4:  747 5:  71 6:  69 7:  158 8:  217 9:  520 10:  698 11:  241 12:  16\n"]}],"source":["zero = 0\n","one=0\n","two=0 \n","three=0\n","four=0\n","five=0\n","six=0\n","seven=0\n","eight=0\n","nine=0\n","ten=0\n","eleven=0\n","tw=0\n","\n","local_set = test\n","for i in range(len(local_set)):\n","  for j in range(len(local_set[i]['labels'])):\n","    if local_set[i]['labels'][j] == 0:\n","      zero += 1\n","    elif local_set[i]['labels'][j] == 1:\n","      one += 1\n","    elif local_set[i]['labels'][j] == 2:\n","      two += 1\n","    elif local_set[i]['labels'][j] == 3:\n","      three += 1\n","    elif local_set[i]['labels'][j] == 4:\n","      four += 1\n","    elif local_set[i]['labels'][j] == 5:\n","      five += 1\n","    elif local_set[i]['labels'][j] == 6:\n","      six += 1\n","    elif local_set[i]['labels'][j] == 7:\n","      seven += 1\n","    elif local_set[i]['labels'][j] == 8:\n","      eight += 1\n","    elif local_set[i]['labels'][j] == 9:\n","      nine += 1\n","    elif local_set[i]['labels'][j] == 10:\n","      ten += 1\n","    elif local_set[i]['labels'][j] == 11:\n","      eleven += 1\n","    elif local_set[i]['labels'][j] == 12:\n","      tw += 1\n","    \n","print('0: ', zero, '1: ', one, '2: ', two, '3: ', three, '4: ', four, '5: ', five, '6: ', six, '7: ', seven, '8: ', eight, '9: ', nine, '10: ', ten, '11: ', eleven, '12: ', tw)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B64qF5V-trfK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645947884734,"user_tz":360,"elapsed":2442887,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"}},"outputId":"5a2705c3-a356-47a3-ad20-93c1e4761d38"},"outputs":[{"output_type":"stream","name":"stdout","text":["0:  5370 1:  127 2:  265 3:  216 4:  419 5:  38 6:  46 7:  71 8:  101 9:  212 10:  289 11:  147 12:  14\n"]}],"source":["zero = 0\n","one=0\n","two=0 \n","three=0\n","four=0\n","five=0\n","six=0\n","seven=0\n","eight=0\n","nine=0\n","ten=0\n","eleven=0\n","tw=0\n","\n","local_set = val\n","for i in range(len(local_set)):\n","  for j in range(len(local_set[i]['labels'])):\n","    if local_set[i]['labels'][j] == 0:\n","      zero += 1\n","    elif local_set[i]['labels'][j] == 1:\n","      one += 1\n","    elif local_set[i]['labels'][j] == 2:\n","      two += 1\n","    elif local_set[i]['labels'][j] == 3:\n","      three += 1\n","    elif local_set[i]['labels'][j] == 4:\n","      four += 1\n","    elif local_set[i]['labels'][j] == 5:\n","      five += 1\n","    elif local_set[i]['labels'][j] == 6:\n","      six += 1\n","    elif local_set[i]['labels'][j] == 7:\n","      seven += 1\n","    elif local_set[i]['labels'][j] == 8:\n","      eight += 1\n","    elif local_set[i]['labels'][j] == 9:\n","      nine += 1\n","    elif local_set[i]['labels'][j] == 10:\n","      ten += 1\n","    elif local_set[i]['labels'][j] == 11:\n","      eleven += 1\n","    elif local_set[i]['labels'][j] == 12:\n","      tw += 1\n","    \n","print('0: ', zero, '1: ', one, '2: ', two, '3: ', three, '4: ', four, '5: ', five, '6: ', six, '7: ', seven, '8: ', eight, '9: ', nine, '10: ', ten, '11: ', eleven, '12: ', tw)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eEKHdlDyy1T2"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["LyMVIljFrioE","52t8l945rf1Y","-DBrafz0KqEq","oGYV8ipcJ5fU","7LthVVOhx_Sz","1Nh8Lcpvb_F4","kv6pGzbGpv2D","BBA4owXH8oS1","dcdDIwq0kXy2","k0w9Lc0d3iOT","hC35X0v72kXB","ymiejDO5srYE"],"name":"SciECR+SciModel-BIO.ipynb","provenance":[{"file_id":"1apRBKJ_i2t4gsKy0TfRAM0Gih4gDkI15","timestamp":1634538734401}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a1476d25d48345149c175868fed7d274":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f0b2c3cf8d094954bab8e5e56f0bf872","IPY_MODEL_9639c6fea41f4bca8363aee422ba0737","IPY_MODEL_8a8f1805e92e4653a905f60ff2030e1a"],"layout":"IPY_MODEL_b62351b64d5e4e8eabab5932764756a7"}},"f0b2c3cf8d094954bab8e5e56f0bf872":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dec757c9dc3e4233a5ea706cee022bed","placeholder":"​","style":"IPY_MODEL_64a7da0e64b942de9b06b9b32f9bb806","value":"Downloading: 100%"}},"9639c6fea41f4bca8363aee422ba0737":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_829e228cc1034b9d9510ffbf546aaae4","max":385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4d9bc8b9fada4bfa8c89310e4152e348","value":385}},"8a8f1805e92e4653a905f60ff2030e1a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_212f9fa896524b19bace9fd386715f41","placeholder":"​","style":"IPY_MODEL_85d96ce17fa84003bd86d076cefb2ec3","value":" 385/385 [00:00&lt;00:00, 4.07kB/s]"}},"b62351b64d5e4e8eabab5932764756a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dec757c9dc3e4233a5ea706cee022bed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64a7da0e64b942de9b06b9b32f9bb806":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"829e228cc1034b9d9510ffbf546aaae4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d9bc8b9fada4bfa8c89310e4152e348":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"212f9fa896524b19bace9fd386715f41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85d96ce17fa84003bd86d076cefb2ec3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d4fbdcb0ed745988516414b03f44c12":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb160682acbc40e0bfa1da5829424cef","IPY_MODEL_84295e5ba2a546f599fc220cddc7e534","IPY_MODEL_33fbb598805141fa900ffe7433c92b91"],"layout":"IPY_MODEL_ae795a36a39f4686b93ea7cd42f059e3"}},"bb160682acbc40e0bfa1da5829424cef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d10a5eeb33644970837ab0b60d229e26","placeholder":"​","style":"IPY_MODEL_365f1298dc57485ca9b809893014fbd1","value":"Downloading: 100%"}},"84295e5ba2a546f599fc220cddc7e534":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4260bdee1e184e4586aec375f496e7f8","max":227845,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae7f5214c63d4117b528ca228a306242","value":227845}},"33fbb598805141fa900ffe7433c92b91":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f65b051125c406ea39378607bed1808","placeholder":"​","style":"IPY_MODEL_db6ef86ad5f04ee5a6a1b92f6485ec04","value":" 223k/223k [00:00&lt;00:00, 742kB/s]"}},"ae795a36a39f4686b93ea7cd42f059e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d10a5eeb33644970837ab0b60d229e26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"365f1298dc57485ca9b809893014fbd1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4260bdee1e184e4586aec375f496e7f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae7f5214c63d4117b528ca228a306242":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4f65b051125c406ea39378607bed1808":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db6ef86ad5f04ee5a6a1b92f6485ec04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f849d11d04041e88436f980f9cad4ac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4268ed26baa2430b9b4c6fa382a74d1e","IPY_MODEL_3474686a610e430697d9cf3f46d8a684","IPY_MODEL_5ae1a0f5a2144220b0c56f0ef1c06863"],"layout":"IPY_MODEL_d4aa92747e86433cad4aea2f6d8f3b41"}},"4268ed26baa2430b9b4c6fa382a74d1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d5f3b964d694d6aaa65258cfbe0f498","placeholder":"​","style":"IPY_MODEL_ae287321f976431c8566b9734aab57fc","value":"Downloading: 100%"}},"3474686a610e430697d9cf3f46d8a684":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_230efeb81e6e4841b78961409b7aa79f","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_07cdb291e89b4557bca2ec866333b374","value":442221694}},"5ae1a0f5a2144220b0c56f0ef1c06863":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ab291a3ca664382afa5b12c6c886ec3","placeholder":"​","style":"IPY_MODEL_86af2d663b014f3caae282f0a42154cb","value":" 422M/422M [00:08&lt;00:00, 55.4MB/s]"}},"d4aa92747e86433cad4aea2f6d8f3b41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d5f3b964d694d6aaa65258cfbe0f498":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae287321f976431c8566b9734aab57fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"230efeb81e6e4841b78961409b7aa79f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07cdb291e89b4557bca2ec866333b374":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ab291a3ca664382afa5b12c6c886ec3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86af2d663b014f3caae282f0a42154cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}